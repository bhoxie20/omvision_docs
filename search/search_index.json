{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"OMVision Developer Documentation","text":"<p>Welcome to the OMVision internal developer documentation. Use the navigation on the left to explore the system architecture, data pipeline, machine learning components, and integrations.</p>"},{"location":"data-models-database/data_models_database/","title":"4. Data Models &amp; Database","text":"<p>OMVision's data persistence layer relies on a PostgreSQL database managed through SQLAlchemy ORM and versioned with Alembic migrations. The database stores all extracted entities (companies, people, signals), their enrichments, relationships, and user-generated metadata. This section documents the schema design, relationships, migration workflow, and access patterns that ensure data integrity and consistency across the system.</p>"},{"location":"data-models-database/data_models_database/#41-database-schema","title":"4.1 Database Schema","text":"<p>OMVision's schema is organized around seven primary tables representing data sources, raw signals, extracted entities, enriched metrics, and user-defined groupings. The schema supports flexible JSON storage for semi-structured data while maintaining referential integrity through foreign keys and association tables.</p>"},{"location":"data-models-database/data_models_database/#database-location","title":"Database Location","text":"<p>Production: AWS RDS PostgreSQL 14+ instance (see \u00a72.2.2 Infrastructure &amp; Deployment) Local Development: Docker-containerized PostgreSQL or native installation</p> <p>Connection Management: The <code>SYSTEM_DB_CONN_STRING</code> environment variable (loaded from <code>.env</code> or AWS Secrets Manager) provides the connection URI used by both Alembic migrations and the <code>DatabaseResource</code> class.</p>"},{"location":"data-models-database/data_models_database/#411-core-entities","title":"4.1.1 Core Entities","text":"<p>OMVision's core schema consists of seven primary tables that capture the complete deal-sourcing workflow from raw signal ingestion through entity extraction and enrichment.</p>"},{"location":"data-models-database/data_models_database/#source","title":"Source","text":"<p>Location: <code>app/db/models.py</code> (lines 40-52)</p> <p>Represents external data providers (Accern, Gmail, Harmonic) that feed signals into OMVision.</p> Column Type Description <code>id</code> <code>Integer</code> (PK) Auto-incrementing primary key <code>name</code> <code>Text</code> Human-readable source name (e.g., \"Accern\", \"Gmail\") <code>description</code> <code>String</code> Brief description of the source's purpose <code>base_url</code> <code>Text</code> API endpoint or base URL for the source <code>channels</code> <code>ARRAY(JSON)</code> Source-specific channels or filters (e.g., Accern themes) <code>created_at</code> <code>DateTime</code> Record creation timestamp (UTC) <code>updated_at</code> <code>DateTime</code> Last modification timestamp (UTC) <p>Relationships:</p> <ul> <li><code>signals</code>: One-to-many with <code>Signal</code> table (one source can have multiple signals)</li> <li><code>searches</code>: One-to-many with <code>Search</code> table (one source can have multiple saved searches)</li> </ul> <p>Typical Data: This is typically a small table (3-5 rows) representing the active data sources:</p> <ul> <li>Accern (with 3 channels for different deal flow feeds)</li> <li>Gmail (newsletter monitoring)</li> <li>Harmonic Search (saved searches from Harmonic)</li> </ul> <p>Usage: Pipeline jobs query <code>Source</code> by name (e.g., <code>fetch_source_from_db(source_name=\"Accern\")</code>) to retrieve the source ID for associating newly ingested signals. Source records are managed through the <code>upsert_data_sources</code> job (see \u00a73.7.2).</p>"},{"location":"data-models-database/data_models_database/#signal","title":"Signal","text":"<p>Location: <code>app/db/models.py</code> (lines 68-79)</p> <p>Stores raw, unstructured data from external sources before entity extraction. Signals represent news articles, emails, or API responses that mention companies or people.</p> Column Type Description <code>id</code> <code>Integer</code> (PK) Auto-incrementing primary key <code>source_id</code> <code>Integer</code> (FK) References <code>source.id</code> <code>source_data</code> <code>JSON</code> Raw payload from the source API (titles, URLs, timestamps) <code>name</code> <code>Text</code> Signal title or subject line <code>ner_tags</code> <code>JSON</code> Extracted named entities (companies, people) after NER processing <code>raw_ner_tags</code> <code>JSON</code> Unfiltered NER output before entity validation <code>source_company_ids</code> <code>ARRAY(Text)</code> External company IDs extracted from the signal (e.g., Harmonic URNs) <code>source_people_ids</code> <code>ARRAY(Text)</code> External people IDs extracted from the signal <code>created_at</code> <code>DateTime</code> Record creation timestamp (UTC) <code>updated_at</code> <code>DateTime</code> Last modification timestamp (UTC) <p>Relationships:</p> <ul> <li><code>source</code>: Many-to-one with <code>Source</code> table (via <code>source_id</code> foreign key)</li> </ul> <p>Update Pattern: After initial insertion, signals are updated in bulk to populate <code>ner_tags</code> (via <code>bulk_update_ner_tags</code>), <code>source_company_ids</code> (via <code>bulk_update_company_ids</code>), and <code>source_people_ids</code> (via <code>bulk_update_people_ids</code>) as downstream processing stages complete.</p> <p>Lifecycle:</p> <ol> <li>Created with <code>source_data</code> and <code>raw_ner_tags</code> populated (from NER extraction)</li> <li>Updated with <code>ner_tags</code> after entity filtering</li> <li>Updated with <code>source_company_ids</code> and <code>source_people_ids</code> after enrichment</li> </ol>"},{"location":"data-models-database/data_models_database/#company","title":"Company","text":"<p>Location: <code>app/db/models.py</code> (lines 82-126)</p> <p>Represents enriched company entities extracted from signals or imported from Harmonic saved searches. Each row corresponds to a company with firmographic data from Harmonic.</p> Column Type Description <code>id</code> <code>Integer</code> (PK) Auto-incrementing primary key (OMVision's internal company ID) <code>search_id</code> <code>Integer</code> References <code>search.id</code> if discovered via Harmonic saved search <code>signal_id</code> <code>Integer</code> References <code>signal.id</code> if discovered via Accern/Gmail signal <code>source_company_id</code> <code>Integer</code> Harmonic's company ID (from their API) <code>type</code> <code>Text</code> Company type classification <code>name</code> <code>Text</code> Company name (from Harmonic) <code>name_aliases</code> <code>ARRAY(Text)</code> Alternative names or DBAs <code>legal_name</code> <code>Text</code> Registered legal name <code>description</code> <code>Text</code> Company description/mission <code>contact</code> <code>JSON</code> Contact information (email, phone) <code>founding_date</code> <code>JSON</code> Founding date information <code>website_urls</code> <code>JSON</code> Primary and additional website URLs <code>logo_url</code> <code>Text</code> URL to company logo <code>ownership_status</code> <code>Text</code> Public/Private/Subsidiary status <code>location</code> <code>JSON</code> HQ location (city, state, country) <code>tags</code> <code>ARRAY(JSON)</code> Industry tags and classifications <code>socials</code> <code>JSON</code> Social media links (LinkedIn, Twitter, etc.) <code>rank</code> <code>Float</code> ML-predicted relevance score (0.0-1.0) <code>related_companies</code> <code>JSON</code> Parent companies, subsidiaries, competitors <code>comments</code> <code>Text</code> User-generated notes about the company <code>relevence_stage</code> <code>Text</code> Investment pipeline stage (\"In Review\", \"Passed\", \"Declined\", \"Portfolio\") <code>is_hidden</code> <code>Boolean</code> Whether company is hidden from UI (default: False) <code>created_at</code> <code>DateTime</code> Record creation timestamp (UTC) <code>updated_at</code> <code>DateTime</code> Last modification timestamp (UTC) <p>Relationships:</p> <ul> <li><code>people</code>: Many-to-many with <code>Person</code> table via <code>person_company_association</code> (employees at company)</li> <li><code>lists</code>: One-to-many with <code>ListEntityAssociation</code> (company memberships in user-created lists)</li> </ul> <p>Indexes:</p> <ul> <li>Primary key on <code>id</code></li> <li>Recommended: Index on <code>(name, source_company_id)</code> for deduplication queries (not currently implemented)</li> </ul> <p>Backend Duplicate Handling:</p> <p>The Company table does not have a unique constraint on <code>(name, source_company_id)</code>, which means duplicate rows can exist in the database.</p> <p>When Duplicates Occur:</p> <p>Duplicates occur when the same company (identified by the same <code>source_company_id</code> from Harmonic) is ingested multiple times:</p> <ol> <li>Across Different Days: A company mentioned in an Accern signal on Monday and again on Friday will be inserted twice</li> <li>Multiple Signals Same Day: A company mentioned in 3 different signals on the same day will be inserted 3 times</li> <li>Cross-Source Mentions: The same company discovered via Accern and also in a Harmonic saved search</li> </ol> <p>Example Scenario:</p> <pre><code>-- Monday: \"Acme AI\" discovered via Accern signal\nRow 1: id=100, name=\"Acme AI\", source_company_id=12345, signal_id=50\n\n-- Friday: \"Acme AI\" mentioned in another Accern signal\nRow 2: id=200, name=\"Acme AI\", source_company_id=12345, signal_id=75\n\n-- Same Friday: \"Acme AI\" also in Harmonic saved search\nRow 3: id=201, name=\"Acme AI\", source_company_id=12345, search_id=10\n</code></pre> <p>All three rows have the same <code>source_company_id</code> (12345) from Harmonic, representing the same physical company, but exist as separate database records.</p> <p>Deduplication Logic (Persistence Workflow Only):</p> <p>The system does not prevent duplicates during insertion. The <code>bulk_insert_rows</code> method (<code>app/resources/db_manager.py</code>) performs a simple <code>session.bulk_save_objects(rowArray)</code> with no duplicate checking.</p> <p>However, the <code>persist_custom_columns_data</code> job (see \u00a73.2.5) implements deduplication when syncing user-generated metadata:</p> <p>Code Reference: <code>app/resources/db_manager.py</code> - <code>fetch_custom_columns_by_company_name_and_source_company_id</code> method</p> <pre><code>def fetch_custom_columns_by_company_name_and_source_company_id(\n    self, ingested_companies: list[CompanyCustomColumns]\n):\n    ingested_company_ids = [company.id for company in ingested_companies]\n\n    with self._Session() as session:\n        # Build filters for each (name, source_company_id) combination\n        filters = [\n            and_(\n                Company.name == company.name,\n                Company.source_company_id == company.source_company_id,\n            )\n            for company in ingested_companies\n        ]\n\n        # Subquery: find the OLDEST (minimum ID) for each combination\n        subquery = (\n            session.query(\n                Company.name,\n                Company.source_company_id,\n                func.min(Company.id).label(\"oldest_id\"),\n            )\n            .filter(or_(*filters))\n            .group_by(Company.name, Company.source_company_id)\n            .subquery()\n        )\n\n        # Return only the oldest record for each (name, source_company_id) group\n        return (\n            session.query(Company)\n            .outerjoin(ListEntityAssociation, ListEntityAssociation.entity_id == Company.id)\n            .outerjoin(List, List.id == ListEntityAssociation.list_id)\n            .join(subquery, Company.id == subquery.c.oldest_id)\n            .filter(not_(Company.id.in_(ingested_company_ids)))\n            .all()\n        )\n</code></pre> <p>How Deduplication Works:</p> <ol> <li>Groups by <code>(name, source_company_id)</code>: All companies with the same name and Harmonic ID are grouped together</li> <li>Selects Oldest Record: Uses <code>func.min(Company.id)</code> to identify the earliest-created record for each group</li> <li>Updates Only Oldest: When custom columns (rank, comments, relevance_stage, etc.) are synced from the frontend, only the oldest record receives the updates</li> </ol> <p>Result:</p> <p>Using the example above:</p> <ul> <li>Row 1 (ID=100): Receives custom column updates because it's the oldest</li> <li>Row 2 (ID=200): Ignored during persistence sync</li> <li>Row 3 (ID=201): Ignored during persistence sync</li> </ul> <p>Frontend Behavior (Unknown):</p> <p>The documentation does not currently cover how the frontend (Supabase/React application) handles duplicates when displaying companies to users. This is an area that requires further investigation or clarification from the frontend codebase.</p> <p>Design Implications:</p> <ul> <li>Storage: Duplicate records consume additional database space</li> <li>Performance: Queries may return multiple rows for the same company unless explicitly deduplicated</li> <li>Data Consistency: Only the oldest record reflects current user annotations</li> <li>Future Enhancement: Consider adding a unique constraint on <code>(name, source_company_id)</code> or implementing upsert logic during insertion</li> </ul>"},{"location":"data-models-database/data_models_database/#person","title":"Person","text":"<p>Location: <code>app/db/models.py</code> (lines 129-158)</p> <p>Represents individuals (founders, executives, employees) extracted from signals or enriched via Harmonic.</p> Column Type Description <code>id</code> <code>Integer</code> (PK) Auto-incrementing primary key <code>signal_id</code> <code>Integer</code> References <code>signal.id</code> if discovered via signal <code>source_person_id</code> <code>Integer</code> External person ID (from Harmonic or LinkedIn) <code>first_name</code> <code>Text</code> Person's first name <code>last_name</code> <code>Text</code> Person's last name <code>location</code> <code>JSON</code> Person's location information <code>linkedin_url</code> <code>Text</code> LinkedIn profile URL <code>title</code> <code>Text</code> Current job title <code>summary</code> <code>Text</code> Professional summary or bio <code>profile_picture_url</code> <code>Text</code> URL to profile picture <code>relevence_stage</code> <code>Text</code> Pipeline stage for tracking <code>comments</code> <code>Text</code> User-generated notes <code>is_hidden</code> <code>Boolean</code> Whether person is hidden from UI <code>created_at</code> <code>DateTime</code> Record creation timestamp <code>updated_at</code> <code>DateTime</code> Last modification timestamp <p>Relationships:</p> <ul> <li><code>companies</code>: Many-to-many with <code>Company</code> table via <code>person_company_association</code></li> <li><code>lists</code>: One-to-many with <code>ListEntityAssociation</code></li> </ul> <p>Duplicate Handling: Similar to the Company table, people can appear as multiple database rows if discovered across different signals or searches. The <code>persist_custom_columns_data</code> job uses <code>(first_name, last_name, source_person_id)</code> as a deduplication key, selecting the oldest record (minimum ID) when syncing custom columns from the frontend.</p>"},{"location":"data-models-database/data_models_database/#search","title":"Search","text":"<p>Location: <code>app/db/models.py</code> (lines 55-65)</p> <p>Represents saved searches from Harmonic that are monitored for new companies/people.</p> Column Type Description <code>id</code> <code>Integer</code> (PK) Auto-incrementing primary key <code>source_id</code> <code>Integer</code> (FK) References <code>source.id</code> (always Harmonic source) <code>name</code> <code>Text</code> Search name (e.g., \"DealFlow - Series A Healthcare\") <code>source_company_ids</code> <code>ARRAY(Text)</code> List of Harmonic company IDs from this search <code>source_people_ids</code> <code>ARRAY(Text)</code> List of Harmonic people IDs from this search <code>created_at</code> <code>DateTime</code> Record creation timestamp <code>updated_at</code> <code>DateTime</code> Last modification timestamp <p>Relationships:</p> <ul> <li><code>source</code>: Many-to-one with <code>Source</code> table</li> </ul> <p>Usage: The <code>ingest_companies_from_searches</code> job (\u00a73.2.4) fetches saved searches from Harmonic daily and stores new results. The <code>source_company_ids</code> array tracks which companies originated from each search for traceability.</p>"},{"location":"data-models-database/data_models_database/#companymetric","title":"CompanyMetric","text":"<p>Location: <code>app/db/models.py</code> (lines 119-132)</p> <p>Stores firmographic metrics and enrichments for companies. This table is separate from <code>Company</code> to isolate volatile, data-heavy fields.</p> Column Type Description <code>id</code> <code>Integer</code> (PK) Auto-incrementing primary key (unique to this table) <code>company_id</code> <code>Integer</code> (FK) References <code>company.id</code> <code>stage</code> <code>Text</code> Funding stage (Seed, Series A, etc.) <code>headcount</code> <code>Integer</code> Number of employees <code>traction_metrics</code> <code>JSON</code> Revenue, growth metrics <code>funding</code> <code>JSON</code> Total funding information <code>employees</code> <code>JSON</code> Employee details from Harmonic <code>highlights</code> <code>ARRAY(JSON)</code> Key company highlights <code>employee_highlights</code> <code>ARRAY(JSON)</code> Notable employee backgrounds <code>investor_urn</code> <code>Text</code> Harmonic identifier for investors <code>funding_rounds</code> <code>ARRAY(JSON)</code> Detailed funding round history <code>created_at</code> <code>DateTime</code> Record creation timestamp <code>updated_at</code> <code>DateTime</code> Last modification timestamp <p>Relationships:</p> <ul> <li><code>company</code>: One-to-one with <code>Company</code> table (each <code>CompanyMetric</code> belongs to exactly one <code>Company</code>, and each <code>Company</code> has exactly one <code>CompanyMetric</code>)</li> </ul> <p>Insert Logic (No Updates):</p> <p>The system uses an insert-only pattern for <code>CompanyMetric</code> records:</p> <pre><code># From app/jobs/ingest_companies_from_signals.py - store_companies_metrics_from_signals_in_db\ncompany_metrics = []\nfor inserted_company, company in zip(inserted_companies, all_companies):\n    company_metrics.append(\n        CompanyMetric(\n            company_id=inserted_company.id,  # Foreign key to the Company row\n            stage=company.stage,\n            headcount=company.headcount,\n            # ... other metrics\n        )\n    )\ndb.bulk_insert_rows(company_metrics)\n</code></pre> <p>Key Behavior:</p> <ul> <li>One-to-One Relationship: Each <code>Company</code> row has exactly one <code>CompanyMetric</code> row, and each <code>CompanyMetric</code> belongs to exactly one <code>Company</code> row (verified by database query showing equal counts)</li> <li>No Updates: There is no code that updates existing <code>CompanyMetric</code> records</li> <li>Multiple Metrics Per Physical Company: Since the <code>Company</code> table can have duplicate rows for the same physical company (same <code>source_company_id</code> ingested on different days), that physical company will have multiple <code>CompanyMetric</code> rows - one for each corresponding <code>Company</code> row</li> </ul> <p>Example: <pre><code>-- Monday: \"Acme AI\" ingested for the first time\nCompany:        id=100, name=\"Acme AI\", source_company_id=12345\nCompanyMetric:  id=1, company_id=100, headcount=25, stage=\"Series A\"\n\n-- Friday: \"Acme AI\" ingested again (duplicate Company row created)\nCompany:        id=200, name=\"Acme AI\", source_company_id=12345\nCompanyMetric:  id=2, company_id=200, headcount=30, stage=\"Series A\"\n</code></pre></p> <p>Note on <code>id</code> vs <code>company_id</code>:</p> <ul> <li><code>id</code>: Primary key of the <code>CompanyMetric</code> table (auto-incrementing, unique within this table)</li> <li><code>company_id</code>: Foreign key pointing to <code>Company.id</code></li> <li>These are always different values</li> </ul>"},{"location":"data-models-database/data_models_database/#412-association-tables","title":"4.1.2 Association Tables","text":"<p>OMVision uses two patterns for many-to-many relationships:</p>"},{"location":"data-models-database/data_models_database/#standard-many-to-many-person_company_association","title":"Standard Many-to-Many: <code>person_company_association</code>","text":"<p>Location: <code>app/db/models.py</code> (lines 32-37)</p> <pre><code>person_company_association = Table(\n    \"person_company_association\",\n    Base.metadata,\n    Column(\"person_id\", Integer, ForeignKey(\"person.id\")),\n    Column(\"company_id\", Integer, ForeignKey(\"company.id\")),\n)\n</code></pre> <p>This simple junction table links people to companies (employment relationships).</p> <p>Usage Example: <pre><code># Query all companies where a person works\nperson = session.query(Person).filter_by(id=123).first()\ncompanies = person.companies  # Returns list of Company objects\n\n# Query all employees at a company\ncompany = session.query(Company).filter_by(id=456).first()\nemployees = company.people  # Returns list of Person objects\n</code></pre></p>"},{"location":"data-models-database/data_models_database/#polymorphic-association-listentityassociation","title":"Polymorphic Association: <code>ListEntityAssociation</code>","text":"<p>Location: <code>app/db/models.py</code> (lines 174-207)</p> <pre><code>class ListEntityAssociation(Base):\n    id = Column(Integer, primary_key=True, autoincrement=True)\n    list_id = Column(Integer, ForeignKey(\"list.id\"), nullable=False)\n    entity_id = Column(Integer, nullable=False)\n    entity_type = Column(String(50), nullable=False)  # 'company' or 'person'\n    created_at = Column(DateTime, default=utcnow(), nullable=False)\n</code></pre> <p>This table enables polymorphic relationships: a single <code>List</code> can contain both companies and people. The <code>entity_type</code> discriminator column specifies whether <code>entity_id</code> references a company or person.</p> <p>Usage Example: <pre><code># Add company to list\ndb.add_company_to_list(company_id=123, list_id=5)\n\n# Add person to list\ndb.add_person_to_list(person_id=456, list_id=5)\n\n# Query all entities in a list\nlist_obj = session.query(List).filter_by(id=5).first()\nfor association in list_obj.entities:\n    if association.entity_type == \"company\":\n        print(f\"Company: {association.company.name}\")\n    elif association.entity_type == \"person\":\n        print(f\"Person: {association.person.first_name} {association.person.last_name}\")\n</code></pre></p>"},{"location":"data-models-database/data_models_database/#413-entity-relationship-diagram","title":"4.1.3 Entity Relationship Diagram","text":"<pre><code>erDiagram\n    Source ||--o{ Signal : \"has many\"\n    Source ||--o{ Search : \"has many\"\n    Signal ||--o{ Company : \"produces\"\n    Signal ||--o{ Person : \"produces\"\n    Search ||--o{ Company : \"discovers\"\n    Search ||--o{ Person : \"discovers\"\n    Company ||--|| CompanyMetric : \"has metrics\"\n    Company }o--o{ Person : \"person_company_association\"\n    Company ||--o{ ListEntityAssociation : \"appears in lists\"\n    Person ||--o{ ListEntityAssociation : \"appears in lists\"\n    List ||--o{ ListEntityAssociation : \"contains entities\"\n\n    Source {\n        int id PK\n        text name\n        text base_url\n        json channels\n        datetime created_at\n    }\n\n    Signal {\n        int id PK\n        int source_id FK\n        json source_data\n        json ner_tags\n        array source_company_ids\n        array source_people_ids\n        datetime created_at\n    }\n\n    Search {\n        int id PK\n        int source_id FK\n        text name\n        array source_company_ids\n        array source_people_ids\n        datetime created_at\n    }\n\n    Company {\n        int id PK\n        int signal_id\n        int search_id\n        int source_company_id\n        text name\n        text description\n        json location\n        float rank\n        text relevence_stage\n        datetime created_at\n    }\n\n    Person {\n        int id PK\n        int signal_id\n        int search_id\n        int source_person_id\n        text first_name\n        text last_name\n        text linkedin_url\n        text relevence_stage\n        datetime created_at\n    }\n\n    CompanyMetric {\n        int id PK\n        int company_id FK\n        text stage\n        int headcount\n        json funding\n        json employees\n        datetime created_at\n    }\n\n    List {\n        int id PK\n        text name\n        text type\n        datetime created_at\n    }\n\n    ListEntityAssociation {\n        int id PK\n        int list_id FK\n        int entity_id\n        string entity_type\n        datetime created_at\n    }</code></pre>"},{"location":"data-models-database/data_models_database/#42-alembic-migrations","title":"4.2 Alembic Migrations","text":"<p>OMVision uses Alembic for database schema versioning and migrations. Alembic tracks schema changes as Python scripts, enabling reproducible deployments and rollback capabilities.</p>"},{"location":"data-models-database/data_models_database/#421-migration-configuration","title":"4.2.1 Migration Configuration","text":"<p>Location: <code>alembic.ini</code> and <code>alembic/env.py</code></p> <p>Key Settings:</p> <ul> <li>Script Location: <code>alembic/versions/</code> (stores migration files)</li> <li>Database URL: Loaded from <code>SYSTEM_DB_CONN_STRING</code> environment variable</li> <li>Target Metadata: <code>Base.metadata</code> from <code>app/db/base.py</code></li> </ul> <p>Connection Setup (<code>alembic/env.py</code>): <pre><code>from app.db.base import Base\nfrom app.config import SYSTEM_DB_CONN_STRING\n\nconfig.set_main_option(\"sqlalchemy.url\", SYSTEM_DB_CONN_STRING)\ntarget_metadata = Base.metadata\n</code></pre></p>"},{"location":"data-models-database/data_models_database/#422-migration-history","title":"4.2.2 Migration History","text":"<p>OMVision's schema evolved through multiple migrations. Below is the complete migration history:</p> Revision ID Description Key Changes Created Date <code>5615fc35a13a</code> Phase One Schema Initial schema with Source, Signal, Company, Person, Search, CompanyMetric, List, ListEntityAssociation tables Feb 2024 <code>f4b26d1bc16a</code> Add search_id and signal_id to Company Added nullable foreign keys to link companies to their discovery source Mar 2024 <code>ca7d8e50abe2</code> Add comments, relevance_stage, is_hidden to Company User-generated metadata columns for tracking investment pipeline Apr 2024 <code>d97ec15c5cb0</code> Add comments, relevance_stage, is_hidden to Person Extended user metadata to people entities Apr 2024 <code>4a7c5b73917f</code> Add rank to Company ML-predicted relevance score column May 2024 <p>Current Schema Version: <code>4a7c5b73917f</code> (as of documentation date)</p>"},{"location":"data-models-database/data_models_database/#423-creating-new-migrations","title":"4.2.3 Creating New Migrations","text":"<p>When modifying the database schema, follow this workflow:</p> <p>1. Update SQLAlchemy Models</p> <p>Modify the relevant model in <code>app/db/models.py</code>: <pre><code># Example: Add a new column\nclass Company(Base):\n    # ... existing columns ...\n    new_field = Column(Text, nullable=True)\n</code></pre></p> <p>2. Generate Migration Script</p> <pre><code>alembic revision --autogenerate -m \"Add new_field to Company\"\n</code></pre> <p>Alembic compares <code>Base.metadata</code> against the current database schema and generates a migration script in <code>alembic/versions/</code>.</p> <p>3. Review Generated Migration</p> <p>Critical: Alembic's autogenerate is not perfect. Always review the generated script:</p> <ul> <li>Check column types match intentions</li> <li>Verify nullable constraints</li> <li>Add data migrations if needed (e.g., populating new columns with default values)</li> </ul> <p>Example Generated Migration: <pre><code># alembic/versions/xyz123_add_new_field.py\ndef upgrade() -&gt; None:\n    op.add_column('company', sa.Column('new_field', sa.Text(), nullable=True))\n\ndef downgrade() -&gt; None:\n    op.drop_column('company', 'new_field')\n</code></pre></p> <p>4. Apply Migration</p> <pre><code># Local/Dev\nalembic upgrade head\n\n# Production (via Dagster job or CI/CD)\nalembic upgrade head\n</code></pre> <p>5. Commit Migration File</p> <p>Add the new migration file to version control: <pre><code>git add alembic/versions/xyz123_add_new_field.py\ngit commit -m \"Migration: Add new_field to Company table\"\n</code></pre></p>"},{"location":"data-models-database/data_models_database/#424-migration-rollback","title":"4.2.4 Migration Rollback","text":"<p>Alembic supports rolling back migrations via <code>downgrade()</code> functions.</p> <p>Rollback to Previous Version: <pre><code>alembic downgrade -1  # Go back one migration\n</code></pre></p> <p>Rollback to Specific Version: <pre><code>alembic downgrade 5615fc35a13a  # Rollback to Phase One schema\n</code></pre></p>"},{"location":"data-models-database/data_models_database/#43-database-resource-management","title":"4.3 Database Resource Management","text":"<p>OMVision centralizes database access through the <code>DatabaseResource</code> class, which manages connection pooling, session lifecycle, and common query patterns.</p>"},{"location":"data-models-database/data_models_database/#431-databaseresource-class","title":"4.3.1 DatabaseResource Class","text":"<p>Location: <code>app/resources/db_manager.py</code></p> <p>The <code>DatabaseResource</code> class implements the Dagster <code>ConfigurableResource</code> interface, enabling dependency injection of database connections into Dagster jobs and ops.</p> <p>Initialization: <pre><code>from sqlalchemy import create_engine\nfrom sqlalchemy.orm import scoped_session, sessionmaker\n\nclass DatabaseResource(ConfigurableResource):\n    conn_string: str = Field(description=\"Database connection string\")\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self._engine = None\n        self._Session = None\n\n    def setup_for_execution(self, context) -&gt; None:\n        \"\"\"Initialize engine and session factory when resource is created\"\"\"\n        self._engine = create_engine(\n            self.conn_string,\n            pool_size=10,\n            max_overflow=20,\n            pool_pre_ping=True  # Verify connections before use\n        )\n        self._Session = scoped_session(\n            sessionmaker(bind=self._engine)\n        )\n</code></pre></p> <p>Key Features:</p> <ul> <li>Connection Pooling: SQLAlchemy's connection pool reuses database connections across requests</li> <li>Thread Safety: <code>scoped_session</code> provides thread-local sessions</li> <li>Connection Health Checks: <code>pool_pre_ping=True</code> detects stale connections</li> </ul>"},{"location":"data-models-database/data_models_database/#432-session-management","title":"4.3.2 Session Management","text":"<p>The <code>DatabaseResource</code> uses context managers to ensure proper session lifecycle:</p> <pre><code>def fetch_data(self, model, field, value):\n    \"\"\"Example query method with session management\"\"\"\n    with self._Session() as session:\n        results = session.query(model).filter(field == value).all()\n        return results\n    # Session automatically closed when exiting 'with' block\n</code></pre> <p>Session Lifecycle:</p> <ol> <li>Creation: <code>with self._Session()</code> creates a new session from the pool</li> <li>Query Execution: Perform database operations within the context</li> <li>Commit/Rollback: Transactions are committed if no exceptions occur</li> <li>Cleanup: Session is automatically closed and returned to the pool</li> </ol> <p>Error Handling: <pre><code>with self._Session() as session:\n    try:\n        # Database operations\n        session.commit()\n    except Exception as e:\n        session.rollback()  # Undo changes on error\n        raise e\n</code></pre></p>"},{"location":"data-models-database/data_models_database/#433-common-database-operations","title":"4.3.3 Common Database Operations","text":""},{"location":"data-models-database/data_models_database/#bulk-insert","title":"Bulk Insert","text":"<p>Method: <code>bulk_insert_rows(rowArray: list)</code></p> <pre><code>def bulk_insert_rows(self, rowArray):\n    \"\"\"Insert multiple rows efficiently\"\"\"\n    with self._Session() as session:\n        session.bulk_save_objects(rowArray)\n        session.commit()\n    return rowArray  # Returns inserted objects with populated IDs\n</code></pre> <p>Usage: <pre><code>companies = [\n    Company(name=\"Acme AI\", source_company_id=12345),\n    Company(name=\"Beta Corp\", source_company_id=67890),\n]\ninserted = db.bulk_insert_rows(companies)\n</code></pre></p> <p>Note: <code>bulk_save_objects</code> does not populate primary keys by default. Use <code>return_defaults=True</code> if you need IDs immediately.</p>"},{"location":"data-models-database/data_models_database/#bulk-update","title":"Bulk Update","text":"<p>Method: <code>bulk_update_ner_tags(rowArray: list)</code></p> <pre><code>def bulk_update_ner_tags(self, rowArray):\n    \"\"\"Update NER tags for multiple signals\"\"\"\n    updated_rows = 0\n    with self._Session() as session:\n        for row in rowArray:\n            model_class = type(row)\n            stmt = (\n                update(model_class)\n                .where(model_class.id == row.id)\n                .values(ner_tags=row.ner_tags)\n            )\n            session.execute(stmt)\n            updated_rows += 1\n        session.commit()\n    return updated_rows\n</code></pre> <p>Usage: <pre><code>signals = [\n    Signal(id=1, ner_tags={\"org\": [\"Acme AI\"], \"person\": [\"John Doe\"]}),\n    Signal(id=2, ner_tags={\"org\": [\"Beta Corp\"]}),\n]\ndb.bulk_update_ner_tags(signals)\n</code></pre></p>"},{"location":"data-models-database/data_models_database/#deduplication-queries","title":"Deduplication Queries","text":"<p>Method: <code>fetch_custom_columns_by_company_name_and_source_company_id</code></p> <p>This method implements the deduplication logic described in \u00a74.1.1 (Company table):</p> <pre><code>def fetch_custom_columns_by_company_name_and_source_company_id(\n    self, ingested_companies: list[CompanyCustomColumns]\n):\n    \"\"\"Find oldest company for each (name, source_company_id) combination\"\"\"\n    ingested_company_ids = [company.id for company in ingested_companies]\n\n    with self._Session() as session:\n        filters = [\n            and_(\n                Company.name == company.name,\n                Company.source_company_id == company.source_company_id,\n            )\n            for company in ingested_companies\n        ]\n\n        # Subquery: select oldest ID for each (name, source_company_id) group\n        subquery = (\n            session.query(\n                Company.name,\n                Company.source_company_id,\n                func.min(Company.id).label(\"oldest_id\"),\n            )\n            .filter(or_(*filters))\n            .group_by(Company.name, Company.source_company_id)\n            .subquery()\n        )\n\n        # Join to get full company records for oldest IDs only\n        return (\n            session.query(Company)\n            .join(subquery, Company.id == subquery.c.oldest_id)\n            .filter(not_(Company.id.in_(ingested_company_ids)))\n            .all()\n        )\n</code></pre> <p>This pattern is used by the <code>persist_custom_columns_data</code> job to ensure custom columns are applied to the canonical (oldest) record for each company.</p>"},{"location":"data-models-database/data_models_database/#434-resource-usage-in-dagster-jobs","title":"4.3.4 Resource Usage in Dagster Jobs","text":"<p>Dagster jobs access the <code>DatabaseResource</code> via dependency injection:</p> <p>Resource Configuration (<code>app/jobs/__init__.py</code>): <pre><code>from app.resources.db_manager import DatabaseResource\nfrom app.config import SYSTEM_DB_CONN_STRING\n\n@job\ndef ingest_signals_from_accern():\n    # Job ops defined here\n    pass\n\n# Resource bindings\ningest_signals_from_accern = ingest_signals_from_accern.configure(\n    {\n        \"resources\": {\n            \"db\": DatabaseResource(conn_string=SYSTEM_DB_CONN_STRING)\n        }\n    }\n)\n</code></pre></p> <p>Op Usage: <pre><code>@op\ndef store_signals_in_db(context, db: DatabaseResource, signals: list[Signal]):\n    \"\"\"Store signals in database using injected resource\"\"\"\n    context.log.info(f\"Inserting {len(signals)} signals\")\n    db.bulk_insert_rows(signals)\n</code></pre></p> <p>Dagster automatically injects the <code>DatabaseResource</code> instance into ops that declare it as a parameter.</p> <p>-</p>"},{"location":"data-pipeline-processing/data_pipeline_processing/","title":"3. Data Pipeline &amp; Processing Logic","text":"<p>This section provides a comprehensive explanation of OMVision's data pipeline architecture, describing how raw signals from external sources are transformed into enriched, classified, and persisted company records ready for internal analysis.</p>"},{"location":"data-pipeline-processing/data_pipeline_processing/#31-dagster-orchestration","title":"3.1 Dagster Orchestration","text":"<p>OMVision employs Dagster as its orchestration framework to manage complex, interdependent data workflows. Dagster provides job scheduling, dependency management, resource allocation, and observability across the entire pipeline.</p>"},{"location":"data-pipeline-processing/data_pipeline_processing/#311-job-configuration","title":"3.1.1 Job Configuration","text":"<p>All jobs are centrally defined in <code>app/main.py</code> within a <code>Definitions</code> object that serves as the entry point for Dagster's code location. This definition includes:</p> <p>Core Jobs:</p> <ul> <li><code>upsert_data_sources</code>: Initializes or updates source configurations</li> <li><code>ingest_signals_from_accern</code>: Fetches signals from Accern API channels</li> <li><code>ingest_signals_from_emails</code>: Processes newsletter emails via Gmail</li> <li><code>ingest_companies_from_searches</code>: Ingests companies from Harmonic saved searches</li> <li><code>ingest_companies_from_signals</code>: Extracts and enriches companies from signals</li> <li><code>ingest_people_from_searches</code>: Ingests people from Harmonic saved searches</li> <li><code>ingest_people_from_signals</code>: Extracts and enriches people from signals</li> <li><code>classify_ingested_companies</code>: Applies ML classification to unclassified companies</li> <li><code>persist_custom_columns_data</code>: Syncs custom column metadata from frontend</li> </ul> <p>Resources:</p> <p>Jobs have access to configurable resources defined in the <code>resources</code> dictionary:</p> <ul> <li><code>db</code>: <code>DatabaseResource</code> for PostgreSQL interactions</li> <li><code>accern</code>: <code>AccernResource</code> for Accern API integration</li> <li><code>openai</code>: <code>OpenAIResource</code> for NER and context extraction</li> <li><code>gmail</code>: <code>GmailResource</code> for Gmail API integration</li> <li><code>google</code>: <code>WebSearchResource</code> for URL discovery</li> <li><code>harmonic</code>: <code>HarmonicResource</code> for Harmonic API enrichment</li> <li><code>ml</code>: <code>MLResource</code> for machine learning classification</li> <li><code>s3_io_manager</code>: S3-based I/O manager for asset materialization</li> </ul> <p>Resources are instantiated once per run and injected into ops as needed, following Dagster's dependency injection pattern.</p> <p>Assets:</p> <p>The system defines one materialized asset:</p> <ul> <li><code>company_filter_list</code>: An auto-materializing asset that fetches company names from Harmonic filter search and watchlist, stored in S3</li> </ul> <p>This asset uses an eager auto-materialize policy, ensuring it updates when missing and is available for filtering operations.</p>"},{"location":"data-pipeline-processing/data_pipeline_processing/#312-sensors-triggers","title":"3.1.2 Sensors &amp; Triggers","text":"<p>OMVision uses run status sensors to create chained workflows where downstream jobs trigger automatically upon successful completion of upstream jobs. This pattern decouples signal ingestion from entity extraction while maintaining execution order.</p> <p>Signal Ingestion Sensors:</p> <p>Defined in <code>app/sensors/main.py</code>, two sensors monitor signal ingestion jobs:</p> <ol> <li> <p><code>signal_ingestion_from_accern</code></p> </li> <li> <p>Monitors: <code>ingest_signals_from_accern</code></p> </li> <li>Triggers on: <code>DagsterRunStatus.SUCCESS</code></li> <li>Requests: <code>ingest_companies_from_signals</code> and <code>ingest_people_from_signals</code></li> <li>Minimum interval: 7200 seconds (2 hours)</li> <li>Configuration: Injects source-specific config via <code>get_op_config(\"Accern\")</code></li> </ol> <p>Behavior: When Accern signal ingestion succeeds, the sensor yields two RunRequest objects\u2014one for company extraction configured for the \u201cAccern\u201d source, and one for people extraction. The 2-hour minimum interval prevents rapid re-triggering if multiple Accern jobs complete in succession.</p> <ol> <li> <p><code>signal_ingestion_from_emails</code></p> </li> <li> <p>Monitors: <code>ingest_signals_from_emails</code></p> </li> <li>Triggers on: <code>DagsterRunStatus.SUCCESS</code></li> <li>Requests: <code>ingest_companies_from_signals</code> and <code>ingest_people_from_signals</code></li> <li>Minimum interval: 7200 seconds (2 hours)</li> <li>Configuration: Injects source-specific config via <code>get_op_config(\"Gmail\")</code></li> </ol> <p>Behavior: Mirrors the Accern sensor but configured for the \u201cGmail\u201d data source. When email signal ingestion completes successfully, it triggers parallel company and people extraction jobs</p> <p>The minimum interval prevents sensor over-triggering in case of rapid successive runs.</p> <p>Sensor Logic Flow:</p> <pre><code>graph TB\n    A[ingest_signals_from_accern] --&gt;|SUCCESS| B[signal_ingestion_from_accern sensor]\n    B --&gt; C[ingest_companies_from_signals]\n    B --&gt; D[ingest_people_from_signals]\n\n    E[ingest_signals_from_emails] --&gt;|SUCCESS| F[signal_ingestion_from_emails sensor]\n    F --&gt; G[ingest_companies_from_signals]\n    F --&gt; H[ingest_people_from_signals]\n\n    style B fill:#e1f5ff\n    style F fill:#e1f5ff</code></pre> <p>Configuration Injection:</p> <p>The <code>get_op_config</code> utility (in <code>app/sensors/op_config.py</code>) dynamically constructs run configurations based on source name and pipeline type:</p> <pre><code>def get_op_config(source_name: str, pipeline_type: PipelineType = PipelineType.company):\n    op_config = {\n        \"fetch_source_from_db\": {\n            \"config\": {\"source_name\": source_name},\n            \"inputs\": {\"source_name\": source_name},\n        }\n    }\n    watchlist_config = {\"config\": {\"source_name\": source_name}}\n\n    if pipeline_type == PipelineType.company:\n        op_config[\"get_source_watchlist\"] = watchlist_config\n    else:\n        op_config[\"get_source_people_watchlist\"] = watchlist_config\n\n    return op_config\n</code></pre> <p>This ensures that downstream jobs process entities associated with the correct source and watchlist.</p>"},{"location":"data-pipeline-processing/data_pipeline_processing/#313-workspace-configuration","title":"3.1.3 Workspace Configuration","text":"<p>The Dagster workspace is configured via <code>workspace.yaml</code>, which defines code locations accessible to the webserver and daemon.</p> <p>Workspace Definition:</p> <pre><code>load_from:\n  - grpc_server:\n      host: deal_flow_code\n      port: 4000\n      location_name: \"DealFlow\"\n</code></pre> <p>This configuration tells Dagster to load job definitions from a gRPC server running on the <code>deal_flow_code</code> service at port 4000.</p> <p>Service Architecture:</p> <p>The system deploys three Docker services (defined in <code>docker-compose.yaml</code>):</p> <ol> <li><code>dagster_webserver</code>: Hosts the Dagster UI on port 3000, loads jobs from gRPC server</li> <li><code>dagster_daemon</code>: Background service that executes queued runs and manages schedules/sensors</li> <li><code>deal_flow_code</code>: gRPC server exposing all user-defined jobs, ops, resources, and assets</li> </ol> <p>Code Location Server:</p> <p>The <code>deal_flow_code</code> service runs: <pre><code>dagster api grpc -h 0.0.0.0 -p 4000 -f app/main.py\n</code></pre></p> <p>This command starts a gRPC server that serializes the <code>Definitions</code> object from <code>app/main.py</code> and serves it to the webserver and daemon. This architecture separates orchestration infrastructure (webserver/daemon) from business logic (user code), enabling independent scaling and deployment.</p> <p>See \u00a72.1.1 for detailed Docker service configuration.</p>"},{"location":"data-pipeline-processing/data_pipeline_processing/#314-run-coordination","title":"3.1.4 Run Coordination","text":"<p>OMVision uses the QueuedRunCoordinator to manage job execution, defined in <code>dagster-prod.yaml</code>:</p> <pre><code>run_coordinator:\n  module: dagster.core.run_coordinator\n  class: QueuedRunCoordinator\n</code></pre> <p>Execution Flow:</p> <ol> <li>When a job is launched (via schedule, sensor, or manual trigger), the webserver creates a run and places it in a queue</li> <li>The <code>dagster_daemon</code> service polls the queue and dequeues runs for execution</li> <li>Runs are launched via the EcsRunLauncher, which creates ephemeral ECS tasks:</li> </ol> <pre><code>run_launcher:\n  module: dagster_aws.ecs\n  class: EcsRunLauncher\n  config:\n    include_sidecars: true\n    secrets_tag: \"\"\n</code></pre> <p>Each job run executes in an isolated ECS task using the same container image (<code>deal_flow_code</code>). This provides:</p> <ul> <li>Isolation: Failures in one run don't affect others</li> <li>Scalability: Multiple runs can execute concurrently across ECS cluster</li> <li>Resource control: ECS enforces CPU/memory limits per run</li> </ul> <p>Schedules:</p> <p>Jobs are scheduled via cron expressions defined in <code>app/schedules/main.py</code>:</p> Schedule Job Cron Execution Time <code>accern_ingest</code> <code>ingest_signals_from_accern</code> <code>0 15 * * *</code> Daily at 3:00 PM UTC <code>emails_ingest</code> <code>ingest_signals_from_emails</code> <code>0 15 * * *</code> Daily at 3:00 PM UTC <code>harmonic_ingest</code> <code>ingest_companies_from_searches</code> <code>0 15 * * *</code> Daily at 3:00 PM UTC <code>harmonic_people_ingest</code> <code>ingest_people_from_searches</code> <code>0 15 * * *</code> Daily at 3:00 PM UTC <code>data_persistor</code> <code>persist_custom_columns_data</code> <code>0 18 * * *</code> Daily at 6:00 PM UTC <code>company_classifier</code> <code>classify_ingested_companies</code> <code>30 18 * * *</code> Daily at 6:30 PM UTC <p>Execution Sequence:</p> <p>The schedule timing ensures proper sequencing:</p> <ul> <li>Signal ingestion and direct searches execute at 3:00 PM</li> <li>Sensors trigger entity extraction jobs upon successful ingestion (3:00-5:00 PM)</li> <li>Custom column persistence runs at 6:00 PM (after entity processing)</li> <li>Classification runs at 6:30 PM (after new companies are stored)</li> </ul> <p>Storage Configuration:</p> <p>All orchestration metadata (run history, logs, schedules) is stored in PostgreSQL:</p> <pre><code>run_storage:\n  module: dagster_postgres.run_storage\n  class: PostgresRunStorage\n\nevent_log_storage:\n  module: dagster_postgres.event_log\n  class: PostgresEventLogStorage\n\nschedule_storage:\n  module: dagster_postgres.schedule_storage\n  class: PostgresScheduleStorage\n</code></pre> <p>This centralized storage enables the webserver to display run history and logs while the daemon manages execution state.</p>"},{"location":"data-pipeline-processing/data_pipeline_processing/#32-data-flow-stages","title":"3.2 Data Flow Stages","text":"<p>This section documents the five sequential stages through which data flows in OMVision, transforming raw external signals into fully enriched, classified, and stored entities ready for analysis. Each stage builds upon the previous one, progressively refining data quality and adding business intelligence.</p> <pre><code>graph LR\n    A[Signal Ingestion] --&gt; B[Entity Extraction]\n    B --&gt; C[Data Enrichment]\n    C --&gt; D[Classification]\n    D --&gt; E[Persistence]\n\n    style A fill:#e1f5ff\n    style B fill:#fff4e1\n    style C fill:#ffe1f5\n    style D fill:#f5e1ff\n    style E fill:#e1ffe1</code></pre> <p>The pipeline processes three distinct data sources:</p> <ul> <li>Accern: News articles and funding events with structured entity/event fields</li> <li>Gmail: Newsletter emails containing company announcements</li> <li>Harmonic Search: Pre-qualified companies from saved searches</li> </ul>"},{"location":"data-pipeline-processing/data_pipeline_processing/#321-signal-ingestion","title":"3.2.1 Signal Ingestion","text":"<p>Signal ingestion is the entry point for all external data. Signals represent raw, unprocessed records from data sources that potentially mention early-stage companies or founders. Each of the three signal types has its own ingestion pathway optimized for its unique data structure and availability.</p>"},{"location":"data-pipeline-processing/data_pipeline_processing/#accern-signal-ingestion","title":"Accern Signal Ingestion","text":"<p>Datasource Overview</p> <p>Accern is a portfolio company of OMVC that uses NLP and ML to identify relevant signals across wide data sets, capturing hidden trends in venture funding, partnerships, and company developments. Accern delivers data through use-case-specific channels, each representing a distinct topical feed (e.g., \"real-time venture deal flow\" or \"co-investor tracking\").</p> <p>OMVision maintains three active Accern channels, each with a dedicated API endpoint and authentication token. Channel configuration is stored in <code>app/constants/data_sources.py</code>:</p> <pre><code>Channel(\n    api_key=\"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9...\",\n    api_endpoint=\"feed/real-time-venture-deal-flow-bcc2d312-vectr\"\n),\nChannel(\n    api_key=\"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9...\",\n    api_endpoint=\"feed/deal-flow-fund-i-co-investor-tracking-6706ac78-vectr\"\n),\nChannel(\n    api_key=\"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9...\",\n    api_endpoint=\"feed/deal-flow-fund-ii-co-investor-tracking-e1c5e74b-vectr\"\n)\n</code></pre> <p>Ingestion Process</p> <p>The <code>ingest_signals_from_accern</code> job (in <code>app/jobs/ingest_signals_from_accern.py</code>) orchestrates the following workflow:</p> <p>1. Fetch Source Metadata (<code>fetch_source_from_db</code>)</p> <p>Retrieves the \"Accern\" data source record from the database, including all associated channels with their API credentials. The source metadata links ingested signals to their originating source for traceability.</p> <p>2. Ingest Data from Channels (<code>ingest_data_from_channels</code>)</p> <p>For each configured channel, the <code>AccernResource</code> (<code>app/resources/accern_api.py</code>) fetches the last 24 hours of signals:</p> <pre><code>def fetch_feed(self, endpoint: str, token: str) -&gt; AccernFeed:\n    ny_tz = pytz.timezone(\"America/New_York\")\n    end_date = datetime.now(ny_tz).replace(hour=11, minute=0, second=0, microsecond=0)\n    start_date = end_date - timedelta(hours=24)\n\n    endpoint_with_queries = f\"{self.base_url}{endpoint}?token={token}&amp;published_at=[{start_str}..{end_str}]\"\n    response = requests.get(endpoint_with_queries, headers={\"user-agent\": \"dagster\"})\n    return AccernFeed.model_validate(response.json())\n</code></pre> <p>The API returns an <code>AccernFeed</code> object containing metadata about the time window and a list of <code>AccernSignal</code> objects.</p> <p>3. Extract Signals from Feeds (<code>get_signals_from_feeds</code>)</p> <p>Aggregates signals from all channel feeds into a single list. Accern signals contain structured fields that facilitate downstream NER extraction:</p> <pre><code>class AccernSignal(BaseModel):\n    entity_text: list[str]        # Text snippets describing entities\n    event_text: list[str]          # Text snippets describing events\n    entity_name: Optional[str]     # Primary entity mentioned\n    entity_type: Optional[str]     # Entity classification (Company, Person, etc.)\n    doc_title: Optional[str]       # Article/document title\n    doc_url: Optional[str]         # Source URL\n    doc_sentiment: Optional[float]\n    event: Optional[str]           # Event classification (Funding, Acquisition, etc.)\n    published_at: Optional[datetime]\n    # ... additional metadata fields\n</code></pre> <p>4. Deduplicate Signal Context (<code>get_unique_context_from_signals</code>)</p> <p>Accern may deliver duplicate signals across channels or within the 24-hour window. Deduplication keys on a composite of: - <code>entity_text</code> (tuple) - <code>event_text</code> (tuple) - <code>entity_name</code> - <code>entity_type</code> - <code>doc_title</code> - <code>doc_url</code></p> <p>Implementation (<code>app/jobs/ingest_signals_from_accern.py</code>):</p> <pre><code>@op(out={\"unique_contexts\": Out(), \"unique_signals\": Out()})\ndef get_unique_context_from_signals(\n    context, signals: list[AccernSignal]\n) -&gt; tuple[list[dict], list[AccernSignal]]:\n    \"\"\"\n    Extracts context from each signal, focusing on entity and event text, as well as \n    additional metadata. Ensures that the list of signal contexts returned is unique \n    and also returns the corresponding unique signals.\n    \"\"\"\n    unique_contexts = {}\n\n    for signal in signals:\n        # Create composite key from all signal fields\n        context_key = (\n            (\n                tuple(signal.entity_text)\n                if isinstance(signal.entity_text, list)\n                else signal.entity_text\n            ),\n            (\n                tuple(signal.event_text)\n                if isinstance(signal.event_text, list)\n                else signal.event_text\n            ),\n            signal.entity_name,\n            signal.entity_type,\n            signal.doc_title,\n            signal.doc_url,\n        )\n\n        # Store only first occurrence of each unique context\n        if context_key not in unique_contexts:\n            unique_contexts[context_key] = signal\n\n    context.log.info(f\"Unique Accern signals retrieved: {len(unique_contexts)}\")\n\n    unique_signals = list(unique_contexts.values())\n\n    # Convert tuple keys back to dictionary format for downstream processing\n    unique_signal_contexts = [\n        {\n            \"entity_text\": context_key[0],\n            \"event_text\": context_key[1],\n            \"entity_name\": context_key[2],\n            \"entity_type\": context_key[3],\n            \"doc_title\": context_key[4],\n            \"doc_url\": context_key[5],\n        }\n        for context_key in unique_contexts.keys()\n    ]\n\n    return unique_signal_contexts, unique_signals\n</code></pre> <p>Only the first occurrence of each unique context is retained, reducing redundant processing downstream. The operation returns both the unique signal contexts (dictionaries containing the deduplicated fields) and the corresponding unique <code>AccernSignal</code> objects.</p> <p>Why deduplication matters: Without this step, the pipeline would extract entities from the same article multiple times, inflating storage costs and creating duplicate company records. Deduplication at this stage (before expensive OpenAI calls) minimizes API usage and database writes.</p> <p>At this point, the pipeline has unique signal contexts ready for entity extraction. The next stage involves OpenAI-based NER.</p>"},{"location":"data-pipeline-processing/data_pipeline_processing/#email-signal-ingestion","title":"Email Signal Ingestion","text":"<p>Datasource Overview</p> <p>OMVision monitors a dedicated Gmail inbox (<code>newsletters@omvc.co</code>) subscribed to venture capital newsletters, founder announcements, and industry publications. These newsletters frequently mention early-stage companies, funding rounds, product launches, and team expansions\u2014all valuable dealflow signals.</p> <p>Ingestion Process</p> <p>The <code>ingest_signals_from_emails</code> job (in <code>app/jobs/ingest_signals_from_emails.py</code>) follows a simplified workflow compared to Accern, as emails lack the structured entity/event separation:</p> <p>1. Fetch Source Metadata (<code>fetch_source_from_db</code>)</p> <p>Retrieves the \"Gmail\" data source record, which does not have channels (unlike Accern) but is linked to a single service account.</p> <p>2. Fetch Emails (<code>fetch_emails</code>)</p> <p>The <code>GmailResource</code> (configured with a service account JSON key) retrieves all emails from the past 24 hours using the Gmail API:</p> <pre><code>def get_emails(self) -&gt; list[MailMessage]:\n    # Authenticates with service account\n    # Queries messages from last 24 hours\n    # Returns list of MailMessage objects with body, subject, sender, date\n</code></pre> <p>Each <code>MailMessage</code> contains the email body (HTML or plaintext) and metadata.</p> <p>3. Extract Email Context (<code>get_context_from_emails</code>)</p> <p>Email bodies are extracted as strings. Unlike Accern signals with pre-separated <code>entity_text</code> and <code>event_text</code>, email content is unstructured prose. This operation serves as a critical data extraction layer that transforms structured email objects into plain text for NER processing.</p> <p>Implementation (<code>app/jobs/ingest_signals_from_emails.py</code>):</p> <pre><code>@op\ndef get_context_from_emails(emails: list[MailMessage]) -&gt; list[str]:\n    \"\"\"\n    Extracts the body content from each email message.\n\n    Args:\n        emails (list[MailMessage]): A list of email messages.\n\n    Returns:\n        list[str]: A list of email body content as strings.\n    \"\"\"\n    return [f\"{email.body}\" for email in emails]\n</code></pre> <p>Why This Formatting is Needed:</p> <p>This seemingly simple operation serves several critical architectural purposes:</p> <p>1. Type Transformation</p> <p>Converts from structured <code>MailMessage</code> objects to simple strings:</p> <p>Input type: <code>MailMessage</code> (Pydantic model) <pre><code>class MailMessage(BaseModel):\n    sender: Optional[str]  # \"techcrunch@newsletter.com\"\n    date: Optional[str]    # \"2025-11-04\"\n    body: str              # Full email text content\n</code></pre></p> <p>Output type: <code>list[str]</code> (plain text strings)</p> <p>2. Data Abstraction &amp; Pipeline Consistency</p> <p>Creates a uniform interface for downstream NER operations:</p> <ul> <li>Isolates relevant data: Extracts body text from metadata (sender, date)</li> <li>Enables source-agnostic processing: The NER pipeline (<code>get_entities_from_emails</code>, <code>extract_entity_context_from_emails</code>) works with strings regardless of whether they originated from emails, Accern signals, or other sources</li> <li>Single responsibility: Each pipeline stage has a clear, bounded function</li> </ul> <p>3. Format Transformation</p> <p>Before <code>get_context_from_emails</code>: <pre><code>[\n    MailMessage(\n        sender=\"techcrunch@newsletter.com\",\n        date=\"2025-11-04\",\n        body=\"DeepTech raises $10M for healthcare AI diagnostic imaging. The Series A round...\"\n    ),\n    MailMessage(\n        sender=\"venturehacks@newsletter.com\", \n        date=\"2025-11-04\",\n        body=\"Series A spotlight: Five robotics startups to watch including RoboTech...\"\n    )\n]\n</code></pre></p> <p>After <code>get_context_from_emails</code>: <pre><code>[\n    \"DeepTech raises $10M for healthcare AI diagnostic imaging. The Series A round...\",\n    \"Series A spotlight: Five robotics startups to watch including RoboTech...\"\n]\n</code></pre></p> <p>4. Metadata Preservation</p> <p>While the body text is extracted for NER, the original <code>MailMessage</code> objects are preserved throughout the pipeline and later used in <code>combine_emails_and_entities</code>:</p> <pre><code>processed_signals = combine_emails_and_entities(\n    source_data, \n    ingested_emails,      # \u2190 Original MailMessage objects with full metadata\n    filtered_entities,    # \u2190 Extracted entities from body text\n    raw_entities\n)\n</code></pre> <p>This allows the full email metadata (sender, date) to be stored in the database's <code>source_data</code> field for audit and traceability purposes, while the NER pipeline operates only on the relevant text content.</p> <p>5. Simplified Downstream Logic</p> <p>By converting to strings early, all downstream operations can use the same code paths:</p> <pre><code>## Email pipeline (after get_context_from_emails)\nfor email_body in email_body_list:  # Processes simple strings\n    preprocessed_text = openai.preprocess_text(email_body)\n    extracted_entities = openai.get_all_ner_tags(preprocessed_text, vanilla_prompt=True)\n</code></pre> <p>Compare to Accern (which also produces strings after combining entity_text + event_text): <pre><code>## Accern pipeline (after combining fields)\nfor signal in signals:\n    combined_text = entity_text + event_text  # Also produces strings\n    preprocessed_text = openai.preprocess_text(combined_text)\n    extracted_entities = openai.get_all_ner_tags(preprocessed_text, signal, vanilla_prompt=False)\n</code></pre></p> <p>Both pipelines converge on string processing, despite starting with different data structures.</p> <p>6. Reusability</p> <p>The extracted string list is reused for entity context extraction without re-parsing the email objects:</p> <pre><code>signal_contexts = extract_entity_context_from_emails(\n    email_context,        # \u2190 Same list[str] from get_context_from_emails\n    relevant_entities\n)\n</code></pre> <p>Underlying Data Cleaning</p> <p>The actual text cleaning happens earlier in <code>GmailResource.get_emails()</code> (<code>app/resources/mail_client.py</code>):</p> <pre><code>def _clean_message(self, message: str) -&gt; str:\n    \"\"\"Cleans an email message by removing CSS and extracting plain text content.\"\"\"\n    try:\n        message_no_css = re.sub(r\"\\*{.*?}}\\r\\n\", \"\", message, flags=re.DOTALL)\n        soup = BeautifulSoup(message_no_css, \"html.parser\")\n        clean_text = soup.get_text(separator=\" \").strip()\n        return clean_text\n    except:\n        return message\n</code></pre> <p>This method:</p> <ul> <li>Strips CSS styles (regex removes <code>*{...}</code> blocks)</li> <li>Parses HTML with BeautifulSoup and extracts plain text</li> <li>Removes formatting artifacts and normalizes whitespace</li> </ul> <p>By the time <code>get_context_from_emails</code> executes, email bodies are already clean plain text\u2014the operation simply extracts them from the <code>MailMessage</code> objects.</p> <p>What is sent to NER: The entire email body text as a plain string. Preprocessing (\u00a73.2.2) will filter this unstructured content before entity extraction.</p> <p>Architectural Benefits</p> <p>This design pattern exemplifies good software engineering:</p> <ul> <li>Separation of concerns: Email fetching, text extraction, and NER are distinct stages</li> <li>Interface segregation: Downstream operations receive only the data they need (text), not extraneous metadata</li> <li>Reusability: The same NER code processes emails and Accern signals despite different source structures</li> <li>Auditability: Original metadata is preserved separately for database storage</li> </ul> <p>Why no deduplication: Email ingestion does not deduplicate because each email, even if covering the same company, represents a distinct temporal signal. Multiple newsletters mentioning the same funding round on the same day provide reinforcing evidence of relevance.</p>"},{"location":"data-pipeline-processing/data_pipeline_processing/#direct-search-ingestion-harmonic","title":"Direct Search Ingestion (Harmonic)","text":"<p>Datasource Overview</p> <p>Harmonic is a B2B company intelligence platform that provides structured company and people data. Unlike Accern and Gmail, which require NER to discover entities, Harmonic searches return fully identified and enriched entities directly.</p> <p>OMVision leverages Harmonic's saved search functionality: investment team members create searches in Harmonic's UI with specific criteria (e.g., \"Series A companies in healthcare AI with 10-50 employees\"), and OMVision automatically ingests net-new results daily.</p> <p>Company Ingestion</p> <p>The <code>ingest_companies_from_searches</code> job (<code>app/jobs/ingest_companies_from_searches.py</code>) processes companies from saved searches. This pathway bypasses NER entirely because entities are already identified:</p> <p>1. Fetch Source Metadata (<code>fetch_source_from_db</code>)</p> <p>Retrieves the \"Harmonic Search\" data source, which contains the Harmonic API key in its channel configuration.</p> <p>2. Fetch Saved Searches (<code>fetch_all_searches</code>, <code>get_saved_searches_from_harmonic</code>)</p> <p>The <code>HarmonicResource</code> calls <code>harmonic.get_saved_searches(type=SearchType.companies)</code>, which:</p> <ul> <li>Makes a GET request to <code>https://api.harmonic.ai/savedSearches</code></li> <li>Filters searches where <code>name</code> starts with \"DealFlow\" (excluding \"DealFlow - Filter list\")</li> <li>Returns a list of <code>SearchList</code> objects with search name and URN</li> </ul> <p>This naming convention allows team members to designate which searches OMVision should monitor.</p> <p>3. Fetch Companies for Each Search (<code>fetch_all_companies_by_search</code>, <code>get_companies_from_search</code>)</p> <p>For each saved search, the system retrieves associated companies:</p> <pre><code>def get_companies_by_search(self, search_id: str) -&gt; list[CompanyBase]:\n    return self._fetch_all_pages(f\"savedSearches:results/{search_id}\", CompanyBase)\n</code></pre> <p>The <code>_fetch_all_pages</code> method handles pagination, iterating through result pages until <code>page_info[\"has_next\"]</code> is False. Each company is returned as a fully populated <code>CompanyBase</code> object with:</p> <ul> <li>Company name, description, website</li> <li>Founding date, location, ownership status</li> <li>Funding details, stage, headcount</li> <li>People (employees), highlights, socials</li> <li>All available Harmonic metrics</li> </ul> <p>4. Parse Company Metadata (<code>parse_incoming_data</code>)</p> <p>Extracts three parallel structures from the search results:</p> <ul> <li>Company URNs: Unique resource names for Harmonic's internal identification (format: <code>urn:harmonic:company:...</code>)</li> <li><code>SearchWithCompanyIds</code>: Maps each search name to a list of company IDs (Harmonic's integer identifiers)</li> <li><code>CompanyBase</code> objects: Full company data for storage</li> </ul> <p>5. Store Search Metadata (<code>store_harmonic_search_in_db</code>)</p> <p>Creates <code>Search</code> records in the database, linking each search to the Harmonic source and storing <code>source_company_ids</code> to track which companies originated from which search. This traceability enables analysis of search effectiveness.</p> <p>6. Store Companies and Metrics (<code>store_harmonic_companies_in_db</code>, <code>store_company_metrics_in_db</code>)</p> <p>Companies are stored in two related tables:</p> <ul> <li><code>Company</code>: Core attributes (name, description, website, location, tags, etc.)</li> <li><code>CompanyMetric</code>: Time-series and quantitative data (funding, headcount, traction metrics, employee highlights)</li> </ul> <p>Each <code>Company</code> record links to its originating <code>Search</code> via <code>search_id</code>, and each <code>CompanyMetric</code> links to its <code>Company</code> via <code>company_id</code>.</p> <p>7. Add to Watchlist (<code>add_to_harmonic_watchlist</code>)</p> <p>Company URNs are bulk-added to the source-specific Harmonic watchlist (\"DealFlow - Harmonic Search\"):</p> <pre><code>def add_company_to_watchlist(self, watchlist_id: str, company_urns: list[str]):\n    payload = {\"urns\": company_urns}\n    response = requests.post(\n        f\"{self._base_url}watchlists/companies/{watchlist_id}:addCompanies\",\n        json=payload,\n        headers=self._headers\n    )\n</code></pre> <p>This enables ongoing monitoring within Harmonic's platform, ensuring OMVision's tracked companies remain visible to the investment team in Harmonic.</p> <p>People Ingestion</p> <p>The <code>ingest_people_from_searches</code> job mirrors the company flow but processes people entities:</p> <ul> <li>Fetches saved searches with <code>type=SearchType.people</code></li> <li>Retrieves people via <code>get_people_by_search(search_id)</code></li> <li>Stores <code>Person</code> records with LinkedIn URL, experience, education, highlights</li> <li>Adds people URNs to the people watchlist via <code>add_people_to_watchlist</code></li> </ul>"},{"location":"data-pipeline-processing/data_pipeline_processing/#322-entity-extraction","title":"3.2.2 Entity Extraction","text":"<p>Entity extraction transforms unstructured signal text into structured lists of companies and people. This stage is critical for Accern and Gmail signals, which contain entity mentions embedded in prose. Harmonic signals skip this stage entirely as entities are pre-identified.</p> <p>OMVision employs a multi-step NER pipeline powered by OpenAI's GPT models, combining text preprocessing, chunking, structured entity extraction, LLM-based filtering, and context extraction for URL discovery.</p>"},{"location":"data-pipeline-processing/data_pipeline_processing/#the-ner-extraction-process","title":"The NER Extraction Process","text":"<p>1. Preprocess Text</p> <p>Before entity extraction, signal text undergoes LLM-based preprocessing to remove irrelevant content and improve extraction accuracy.</p> <p>Accern Preprocessing</p> <p>Accern signals have structured <code>entity_text</code> and <code>event_text</code> fields. The <code>get_entities_from_signals</code> op in <code>app/jobs/ingest_signals_from_accern.py</code> combines these fields:</p> <pre><code>for signal in signals:\n    entity_text = signal.get(\"entity_text\", [])  # List of strings\n    event_text = signal.get(\"event_text\", [])    # List of strings\n\n    # Ensure both are lists\n    if not isinstance(entity_text, list):\n        entity_text = [entity_text]\n    if not isinstance(event_text, list):\n        event_text = [event_text]\n\n    # Combine into single list\n    combined_text = entity_text + event_text\n\n    # Preprocess with OpenAI\n    preprocessed_text = openai.preprocess_text(combined_text)\n</code></pre> <p>The <code>preprocess_text</code> method (<code>app/resources/open_ai.py</code>) sends the combined list to <code>gpt-4o-mini</code>:</p> <pre><code>def preprocess_text(self, text) -&gt; str:\n    response = self._client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": self._preprocess_text_system_prompt()},\n            {\"role\": \"user\", \"content\": f\"```\\n{text}\\n```\"}\n        ],\n        temperature=0\n    )\n    return response.choices[0].message.content\n</code></pre> <p>Preprocessing Prompt:</p> <pre><code>You are a text filtering AI assistant. Your task is to filter incoming text about companies \nand their details delimited by backticks (```), keeping only the relevant information based \non a provided list of labels. The filtered text will be passed to an extraction function, \nso it's crucial to remove irrelevant information while preserving the important details.\n\nHere is the list of labels to use for filtering:\nperson (people, investors, entrepreneurs, etc.), org (organizations, companies, startups, \nagencies, institutions, etc.), gpe (geopolitical entities like countries, cities, states, etc.)\n\nFollow these steps to filter the text:\n1. Read the input text carefully.\n2. Identify information that relates to the labels provided.\n3. Preserve the original wording and order of the relevant information. the filtered text \n   should be a natural language string.\n4. Do not add any introductory phrases or summaries to the filtered text.\n5. Ensure that the filtered text is coherent and maintains context where necessary.\n6. If you are unsure of the usability of the information, you must include it in the \n   filtered text.\n7. do not delimit the output filtered text\n</code></pre> <p>Example:</p> <p>Input: <pre><code>[\"DeepTech, a healthcare AI startup focusing on diagnostic imaging, raised $10M in Series A\", \n\"The funding round was led by Accel. They compete with Microsoft Azure in the cloud space.\"]\n</code></pre></p> <p>Output: <pre><code>DeepTech, a healthcare AI startup focusing on diagnostic imaging, raised $10M in Series A. \nThe funding round was led by Accel.\n</code></pre></p> <p>What was filtered: The sentence about Microsoft Azure competition was removed as tangential\u2014Microsoft is mentioned as a competitor, not as a primary entity of interest.</p> <p>Why preprocess: Preprocessing reduces noise, lowers token costs for subsequent OpenAI calls, and improves NER accuracy by focusing the model on entity-relevant content. The prompt is conservative (instruction #6: \"If you are unsure...include it\") to avoid over-filtering.</p> <p>Email Preprocessing</p> <p>Email signals follow a similar but simpler flow in <code>app/jobs/ingest_signals_from_emails.py</code>:</p> <pre><code>for email_body in email_body_list:\n    # Email body is already a single string\n    preprocessed_text = openai.preprocess_text(email_body)\n</code></pre> <p>No field combination is needed. The entire email body (already a string) is preprocessed with the same prompt.</p> <p>2. Extract NER Tags</p> <p>After preprocessing, the text is passed to OpenAI for structured entity extraction. This is where Accern and Email pipelines diverge in complexity.</p> <p>Accern NER Extraction (<code>get_all_ner_tags</code> with <code>vanilla_prompt=False</code>)</p> <p>The <code>get_entities_from_signals</code> op passes both the preprocessed text and the original signal metadata to OpenAI:</p> <pre><code>extracted_entities = openai.get_all_ner_tags(\n    preprocessed_text,           # Filtered text from preprocessing\n    signal,                      # Original signal dict with metadata\n    vanilla_prompt=False         # Use metadata-enriched prompt\n)\n</code></pre> <p>Why pass signal metadata? Accern signals contain contextual hints that improve extraction accuracy:</p> <ul> <li><code>doc_title</code>: Article headline provides topical context</li> <li><code>doc_url</code>: Source domain indicates credibility</li> <li><code>entity_name</code>: Primary entity mentioned (disambiguation)</li> <li><code>entity_type</code>: Entity classification hint (Company, Person, etc.)</li> </ul> <p>Inside <code>get_all_ner_tags</code> (<code>app/resources/open_ai.py</code>):</p> <p>Step 2a: Chunk the Preprocessed Text</p> <p>Long texts are split into overlapping chunks to respect OpenAI's context window:</p> <pre><code>def _get_chunks_from_text(self, text: str, overlap: int = 50) -&gt; list[int]:\n    tokens = self._encoding.encode(text, disallowed_special=())\n    chunk_size = 1200  # tokens\n    token_chunks = []\n\n    for i in range(0, len(tokens), chunk_size - overlap):\n        chunk = tokens[i : i + chunk_size]\n        token_chunks.append(chunk)\n\n    return token_chunks\n</code></pre> <p>Chunking parameters:</p> <ul> <li>Maximum chunk size: 1200 tokens</li> <li>Overlap: 50 tokens between consecutive chunks</li> <li>Purpose: Prevent entities spanning chunk boundaries from being missed</li> </ul> <p>Example: <pre><code>Full text: 1500 tokens\n\u2192 Chunk 1: tokens 0-1200 (1200 tokens)\n\u2192 Chunk 2: tokens 1150-1500 (350 tokens)\n         \u2191 50-token overlap with Chunk 1\n</code></pre></p> <p>Step 2b: Extract Entities from Each Chunk</p> <p>For each chunk, three messages are sent to <code>gpt-4o-2024-08-06</code>:</p> <p>Message 1: System Message (role definition) <pre><code>You are an expert in Natural Language Processing. Your task is to identify common Named \nEntities (NER) in a given natural language signal text. The possible common Named Entities \n(NER) types are exclusively: (person (people, investors, entrepreneurs, etc.), org \n(organizations, companies, startups, agencies, institutions, etc.), gpe (geopolitical \nentities like countries, cities, states, etc.)).\n</code></pre></p> <p>Message 2: Assistant Example (one-shot learning) <pre><code>EXAMPLE:\n    Text: 'In Germany, in 1440, goldsmith Johannes Gutenberg invented the movable-type \n    printing press. His work led to an information revolution and the unprecedented \n    mass-spread of literature throughout Europe.'\n    {\n        \"person\": [\"Johannes Gutenberg\"],\n        \"org\": [],\n        \"gpe\": [\"Germany\", \"Europe\"]\n    }\n--\n</code></pre></p> <p>Message 3: User Message (actual request)</p> <p>When <code>vanilla_prompt=False</code> (Accern), the prompt includes signal metadata:</p> <pre><code>def _user_message(self, text: str, signal: dict, vanilla_prompt: bool) -&gt; str:\n    if vanilla_prompt:\n        # Email version (no metadata)\n        return f\"```\\n{text}\\n```\"\n    else:\n        # Accern version (with metadata)\n        entity_name = signal.get(\"entity_name\", \"\")\n        entity_type = signal.get(\"entity_type\", \"\")\n        doc_title = signal.get(\"doc_title\", \"\")\n        doc_url = signal.get(\"doc_url\", \"\")\n\n        return f\"\"\"\n            Given the source text below, extract named entities.\n\n            Context:\n            - Primary entity: {entity_name}\n            - Entity type: {entity_type}\n            - Document title: {doc_title}\n            - Source: {doc_url}\n\n            Text to analyze:\n            ```\n            {text}\n            ```\n        \"\"\"\n</code></pre> <p>Why metadata improves extraction:</p> <p>Without metadata: <pre><code>Text: \"The company raised $10M from Accel.\"\nEntities: [\"Accel\"]  # Ambiguous which company\n</code></pre></p> <p>With metadata: <pre><code>Text: \"The company raised $10M from Accel.\"\nContext: entity_name: \"DeepTech\", entity_type: \"Company\", doc_title: \"DeepTech Secures Series A\"\nEntities: [\"DeepTech\", \"Accel\"]  # Clear primary entity + investor\n</code></pre> Note: This logic was put inplace to take advantage of Accern's metadata. However, this metadata actually does not usually have an entity name like \"Accel\". The most common entity name would be \"Fintech Industry\", which wouldnt be helpful for our LLM.</p> <p>Step 2c: Structured Output</p> <p>OpenAI is forced to return JSON matching the <code>OpenAiNerTags</code> schema:</p> <pre><code>response = self._client.beta.chat.completions.parse(\n    model=\"gpt-4o-2024-08-06\",\n    messages=messages,\n    temperature=0,\n    response_format=OpenAiNerTags  # Pydantic schema\n)\n</code></pre> <pre><code>class OpenAiNerTags(BaseModel):\n    person: list[str]  # [\"Jane Smith\", \"John Doe\"]\n    org: list[str]     # [\"DeepTech\", \"Accel\", \"Index Ventures\"]\n    gpe: list[str]     # [\"San Francisco\", \"New York\"]\n</code></pre> <p>Step 2d: Combine Results from All Chunks</p> <p>If the text was chunked, results are merged:</p> <pre><code>combined_ner_tags = OpenAiNerTags(person=[], org=[], gpe=[])\n\nfor ner_tags in ner_tags_for_all_chunks:\n    combined_ner_tags.person.extend(ner_tags.person)\n    combined_ner_tags.org.extend(ner_tags.org)\n    combined_ner_tags.gpe.extend(ner_tags.gpe)\n\nreturn combined_ner_tags\n</code></pre> <p>Duplicates across chunks are not removed at this stage\u2014that happens during filtering.</p> <p>Email NER Extraction (<code>get_all_ner_tags</code> with <code>vanilla_prompt=True</code>)</p> <p>The <code>get_entities_from_emails</code> op in <code>app/jobs/ingest_signals_from_emails.py</code> extracts entities without metadata:</p> <pre><code>extracted_entities = openai.get_all_ner_tags(\n    preprocessed_text,\n    vanilla_prompt=True  # Simple prompt, no signal context\n)\n</code></pre> <p>The user message is just the text wrapped in backticks:</p> <pre><code>[preprocessed email text]\n</code></pre> <p>Why no metadata for emails: Email signals lack structured metadata fields like <code>entity_name</code> or <code>entity_type</code>. The text itself must provide all context.</p> <p>Summary of NER Labels</p> <p>OMVision extracts three entity types:</p> <ul> <li>person: People (founders, investors, entrepreneurs, executives)</li> <li>org: Organizations (companies, startups, venture firms, institutions)</li> <li>gpe: Geopolitical entities (countries, cities, states)</li> </ul> <p>These labels are defined in <code>OpenAIResource.labels</code> and used consistently across preprocessing, extraction, and filtering.</p> <p>3. Filter Entities with LLM</p> <p>Raw NER extraction often captures large corporations, government institutions, and celebrities\u2014entities irrelevant to early-stage dealflow. The <code>filter_ner_tags</code> method (<code>app/resources/open_ai.py</code>) applies an LLM-based filter to remove these.</p> <p>The <code>get_entities_from_signals</code> and <code>get_entities_from_emails</code> ops call:</p> <pre><code>filtered_entities = openai.filter_ner_tags(\n    preprocessed_text,      # Same text used for extraction\n    extracted_entities      # Unfiltered OpenAiNerTags\n)\n</code></pre> <p>Filter Prompt (sent to <code>gpt-4o-2024-08-06</code>):</p> <pre><code>You are an entity filtering AI assistant. There is a source text from which entities have \nbeen extracted; your task is to use the filtering criteria given below to remove entities \nfrom the original list of entities using the source text as context.\n\nIf you are unsure about the entity, retain it. Return ONLY the filtered entities that PASS \nthe given criteria.\n\nEach entity can be one of many different types. The description for the different entity types:\nperson (people, investors, entrepreneurs, etc.), org (organizations, companies, startups, \nagencies, institutions, etc.), gpe (geopolitical entities like countries, cities, states, etc.)\n\nFollow these filtering criteria to eliminate entities from the original list:\n1) Remove entities that may refer to big companies or major-tech firms like Meta, Google, \n   OpenAI, Disney, JP Morgan etc.\n2) Remove entities that refer to public or government-owned institutions (e.g., European \n   Investment Bank)\n3) Remove entities that refer to celebrities or public figures\n\n[Examples with input/output pairs demonstrating filtering]\n</code></pre> <p>Example:</p> <p>Input: <pre><code>Source text: DeepTech, a healthcare AI startup, raised $10M in Series A. The funding round \nwas led by Accel and Index Ventures. CEO Jane Smith previously worked at Google and Microsoft.\n\nExtracted entities: \n{\n    \"person\": [\"Jane Smith\"],\n    \"org\": [\"DeepTech\", \"Accel\", \"Index Ventures\", \"Google\", \"Microsoft\"],\n    \"gpe\": []\n}\n</code></pre></p> <p>Output: <pre><code>{\n    \"person\": [\"Jane Smith\"],\n    \"org\": [\"DeepTech\", \"Accel\", \"Index Ventures\"],\n    \"gpe\": []\n}\n</code></pre></p> <p>Why filtered:</p> <ul> <li>Google and Microsoft are major tech firms \u2192 Removed (criterion #1)</li> <li>Jane Smith is not a celebrity \u2192 Retained</li> <li>DeepTech is a startup \u2192 Retained</li> <li>Accel and Index Ventures are VCs, not major corporations \u2192 Retained</li> </ul> <p>Why this filter matters: Early removal of large corporations reduces downstream processing costs (URL search, Harmonic enrichment) and prevents these entities from polluting the database. This is an aggressive first pass; more sophisticated filtering happens in \u00a73.2.3.</p> <p>Note: Both <code>extracted_entities</code> (raw) and <code>filtered_entities</code> are preserved for debugging and quality analysis.</p> <p>4. Extract Entity Context</p> <p>The filtered entities now need contextual descriptors to enable URL discovery via Google Search. The <code>extract_entity_context_from_signals</code> and <code>extract_entity_context_from_emails</code> ops call:</p> <pre><code>signal_context = openai.extract_context_from_signal(\n    original_text,          # ORIGINAL entity_text + event_text (not preprocessed)\n    filtered_entities       # Filtered OpenAiNerTags\n)\n</code></pre> <p>Why use original (unpreprocessed) text: Preprocessing removed tangential details, but those details are valuable for creating descriptive search queries. For example:</p> <p>Preprocessed: \"DeepTech raised $10M\" Original: \"DeepTech, a healthcare AI startup focusing on diagnostic imaging, raised $10M\"</p> <p>The descriptors \"healthcare AI\" and \"diagnostic imaging\" are crucial for constructing a Google query like \"DeepTech healthcare AI website\".</p> <p>Context Extraction Prompt (sent to <code>gpt-4o-2024-08-06</code>):</p> <pre><code>You are a content extraction assistant. A source text and corresponding list of entities will \nbe given to you. Your task is to extract links and descriptors of entities from the given \nsource text.\n\nTo aid you in your task, the definition for different entity types is mentioned below:\nperson (people, investors, entrepreneurs, etc.), org (organizations, companies, startups, \nagencies, institutions, etc.), gpe (geopolitical entities like countries, cities, states, etc.)\n\nFollow the following instructions while performing the task:\n1) Extract links for the entities only when it is explicitly mentioned in the source text. \n   Return an empty string otherwise.\n2) For each entity, give a list of descriptors (or keywords) related to the entity using the \n   source text as context. Keep in mind that these descriptors will be used downstream for \n   searching the entity on Google, so keep them as generic as possible.\n</code></pre> <p>Input to OpenAI:</p> <pre><code>Source text: [\"DeepTech, a healthcare AI startup focusing on diagnostic imaging, raised $10M \nin Series A\", \"The funding round was led by Accel and Index Ventures\"]\n\nExtracted entities: {\"person\": [\"Jane Smith\"], \"org\": [\"DeepTech\", \"Accel\", \"Index Ventures\"], \n\"gpe\": []}\n</code></pre> <p>Output (<code>OpenAiSignalContext</code>):</p> <pre><code>OpenAiSignalContext(\n    companies=[\n        OpenAiEntityContext(\n            name=\"DeepTech\",\n            descriptors=[\"healthcare AI startup\", \"diagnostic imaging\", \"Series A funding\"],\n            link=\"\"  # No URL explicitly mentioned in text\n        ),\n        OpenAiEntityContext(\n            name=\"Accel\",\n            descriptors=[\"venture capital\", \"Series A investor\"],\n            link=\"\"\n        ),\n        OpenAiEntityContext(\n            name=\"Index Ventures\",\n            descriptors=[\"venture capital\", \"Series A investor\"],\n            link=\"\"\n        )\n    ],\n    people=[\n        OpenAiEntityContext(\n            name=\"Jane Smith\",\n            descriptors=[\"CEO\", \"DeepTech\"],\n            link=\"\"\n        )\n    ]\n)\n</code></pre> <p>What this achieves: Each entity now has:</p> <ul> <li>Descriptors: Keywords optimized for Google/LinkedIn search</li> <li>Links: Extracted only if explicitly mentioned in the text (usually empty)</li> </ul> <p>These descriptors are critical for the next step (URL enrichment).</p> <p>5. URL Enrichment</p> <p>The URL enrichment process has two paths:</p> <ol> <li>Match path: If the entity already has a link from context extraction, validate it</li> <li>Fetch path: If no link exists, search Google and find the best match</li> </ol> <p>From <code>app/resources/web_search.py</code>:</p> <pre><code>def match_or_fetch_company_url(self, company: OpenAiEntityContext) -&gt; str:\n    \"\"\"\n    Matches or fetches a company URL based on the company's name and descriptors.\n\n    Args:\n        company: The company entity context.\n\n    Returns:\n        str: The matched or fetched company URL.\n    \"\"\"\n    # Try to match with existing link first\n    matched_url = self._match_entity_with_url(company)\n\n    if not matched_url:\n        # No match found, search Google\n        query = (\n            f\"{company.name} {company.descriptors[0]}\"\n            if company.descriptors\n            else f\"{company.name} website\"\n        )\n        results = self._google_custom_search(query)\n        matched_url = self._find_best_match(\n            results,\n            company.name,\n            company.descriptors[0] if company.descriptors else \"\",\n        )\n\n    return matched_url\n</code></pre> <p>Path 1: Matching with Existing Link</p> <p>If context extraction found a link, validate it using fuzzy matching:</p> <p>From <code>app/resources/web_search.py</code>:</p> <pre><code>def _match_entity_with_url(\n    self,\n    entity: OpenAiEntityContext,\n    entity_type: EntityType = EntityType.org,\n    match_threshold: int = 80,\n):\n    \"\"\"\n    Matches an entity (person or organization) with a URL by performing fuzzy \n    matching on the entity's name and the URL.\n\n    Args:\n        entity: The entity to match.\n        entity_type: The type of the entity (default: EntityType.org).\n        match_threshold: The minimum score required for a match (default: 80).\n\n    Returns:\n        str: The matched URL or an empty string if no match is found.\n    \"\"\"\n    entity_link = \"\"\n\n    if entity_type == EntityType.person:\n        if \"linkedin.com/in\" not in entity.link:\n            return entity_link\n\n    if entity.link:\n        parsed_entity_link = urlparse(entity.link)\n        extracted_name = (\n            self._parse_company_name_from_link(parsed_entity_link)\n            if entity_type == EntityType.org\n            else self._parse_profile_name_from_link(parsed_entity_link)\n        )\n        match_score, _ = self._get_match_scores(extracted_name, \"\", entity.name, \"\")\n\n        if match_score &gt;= match_threshold:\n            entity_link = entity.link\n\n    return entity_link\n</code></pre> <p>Example matching:</p> <p>Input: <pre><code>company = OpenAiEntityContext(\n    name=\"Deepnote\",\n    link=\"deepnote.com\",\n    descriptors=[\"collaborative data notebook\"]\n)\n</code></pre></p> <p>Process:</p> <ol> <li>Parse URL: <code>deepnote.com</code> \u2192 domain name: <code>deepnote</code></li> <li>Fuzzy match: <code>fuzz.partial_ratio(\"deepnote\", \"Deepnote\")</code> \u2192 100</li> <li>Score &gt;= 80, so return <code>deepnote.com</code></li> </ol> <p>For people:</p> <p>Input: <pre><code>person = OpenAiEntityContext(\n    name=\"Jane Smith\",\n    link=\"linkedin.com/in/jane-smith-123\",\n    descriptors=[\"CEO\", \"Deepnote\"]\n)\n</code></pre></p> <p>Process:</p> <ol> <li>Check if link contains <code>linkedin.com/in</code> \u2192 Yes</li> <li>Parse URL: <code>jane-smith-123</code></li> <li>Fuzzy match: <code>fuzz.partial_ratio(\"jane-smith-123\", \"Jane Smith\")</code> \u2192 ~70</li> <li>Score &lt; 80, so return empty string (will trigger Google search)</li> </ol> <p>Path 2: Fetching with Google Search</p> <p>If no valid link exists, search Google and find the best match:</p> <p>From <code>app/resources/web_search.py</code>:</p> <pre><code>def _google_custom_search(self, query, website=None):\n    \"\"\"\n    Performs a Google Custom Search query using the provided search query and \n    optionally limits the search to a specific website.\n\n    Args:\n        query: The search query.\n        website: The website to limit the search to (default: None).\n\n    Returns:\n        list[dict]: A list of search results from Google Custom Search.\n    \"\"\"\n    self._rate_limiter.acquire()\n    if website is not None:\n        res = (\n            self._service.cse()\n            .list(\n                q=query,\n                cx=self.cse_id,\n                siteSearch=website,\n                siteSearchFilter=\"i\",\n            )\n            .execute()\n        )\n    else:\n        res = self._service.cse().list(q=query, cx=self.cse_id).execute()\n\n    results = res.get(\"items\", [])\n    return results\n</code></pre> <p>Resource configuration (from <code>app/main.py</code>):</p> <pre><code>\"google\": WebSearchResource(\n    api_key=os.getenv(\"GOOGLE_SEARCH_API_KEY\"),\n    cse_id=os.getenv(\"GOOGLE_SEARCH_ENGINE_ID\"),\n),\n</code></pre> <p>Rate limiting is enforced to respect Google's API limits (100 searches per minute):</p> <pre><code>def setup_for_execution(self, context: InitResourceContext):\n    \"\"\"\n    Sets up the Google Custom Search API service and the rate limiter for job execution.\n    \"\"\"\n    self._service = build(\"customsearch\", \"v1\", developerKey=self.api_key)\n    self._rate_limiter = RateLimiter(100, 60)  # 100 requests per 60 seconds\n</code></pre> <p>Example Google search query for company:</p> <pre><code>Query: \"Deepnote collaborative data notebook platform\"\n</code></pre> <p>Example Google search query for person:</p> <pre><code>Query: \"Jane Smith CEO Deepnote\"\nWebsite filter: \"linkedin.com/in\"\n</code></pre> <p>Finding the Best Match</p> <p>After getting Google search results, find the best match using fuzzy matching:</p> <p>From <code>app/resources/web_search.py</code>:</p> <pre><code>def _find_best_match(\n    self,\n    results,\n    entity_name: str,\n    entity_descriptor: str,\n    entity_type: EntityType = EntityType.org,\n):\n    \"\"\"\n    Finds the best match for an entity (person or organization) from the search \n    results based on match and similarity scores.\n\n    Args:\n        results: A list of search results.\n        entity_name: The name of the entity to match.\n        entity_descriptor: A descriptor for the entity.\n        entity_type: The type of the entity (default: EntityType.org).\n\n    Returns:\n        str: The URL of the best match.\n    \"\"\"\n    highest_match_score = 0\n    highest_similarity_score = 0\n    best_match_url = \"\"\n\n    for result in results:\n        result_title = result.get(\"title\", \"\")\n        result_link = result.get(\"link\", \"\")\n\n        if result_link:\n            parsed_link = urlparse(result_link)\n            if entity_type == EntityType.person:\n                result_title = result_title.replace(\" | LinkedIn\", \"\")\n                extracted_name_from_link = self._parse_profile_name_from_link(\n                    parsed_link\n                )\n            else:\n                extracted_name_from_link = self._parse_company_name_from_link(\n                    parsed_link\n                )\n\n            match_score, similarity_score = self._get_match_scores(\n                extracted_name_from_link,\n                result_title,\n                entity_name,\n                entity_descriptor,\n            )\n\n            if match_score &gt; highest_match_score:\n                highest_match_score = match_score\n\n                if similarity_score &gt; highest_similarity_score:\n                    highest_similarity_score = similarity_score\n                    best_match_url = (\n                        parsed_link.scheme\n                        + \"://\"\n                        + parsed_link.netloc\n                        + parsed_link.path\n                    )\n\n    return best_match_url\n</code></pre> <p>Fuzzy matching logic (from <code>app/resources/web_search.py</code>):</p> <pre><code>def _get_match_scores(\n    self,\n    profile_name: str,\n    result_title: str,\n    person_name: str,\n    person_descriptor: str,\n    match_threshold: int = 80,\n    similarity_threshold: int = 25,\n):\n    \"\"\"\n    Calculates the match score and similarity score between a profile name and a \n    result title based on fuzzy string matching.\n\n    Args:\n        profile_name: The extracted profile name or company name from the result.\n        result_title: The title of the search result.\n        person_name: The name of the person to match.\n        person_descriptor: The descriptor of the person to match.\n        match_threshold: The minimum score required for a match (default: 80).\n        similarity_threshold: The minimum score required for a similarity match (default: 25).\n\n    Returns:\n        tuple[int, int]: A tuple containing the match score and similarity score.\n    \"\"\"\n    match_score = fuzz.partial_ratio(profile_name.lower(), person_name.lower())\n    if match_score &gt;= match_threshold:\n        similarity_score = fuzz.partial_ratio(\n            person_descriptor.lower(), result_title.lower()\n        )\n        if similarity_score &gt;= similarity_threshold:\n            return match_score, similarity_score\n        else:\n            return match_score, 0\n    return 0, 0\n</code></pre> <p>How the matching algorithm works:</p> <ol> <li>Match score: Fuzzy match between extracted URL name and entity name</li> <li>Must be &gt;= 80 to be considered</li> <li>Similarity score: Fuzzy match between entity descriptor and search result title</li> <li>Must be &gt;= 25 to be considered</li> <li>Used as a tiebreaker when multiple results have high match scores</li> </ol> <p>Example:</p> <p>Google search results for \"Deepnote collaborative data notebook\":</p> <pre><code>results = [\n    {\n        \"title\": \"Deepnote - Collaborative Data Notebook Platform\",\n        \"link\": \"https://deepnote.com\"\n    },\n    {\n        \"title\": \"Deepnote | Crunchbase\",\n        \"link\": \"https://crunchbase.com/organization/deepnote\"\n    },\n    {\n        \"title\": \"Deepnote Review - TechCrunch\",\n        \"link\": \"https://techcrunch.com/deepnote-review\"\n    }\n]\n</code></pre> <p>Scoring:</p> Result Extracted Name Match Score Similarity Score Selected? deepnote.com deepnote 100 95 (title contains \"collaborative data notebook\") Yes crunchbase.com crunchbase 0 N/A No techcrunch.com techcrunch 0 N/A No <p>Best match: <code>https://deepnote.com</code> with match_score=100, similarity_score=95</p> <p>The URL is stored in the entity context's <code>link</code> field.</p> <p>6. Company Filter Based on Filter List</p> <p>After URL enrichment, a final entity-level filter is applied to remove companies on the manual exclusion list. The <code>filter_entities</code> op (<code>app/ops/__init__.py</code>) compares enriched entities against the <code>company_filter_list</code> asset.</p> <p>Filter List Source:</p> <p>The list is maintained in Harmonic as a saved search named \"DealFlow - Filter list\". Companies added to this search are explicitly marked as irrelevant (e.g., large consultancies, media outlets, repeatedly misidentified entities).</p> <p>The <code>company_filter_list</code> asset (<code>app/assets/company_filters.py</code>) fetches this list:</p> <pre><code>@asset\ndef company_filter_list(harmonic: HarmonicResource) -&gt; list[str]:\n    filter_search = harmonic.get_filter_search()  # \"DealFlow - Filter list\"\n    company_ids = harmonic.get_companies_by_search(filter_search.entity_urn)\n    return [company.name for company in company_ids]\n</code></pre> <p>Filtering Logic:</p> <pre><code>def filter_entities(company_names: list[str], entities: list[NerTags]) -&gt; list[NerTags]:\n    filtered_entities = []\n\n    for entity_tags in entities:\n        filtered_org = {\n            company_name: url\n            for company_name, url in entity_tags.org.items()\n            if company_name not in company_names  # Exclude if in filter list\n        }\n\n        filtered_entities.append(\n            NerTags(\n                person=entity_tags.person,  # People are not filtered here\n                org=filtered_org\n            )\n        )\n\n    return filtered_entities\n</code></pre> <p>Why this filter exists: The LLM filter (step 3) removes well-known large corporations, but cannot anticipate domain-specific noise. The manual filter list captures entities that:</p> <ul> <li>Repeatedly appear in signals but are irrelevant (e.g., \"TechCrunch\", \"Bloomberg\")</li> <li>Are misidentified by NER (e.g., \"Ventures\" as a standalone company)</li> <li>Are outside investment scope but pass other filters (e.g., government labs)</li> </ul> <p>This list is continuously maintained by the investment team, improving system accuracy over time.</p> <p>7. Signal Storage</p> <p>The <code>combine_signals_and_entities</code> (Accern) or <code>combine_emails_and_entities</code> (Gmail) op merges all extracted and processed information back into signal objects for storage.</p> <p>Signal Structure:</p> <pre><code>SignalCreate(\n    source_id=source.id,               # Link to Accern/Gmail source\n    source_data=signal.model_dump(),   # Original raw signal JSON (audit trail)\n    raw_entity_tags=raw_entities.model_dump(),    # Unfiltered entities (OpenAiNerTags)\n    ner_tags=filtered_entities.model_dump()       # Filtered entities with URLs (NerTags)\n)\n</code></pre> <p>Each signal now contains:</p> <ul> <li><code>source_data</code>: Original Accern signal JSON or email metadata (preserved for audit/debugging)</li> <li><code>raw_ner_tags</code>: Unfiltered entity lists from OpenAI (for quality analysis)</li> <li><code>ner_tags</code>: Filtered entities with URLs, formatted as:</li> </ul> <pre><code>{\n    \"person\": {\"Jane Smith\": \"https://linkedin.com/in/jane-smith\"},\n    \"org\": {\"DeepTech\": \"https://deeptech.ai\", \"Accel\": \"https://accel.com\"}\n}\n</code></pre> <p>Database Insertion:</p> <p>The <code>store_in_db</code> or <code>store_email_signals_in_db</code> op bulk inserts signals:</p> <pre><code>@op\ndef store_in_db(db: DatabaseResource, all_signals: list[SignalCreate]):\n    parsed_signals = [\n        Signal(\n            source_id=data.source_id,\n            source_data=data.source_data,\n            raw_ner_tags=data.raw_entity_tags.model_dump(),\n            ner_tags=data.entity_tags.model_dump(),\n            source_company_ids=None,  # \u2190 Marker for unenriched signals\n            source_people_ids=None    # \u2190 Marker for unenriched signals\n        )\n        for data in all_signals\n    ]\n    db.bulk_insert_rows(parsed_signals)\n</code></pre> <p>Critical detail: <code>source_company_ids</code> and <code>source_people_ids</code> are set to <code>NULL</code>. This NULL value signals that entity extraction has completed but enrichment has not yet occurred. Downstream enrichment jobs (\u00a73.2.3) query for signals where these fields are NULL to identify work remaining.</p>"},{"location":"data-pipeline-processing/data_pipeline_processing/#323-data-enrichment","title":"3.2.3 Data Enrichment","text":"<p>Data enrichment transforms extracted entity names and URLs into fully detailed company and people records by querying Harmonic's B2B intelligence platform. This stage retrieves comprehensive firmographic data (funding, headcount, location, team composition) that enables investment thesis filtering and classification.</p> <p>Enrichment operates on signals created in \u00a73.2.2, processing companies and people separately through parallel jobs. The workflow combines name-based searching, URL-based enrichment, and investment criteria filtering to produce the final set of qualified entities.</p>"},{"location":"data-pipeline-processing/data_pipeline_processing/#company-enrichment-workflow","title":"Company Enrichment Workflow","text":"<p>The <code>ingest_companies_from_signals</code> job (<code>app/jobs/ingest_companies_from_signals.py</code>) orchestrates an eight-step process detailed in <code>company_enrichment_flow.md</code>:</p> <p>1. Fetch Signals (<code>get_all_signals_from_source</code>)</p> <p>Retrieves signals for the specified source (Accern or Gmail) where <code>source_company_ids</code> is NULL:</p> <pre><code>signals = db.fetch_data(Signal.source_company_ids, None)\nparsed_signals = []\n\nfor signal in signals:\n    if data_source.id == signal.source_id:\n        parsed_signals.append(SignalWithTags(id=signal.id, ner_tags=signal.ner_tags))\n</code></pre> <p>These represent signals with extracted entities (from \u00a73.2.2) awaiting enrichment.</p> <p>2. Search Companies by Name (<code>search_companies_with_harmonic</code>)</p> <p>For each unique company name in the signal NER tags, the system performs a name-based search in Harmonic:</p> <pre><code>unique_company_names = set()\nfor signal in signals:\n    if signal.ner_tags:\n        for company_name in signal.ner_tags.org.keys():\n            unique_company_names.add(company_name)\n\ncompany_search_results = {}\nfor company_name in unique_company_names:\n    company_search_results[company_name] = harmonic.search_and_match_company(company_name)\n</code></pre> <p>How <code>search_and_match_company</code> works (<code>app/resources/harmonic_api.py</code>):</p> <pre><code>def search_and_match_company(self, company_name: str) -&gt; Optional[CompanyBase]:\n    search_results = self.conduct_search(company_name)\n\n    if search_results:\n        for company in search_results:\n            if company.name == company_name:  # Exact match\n                return company\n\n    return None\n</code></pre> <p>The <code>conduct_search</code> method:</p> <ol> <li>Makes a POST request to <code>https://api.harmonic.ai/search/companies_by_keywords</code></li> <li>Sends <code>{\"keywords\": company_name}</code> as the request body</li> <li>Returns a list of matching companies (Harmonic may return multiple results if companies share names)</li> <li>Searches the results for an exact name match</li> <li>Returns the first exact match if found, otherwise <code>None</code></li> </ol> <p>Important: Every company goes through this name search, regardless of whether a URL was found in \u00a73.2.2. URLs are used later to override name matches when available.</p> <p>3. Parse Matched Companies (<code>parse_matched_companies</code>)</p> <p>This operation makes the critical decision about which companies need URL-based enrichment:</p> <pre><code>for signal in signals:\n    companies_to_be_enriched = []\n    companies_matched = []\n\n    if signal.ner_tags:\n        for company_name, company_url in signal.ner_tags.org.items():\n            matched_company = harmonic_search_results[company_name]\n\n            raw_company = CompanyBase(\n                website={\"url\": company_url},\n                name=company_name\n            )\n\n            # Decision logic\n            if company_url or matched_company is None:\n                companies_to_be_enriched.append(raw_company)\n            else:\n                companies_matched.append(matched_company)\n</code></pre> <p>Decision Tree:</p> <p>A company goes to the \"to enrich\" list if:</p> <ul> <li>The NER tag has a URL (<code>company_url</code> exists), OR</li> <li>No match was found in the name search (<code>matched_company is None</code>)</li> </ul> <p>A company goes to the \"matched/already enriched\" list if:</p> <ul> <li>There is an exact name match from search, AND</li> <li>The NER tag has NO URL</li> </ul> <p>Key Insight: If a URL exists in the NER tags, the system assumes the name search might not be accurate enough. It prefers to enrich by URL for better precision. If there's no URL and no name match, the system still attempts enrichment by name (with an empty URL string).</p> <p>4. Enrich by URL (<code>enrich_companies_with_harmonic</code>)</p> <p>For companies in the \"to enrich\" list, the system queries Harmonic by website URL:</p> <pre><code>for signal in signals_with_companies:\n    companies_enriched = []\n    unknown_companies = []\n\n    for company in signal.companies:\n        company_url = company.website[\"url\"]\n\n        if company_url != \"\":\n            enriched_company = harmonic.enrich_company(\"website_url\", company_url)\n\n            if enriched_company is None:\n                unknown_companies.append(company)  # URL not found in Harmonic\n            else:\n                companies_enriched.append(enriched_company)\n        else:\n            # No URL - company goes through as \"unknown\" with just name\n            unknown_companies.append(company)\n</code></pre> <p>How <code>enrich_company</code> works (<code>app/resources/harmonic_api.py</code>):</p> <pre><code>def enrich_company(self, identifier_type: str, identifier_value: str) -&gt; Optional[CompanyBase]:\n    params = {identifier_type: identifier_value}  # {\"website_url\": \"https://deeptech.ai\"}\n\n    try:\n        response = requests.post(\n            f\"{self._base_url}companies\",\n            headers=self._headers,\n            params=params\n        )\n        response.raise_for_status()\n        data = response.json()\n        return CompanyBase(**data)\n    except requests.RequestException as e:\n        log.info(f\"API call failed: {e}\")\n        return None\n</code></pre> <p>The <code>POST /companies</code> endpoint:</p> <ul> <li>Accepts <code>website_url</code>, <code>linkedin_url</code>, or <code>id</code> as identifier types</li> <li>Returns a fully enriched <code>CompanyBase</code> object if found</li> <li>Returns HTTP 404 if the URL is not in Harmonic's database</li> </ul> <p>What \"enriched\" means: A <code>CompanyBase</code> object contains:</p> <ul> <li>Core attributes: name, legal_name, description, contact, founding_date, website_urls, logo_url, ownership_status, location, tags, socials</li> <li>Metrics: stage, headcount, traction_metrics (web traffic, social metrics), funding details, investor URNs, funding_rounds</li> <li>People: employees with roles, LinkedIn profiles, experience, education</li> <li>Highlights: company highlights (partnerships, products) and employee highlights (former employers, skills)</li> </ul> <p>What happens if enrichment fails: Companies that couldn't be enriched (URL not in Harmonic or empty URL) are marked as \"unknown companies\" and stored with minimal information (name and URL only). They are included in the results but typically filtered out in the next step.</p> <p>5. Filter Companies (<code>filter_companies</code>)</p> <p>The filter applies investment thesis criteria to remove companies outside OMVC's target profile:</p> <pre><code>filtered_companies = []\nupdated_signals = []\n\nfor signal in searched_companies + enriched_companies:\n    signal_company_ids = []\n\n    for company in signal.companies:\n        # Filter 1: Has investor URN (company is an investor, not a portfolio company)\n        if company.investor_urn:\n            continue\n\n        # Filter 2: Location not in approved list\n        if company.location:\n            country = company.location.get(\"country\")\n            if country is not None and country not in LOCATION_FILTER_LIST:\n                continue\n\n        # Filter 3: Funding round not in target stages\n        if company.stage:\n            if company.stage not in FUNDING_ROUND_FILTER_LIST:\n                continue\n\n        # Filter 4: Total funding exceeds limit\n        if company.funding:\n            funding_total = company.funding.get(\"funding_total\")\n            if funding_total is not None and funding_total &gt;= FUNDING_AMOUNT_LIMIT:\n                continue\n\n        # Filter 5: Headcount exceeds limit\n        if company.headcount:\n            if company.headcount &gt; COMPANY_HEADCOUNT_LIMIT:\n                continue\n\n        # Company passed all filters\n        filtered_companies.append(CompanyWithSignalId(signal_id=signal.id, **company.model_dump()))\n        signal_company_ids.append(company.id)\n\n    updated_signals.append(SignalWithCompanyIds(id=signal.id, source_company_ids=signal_company_ids))\n</code></pre> <p>Filter Criteria (from <code>app/constants/company_filters.py</code>):</p> <ul> <li>Investor profiles: Companies with <code>investor_urn</code> are classified as investors, not portfolio companies \u2192 Excluded</li> <li>Location: Country must be in <code>LOCATION_FILTER_LIST</code>:   <pre><code>LOCATION_FILTER_LIST = [\n    \"United States\", \"Singapore\", \"Thailand\", \"Australia\", \"Canada\", \n    \"United Arab Emirates\", \"Egypt\", \"Saudi Arabia\", \"New Zealand\", \n    \"Philippines\", \"Indonesia\", \"Malaysia\", \"Hong Kong\", \"Vietnam\", \n    \"Japan\", \"South Korea\"\n]\n</code></pre></li> <li>Funding round: Stage must be in <code>FUNDING_ROUND_FILTER_LIST</code>:   <pre><code>FUNDING_ROUND_FILTER_LIST = [\n    \"PRE_SEED\", \"SEED\", \"SERIES_A\", \"SERIES_B\", \"VENTURE_UNKNOWN\", \"STEALTH\"\n]\n</code></pre>   (Excludes late-stage: Series C+, growth equity, etc.)</li> <li>Total funding: <code>funding_total &lt; $15,000,000</code></li> <li>Headcount: <code>headcount \u2264 50</code> employees</li> </ul> <p>Purpose: These filters enforce OMVC's investment thesis, removing companies that are too mature, too large, geographically misaligned, or are investors themselves rather than operating companies.</p> <p>The operation logs filter breakdown:</p> <pre><code>context.log.info(\n    f\"Filter breakdown - Investors: {investors_filtered}, Location: {location_filtered}, \"\n    f\"Funding round: {round_filtered}, Funding amount: {funding_filtered}, Team size: {team_size_filtered}\"\n)\n</code></pre> <p>This transparency allows monitoring of filter effectiveness and adjustment of criteria over time.</p> <p>6. Update Signals (<code>update_signals_in_db</code>)</p> <p>Signals are updated with the IDs of companies that passed filtering:</p> <pre><code>for updated_signal in updated_signals:\n    db.update_signal(updated_signal.id, {\"source_company_ids\": updated_signal.source_company_ids})\n</code></pre> <p>The <code>source_company_ids</code> field transitions from <code>NULL</code> (unenriched) to a list of Harmonic company IDs (enriched and filtered). This: - Marks the signal as fully processed - Links the signal to specific companies in the database - Enables traceability: \"Which signals produced this company?\"</p> <p>7. Store Companies (<code>store_companies_from_signals_in_db</code>, <code>store_companies_metrics_from_signals_in_db</code>)</p> <p>Companies and their metrics are bulk-inserted into the database:</p> <p>Company Records: <pre><code>companies = [\n    Company(\n        signal_id=company.signal_id,\n        source_company_id=company.id,  # Harmonic's ID\n        name=company.name,\n        legal_name=company.legal_name,\n        description=company.description,\n        contact=company.contact,\n        founding_date=company.founding_date,\n        website_urls=company.website,\n        logo_url=company.logo_url,\n        ownership_status=company.ownership_status,\n        location=company.location,\n        tags=company.tags,\n        socials=company.socials,\n        # ... additional attributes\n    )\n    for company in filtered_companies\n]\ndb.bulk_insert_rows(companies)\n</code></pre></p> <p>Company Metrics (stored in separate table for time-series tracking): <pre><code>company_metrics = [\n    CompanyMetric(\n        company_id=inserted_company.id,  # Foreign key to Company\n        stage=company.stage,\n        headcount=company.headcount,\n        traction_metrics=company.traction_metrics,\n        funding=company.funding,\n        employees=company.people,\n        highlights=company.highlights,\n        employee_highlights=company.employee_highlights,\n        investor_urn=company.investor_urn,\n        funding_rounds=company.funding_rounds\n    )\n    for inserted_company, company in zip(inserted_companies, filtered_companies)\n]\ndb.bulk_insert_rows(company_metrics)\n</code></pre></p> <p>Why separate tables: The <code>Company</code> table contains static attributes (name, description, founding date), while <code>CompanyMetric</code> contains time-varying metrics (funding, headcount, web traffic). This separation supports historical tracking\u2014future ingestion runs can create new <code>CompanyMetric</code> records to track company growth over time.</p> <p>8. Add to Watchlist (<code>add_to_watchlist</code>)</p> <p>Filtered companies are added to the source-specific Harmonic watchlist:</p> <pre><code>@op\ndef add_to_watchlist(harmonic: HarmonicResource, watchlist: Watchlist, \n                     filtered_companies: list[CompanyWithSignalId]):\n    company_urns = [f\"urn:harmonic:company:{company.source_company_id}\" \n                    for company in filtered_companies]\n\n    harmonic.add_company_to_watchlist_by_urls(\n        watchlist_id=watchlist.id,\n        company_urns=company_urns\n    )\n</code></pre> <p>This enables ongoing monitoring within Harmonic's platform\u2014companies tracked by OMVision automatically appear in the investment team's Harmonic workspace for deeper research.</p>"},{"location":"data-pipeline-processing/data_pipeline_processing/#people-enrichment-workflow","title":"People Enrichment Workflow","text":"<p>The <code>ingest_people_from_signals</code> job mirrors the company enrichment flow but processes people entities:</p> <p>1. Fetch Signals: Queries signals where <code>source_people_ids</code> is NULL</p> <p>2-3. Skip Search/Parse: People enrichment does not include a name search phase. It proceeds directly to URL enrichment because people are identified by LinkedIn URLs rather than names (to avoid ambiguity).</p> <p>4. Enrich by LinkedIn URL (<code>enrich_people_with_harmonic</code>):</p> <pre><code>for signal in signals:\n    enriched_people = []\n\n    for person_name, person_url in signal.ner_tags.person.items():\n        if person_url and \"linkedin.com/in\" in person_url:\n            enriched_person = harmonic.enrich_people(\"linkedin_url\", person_url)\n\n            if enriched_person:\n                enriched_people.append(enriched_person)\n</code></pre> <p><code>enrich_people</code> method: <pre><code>def enrich_people(self, identifier_type: str, identifier_value: str) -&gt; Optional[PeopleBase]:\n    params = {identifier_type: identifier_value}  # {\"linkedin_url\": \"https://linkedin.com/in/...\"}\n    response = requests.post(f\"{self._base_url}people\", headers=self._headers, params=params)\n    return PeopleBase(**response.json())\n</code></pre></p> <p>Returns:</p> <ul> <li>Core attributes: first_name, last_name, headline, location, LinkedIn URL</li> <li>Experience: List of work history with company, title, duration</li> <li>Education: Degrees, institutions, fields of study</li> <li>Highlights: Skills, certifications, notable achievements</li> <li>Network: Mutual connections, if available</li> </ul> <p>5. Filter People: People filtering applies location-based criteria:</p> <pre><code>if person.location:\n    country = person.location.get(\"country\")\n    if country not in LOCATION_FILTER_LIST:\n        continue  # Exclude\n</code></pre> <p>Unlike companies, people are not filtered by funding stage or headcount (those are company attributes).</p> <p>6. Update Signals: Sets <code>source_people_ids</code> on signals</p> <p>7. Store People:</p> <pre><code>people = [\n    Person(\n        signal_id=person.signal_id,\n        source_person_id=person.id,  # Harmonic's ID\n        first_name=person.first_name,\n        last_name=person.last_name,\n        headline=person.headline,\n        location=person.location,\n        linkedin_url=person.linkedin_url,\n        experience=person.experience,\n        education=person.education,\n        highlights=person.highlights\n    )\n    for person in filtered_people\n]\ndb.bulk_insert_rows(people)\n</code></pre> <p>8. Add to People Watchlist:</p> <pre><code>harmonic.add_people_to_watchlist(\n    watchlist_id=watchlist.id,\n    people_urns=[f\"urn:harmonic:person:{person.source_person_id}\" for person in filtered_people]\n)\n</code></pre>"},{"location":"data-pipeline-processing/data_pipeline_processing/#324-classification","title":"3.2.4 Classification","text":"<p>Classification assigns a relevance rank to each company, enabling prioritization in the user interface. This stage uses a machine learning model trained on historical feedback to predict which companies are most likely to be investment-worthy based on both quantitative metrics (funding, headcount, web traffic) and qualitative features (company description, highlights, tags).</p> <p>The <code>classify_ingested_companies</code> job (<code>app/jobs/classify_ingested_companies.py</code>) processes unclassified companies through a seven-step feature engineering and prediction pipeline:</p> <p>1. Fetch Unclassified Companies (<code>get_all_unclassified_companies</code>)</p> <p>Queries the database for companies where the <code>rank</code> field is NULL:</p> <pre><code>companies = db.fetch_unclassified_companies()\n</code></pre> <p>Each company is split into two feature sets:</p> <p>Natural Language Features (<code>CompanyNLFeatures</code>):</p> <ul> <li><code>description</code>: Company description text</li> <li><code>tags</code>: Industry/category tags from Harmonic</li> <li><code>highlights</code>: Company highlights (partnerships, products, milestones)</li> <li><code>employee_highlights</code>: Notable employee backgrounds (former employers, skills)</li> </ul> <p>Numerical/Categorical Features (<code>CompanyOtherFeatures</code>):</p> <ul> <li><code>last_funding_type</code>: Most recent funding round (e.g., \"SEED\", \"SERIES_A\")</li> <li><code>country</code>: Company location</li> <li><code>stage</code>: Funding stage</li> <li><code>headcount</code>: Number of employees</li> <li><code>funding_total</code>: Total capital raised</li> <li><code>last_funding_date</code>: Date of most recent funding</li> <li><code>founding_date</code>: Company founding date</li> <li><code>number_of_funding_rounds</code>: Total funding events</li> <li><code>web_traffic_change</code>: 90-day percent change in website traffic</li> </ul> <p>2. Format NL Features (<code>format_company_nl_features</code>)</p> <p>Transforms raw JSON structures into concatenated strings suitable for LLM processing:</p> <p>Tags Formatting: <pre><code>tags_set = set()\nfor tag in tags:\n    display_value = tag.get(\"display_value\", \"\").strip()\n    tag_type = tag.get(\"type\", \"\").strip()\n    if display_value and tag_type:\n        tags_set.add(f\"{display_value} ({tag_type})\")\n\ntags_str = \", \".join(sorted(tags_set))\n# Example output: \"Healthcare (industry), B2B (business_model), SaaS (product_type)\"\n</code></pre></p> <p>Highlights Formatting: <pre><code>company_highlights_list = []\nfor item in company_highlights:\n    category = item.get(\"category\", \"\").strip()\n    text = item.get(\"text\", \"\").strip()\n    if category and text:\n        company_highlights_list.append(f\"{category}: {text}\")\n\ncompany_highlights_str = \"\\n\".join(company_highlights_list)\n# Example output:\n# \"Partnership: Collaboration with Mayo Clinic for diagnostic trials\n# Product: Launched AI-powered imaging platform in Q2 2024\"\n</code></pre></p> <p>Employee Highlights Formatting (with summarization): <pre><code>category_counts = {}\nfor item in employee_highlights:\n    category = item.get(\"category\", \"\")\n    if category:\n        category_counts[category] = category_counts.get(category, 0) + 1\n\nsummary_lines = [f\"{count} employees with '{category}'\" \n                 for category, count in category_counts.items()]\nsummary_str = \"Employee Highlights Summary:\\n\" + \"\\n\".join(summary_lines)\n\nemployee_highlights_str = summary_str + \"\\n\\n\" + \"\\n\".join(individual_highlights)\n# Example output:\n# \"Employee Highlights Summary:\n# 3 employees with 'Former FAANG'\n# 2 employees with 'PhD'\n#\n# Former FAANG: Worked at Google for 5 years as Senior Engineer\n# PhD: Stanford PhD in Computer Vision\"\n</code></pre></p> <p>3. Extract Numerical Features from NL (<code>extract_numerical_features_from_nl</code>)</p> <p>Uses OpenAI <code>gpt-4o-2024-08-06</code> to transform natural language features into numerical ratings. For each company, the LLM is prompted to score four dimensions:</p> <p>Transformation Prompt (defined in <code>app/resources/open_ai.py</code>):</p> <pre><code>You are a venture capital analyst. Given a company's description, highlights, tags, and employee \nhighlights, rate the company on the following dimensions using a scale of 0-10:\n\n1. company_relevance: How relevant is this company to early-stage venture investment? \n   (0 = completely irrelevant, 10 = highly relevant startup)\n\n2. founder_strength: How strong is the founding team based on their backgrounds? \n   (0 = weak/unknown, 10 = exceptional pedigree)\n\n3. investor_relevance: How notable are the company's investors? \n   (0 = no notable investors, 10 = top-tier VCs)\n\n4. team_strength: How strong is the overall team composition? \n   (0 = weak team, 10 = exceptional team)\n\nCompany information:\n- Description: {description}\n- Tags: {tags}\n- Highlights: {highlights}\n- Employee Highlights: {employee_highlights}\n\nReturn your ratings as a JSON object with keys: company_relevance, founder_strength, \ninvestor_relevance, team_strength\n</code></pre> <p>Example Input: <pre><code>Description: DeepTech develops AI-powered diagnostic imaging tools for early cancer detection. \nOur platform analyzes medical scans 10x faster than traditional methods.\n\nTags: Healthcare (industry), B2B (business_model), SaaS (product_type)\n\nHighlights:\nPartnership: Collaboration with Mayo Clinic for diagnostic trials\nProduct: Launched AI-powered imaging platform in Q2 2024\n\nEmployee Highlights Summary:\n3 employees with 'Former FAANG'\n2 employees with 'PhD'\n\nFormer FAANG: Worked at Google for 5 years as Senior Engineer\nPhD: Stanford PhD in Computer Vision\n</code></pre></p> <p>Example Output: <pre><code>{\n    \"company_relevance\": 9,\n    \"founder_strength\": 8,\n    \"investor_relevance\": 7,\n    \"team_strength\": 9\n}\n</code></pre></p> <p>These scores are stored as <code>CompanyExtractedRatingFeatures</code> alongside the company ID.</p> <p>4. Prepare Input DataFrame (<code>prepare_input_dataframe</code>)</p> <p>Merges the LLM-generated ratings with the numerical/categorical features into a single pandas DataFrame:</p> <pre><code>df_transformed = pd.DataFrame(extracted_numerical_features)  # LLM scores\ndf_other = pd.DataFrame(other_features)                      # Raw metrics\n\ndf_all = df_transformed.join(df_other.set_index(\"id\"), on=\"id\")\n</code></pre> <p>Resulting DataFrame schema: <pre><code>| id | company_relevance | founder_strength | investor_relevance | team_strength | \n| last_funding_type | country | stage | headcount | funding_total | last_funding_date | \n| founding_date | number_of_funding_rounds | web_traffic_change |\n</code></pre></p> <p>5. Preprocess Features (<code>preprocess_input_features</code>)</p> <p>Applies feature engineering and handles missing data:</p> <p>Date Transformations: <pre><code># Convert to datetime\ndf[\"last_funding_date\"] = pd.to_datetime(df[\"last_funding_date\"]).dt.tz_localize(None)\ndf[\"founding_date\"] = pd.to_datetime(df[\"founding_date\"]).dt.tz_localize(None)\n\n# Derive temporal features\ndf[\"days_since_funding\"] = (pd.Timestamp(\"today\") - df[\"last_funding_date\"]).dt.days\ndf[\"company_age\"] = ((pd.Timestamp(\"today\") - df[\"founding_date\"]).dt.days).astype(float)\n\n# Drop original date columns\ndf.drop([\"last_funding_date\", \"founding_date\"], axis=1, inplace=True)\n</code></pre></p> <p>Missing Value Imputation: <pre><code>df[\"headcount\"].fillna(0, inplace=True)\ndf[\"funding_total\"].fillna(0, inplace=True)\ndf[\"last_funding_type\"].fillna(\"UNKNOWN\", inplace=True)\ndf[\"country\"].fillna(\"UNKNOWN\", inplace=True)\ndf[\"stage\"].fillna(\"UNKNOWN\", inplace=True)\ndf[\"web_traffic_change\"].fillna(0, inplace=True)\ndf[\"number_of_funding_rounds\"].fillna(0, inplace=True)\n</code></pre></p> <p>Categorical Encoding: <pre><code># Apply predefined mappings\ndf[\"last_funding_type\"] = df[\"last_funding_type\"].map(FUNDING_TYPE_MAPPING)\ndf[\"stage\"] = df[\"stage\"].map(STAGE_MAPPING)\n\n# Label encode country\nle = LabelEncoder()\ndf[\"country\"] = le.fit_transform(df[\"country\"])\n</code></pre></p> <p>Normalization (MinMax scaling): <pre><code>numerical_columns = df.select_dtypes(include=[np.number]).columns\nnumerical_columns = numerical_columns.difference([\"country\", \"id\"])\n\nscaler = MinMaxScaler()\ndf[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n</code></pre></p> <p>Handling Companies with Missing Critical Data:</p> <p>Companies missing temporal features (founding_date, last_funding_date) are split into a separate DataFrame (<code>df_dropped</code>) containing only the four LLM-generated NL features. These will be classified using a secondary model trained exclusively on NL features.</p> <pre><code>df_cleaned = df.dropna()  # Companies with all features \u2192 primary model\ndf_dropped = df[df.isna().any(axis=1)][[\"id\", \"company_relevance\", \"founder_strength\", \n                                         \"investor_relevance\", \"team_strength\"]]  # NL-only \u2192 secondary model\n</code></pre> <p>6. Classify Companies</p> <p>Two classification operations run in parallel:</p> <p>Primary Classification (<code>get_primary_company_classes</code>):</p> <p>Uses the full feature set (NL scores + metrics):</p> <pre><code>@op\ndef get_primary_company_classes(df_input: pd.DataFrame, ml: MLResource) -&gt; list[CompanyClassification]:\n    company_ids = df_input[\"id\"].tolist()\n    df_input = df_input.drop(\"id\", axis=1)\n\n    predictions = ml.primary_classify_companies(df_input)\n\n    return [CompanyClassification(id=cid, rank=pred) \n            for cid, pred in zip(company_ids, predictions)]\n</code></pre> <p>Inside <code>MLResource.primary_classify_companies</code> (<code>app/resources/ml_model.py</code>):</p> <pre><code>def primary_classify_companies(self, companies: pd.DataFrame) -&gt; list[float]:\n    model = joblib.load(\"app/constants/lightgbm_model.pkl\")\n    y_pred_prob = model.predict(companies, num_iteration=model.best_iteration)\n    y_pred = np.argmax(y_pred_prob, axis=1)  # Ordinal class: 0, 1, 2, 3, 4\n    return y_pred.tolist()\n</code></pre> <p>Secondary Classification (<code>get_secondary_company_classes</code>):</p> <p>Uses only NL features for companies missing metrics:</p> <pre><code>def secondary_classify_companies(self, companies: pd.DataFrame) -&gt; list[float]:\n    model = joblib.load(\"app/constants/lightgbm_nan_model.pkl\")\n    y_pred_prob = model.predict(companies, num_iteration=model.best_iteration)\n    y_pred = np.argmax(y_pred_prob, axis=1)\n    return y_pred.tolist()\n</code></pre> <p>Model Architecture:</p> <p>OMVision uses an ordinal classifier wrapping a LightGBM gradient boosting model. Ordinal classification treats rank as an ordered categorical variable (0 &lt; 1 &lt; 2 &lt; 3 &lt; 4) rather than arbitrary classes, improving prediction accuracy for inherently ranked targets.</p> <p>Rank meanings (inferred from use):</p> <ul> <li>0: Very low relevance (likely filtered out in UI)</li> <li>1: Low relevance</li> <li>2: Moderate relevance</li> <li>3: High relevance (worth investigation)</li> <li>4: Very high relevance (priority review)</li> </ul> <p>The model was trained on historical company classifications labeled by the investment team, learning patterns that correlate features with investment attractiveness.</p> <p>7. Update Database (<code>update_company_classes_in_db</code>)</p> <p>Predicted ranks are bulk-updated in the database:</p> <pre><code>for classification in all_classifications:  # primary + secondary\n    db.update_company(classification.id, {\"rank\": classification.rank})\n</code></pre> <p>Companies now have a <code>rank</code> value, enabling the frontend UI to sort and filter by predicted relevance.</p>"},{"location":"data-pipeline-processing/data_pipeline_processing/#325-persistence","title":"3.2.5 Persistence","text":"<p>The final stage synchronizes frontend custom column data (user-generated metadata) with backend storage. Users interact with OMVision's UI to tag companies and people with custom attributes\u2014comments, relevance stage, visibility flags, and list memberships. These annotations must be persisted to the database to maintain consistency across sessions and team members.</p>"},{"location":"data-pipeline-processing/data_pipeline_processing/#why-this-workflow-exists","title":"Why This Workflow Exists","text":"<p>The OMVision frontend (built with React/Supabase) allows users to:</p> <ul> <li>Rank companies manually: Override ML-predicted ranks with human judgment</li> <li>Tag relevance stage: \"In Review\", \"Passed\", \"Declined\", \"Portfolio\"</li> <li>Add comments: Internal notes about due diligence, call outcomes, thesis fit</li> <li>Hide entities: Mark companies/people as irrelevant without deleting (preserves audit trail)</li> <li>Assign to lists: Organize entities into thematic lists (\"Q4 Targets\", \"Healthcare Focus\", etc.)</li> </ul> <p>These custom columns are initially stored in Supabase (the frontend database) but must be synchronized to the PostgreSQL backend (the source of truth for Dagster jobs) to ensure:</p> <ol> <li>Data consistency: Same entity viewed in UI and Dagster has identical metadata</li> <li>Auditability: All user interactions are logged in the backend</li> <li>Cross-functional access: Investment team annotations are visible to data/engineering teams for model retraining</li> </ol>"},{"location":"data-pipeline-processing/data_pipeline_processing/#persistence-workflow","title":"Persistence Workflow","text":"<p>The <code>persist_custom_columns_data</code> job (<code>app/jobs/persist_custom_columns_data.py</code>) runs daily (scheduled at 6:00 PM UTC) to sync frontend data with the backend.</p> <p>Company Custom Columns Workflow:</p> <p>1. Fetch Today's Ingested Companies (<code>get_companies_to_harmonise</code>)</p> <p>Retrieves companies ingested in the past 24 hours:</p> <pre><code>companies = db.fetch_ingested_companies_for_today()\ningested_companies = [\n    CompanyCustomColumns(\n        id=company.id,\n        name=company.name,\n        source_company_id=company.source_company_id,  # Harmonic ID\n        rank=company.rank,\n        relevence_stage=company.relevence_stage,\n        comments=company.comments,\n        is_hidden=company.is_hidden,\n        list_ids=None\n    )\n    for company in companies\n]\n</code></pre> <p>2. Fetch Custom Column Data from Frontend (<code>get_custom_columns_data</code>)</p> <p>Queries Supabase (via the backend database) for matching companies by <code>name</code> and <code>source_company_id</code>:</p> <pre><code>custom_column_data = db.fetch_custom_columns_by_company_name_and_source_company_id(ingested_companies)\n\ncustom_columns = [\n    CompanyCustomColumns(\n        name=row.name,\n        source_company_id=row.source_company_id,\n        id=row.id,  # Backend ID\n        rank=row.rank,\n        relevence_stage=row.relevence_stage,\n        comments=row.comments,\n        is_hidden=row.is_hidden\n    )\n    for row in custom_column_data\n]\n</code></pre> <p>3. Fetch List Memberships:</p> <pre><code>lists_data = db.fetch_list_by_company_name_and_source_company_id(ingested_companies)\n\naggregated_data = defaultdict(list)\nfor name, source_company_id, list_id in lists_data:\n    aggregated_data[(name, source_company_id)].append(list_id)\n\nlists = [\n    CompanyCustomColumns(\n        name=name,\n        source_company_id=source_company_id,\n        list_ids=list_ids\n    )\n    for (name, source_company_id), list_ids in aggregated_data.items()\n]\n</code></pre> <p>4. Update Custom Columns (<code>update_custom_columns</code>)</p> <p>For each newly ingested company, checks if it already exists in the frontend database (matched by <code>name</code> and <code>source_company_id</code>). If so, copies the frontend's custom column values to the backend:</p> <pre><code>for ingested_company in ingested_companies:\n    matching_company = next(\n        (data for data in custom_columns\n         if data.name == ingested_company.name\n         and data.source_company_id == ingested_company.source_company_id),\n        None\n    )\n\n    if matching_company:\n        update_fields = {}\n        if matching_company.rank is not None and ingested_company.rank is None:\n            update_fields[\"rank\"] = matching_company.rank\n        if matching_company.relevence_stage is not None:\n            update_fields[\"relevence_stage\"] = matching_company.relevence_stage\n        if matching_company.comments is not None:\n            update_fields[\"comments\"] = matching_company.comments\n        if matching_company.is_hidden is not None:\n            update_fields[\"is_hidden\"] = matching_company.is_hidden\n\n        if update_fields:\n            db.update_company(ingested_company.id, update_fields)\n</code></pre> <p>Logic: Only non-NULL frontend values overwrite backend values. This preserves backend defaults (e.g., ML-predicted rank) unless explicitly overridden in the UI.</p> <p>5. Update List Memberships (<code>update_lists</code>)</p> <p>Associates companies with their lists:</p> <pre><code>for ingested_company in ingested_companies:\n    matching_lists = next(\n        (data for data in lists\n         if data.name == ingested_company.name\n         and data.source_company_id == ingested_company.source_company_id),\n        None\n    )\n\n    if matching_lists and matching_lists.list_ids:\n        for list_id in matching_lists.list_ids:\n            db.add_company_to_list(ingested_company.id, list_id)\n</code></pre> <p>This creates <code>ListEntityAssociation</code> records linking companies to lists.</p> <p>People Custom Columns Workflow:</p> <p>The people workflow (<code>get_people_to_harmonise</code>, <code>get_custom_columns_data_for_people</code>, <code>update_custom_columns_for_people</code>, <code>update_lists_for_people</code>) mirrors the company flow but operates on <code>Person</code> records. The logic is identical: match by <code>first_name</code>, <code>last_name</code>, and <code>source_person_id</code>, then copy custom columns and list memberships from frontend to backend.</p>"},{"location":"data-pipeline-processing/data_pipeline_processing/#data-flow-summary","title":"Data Flow Summary","text":"<pre><code>Frontend (Supabase)                    Backend (PostgreSQL)\n    \u2502                                       \u2502\n    \u2502  User tags company                    \u2502\n    \u2502  - Rank: 4                            \u2502\n    \u2502  - Stage: \"In Review\"                 \u2502\n    \u2502  - Comment: \"Strong founder\"          \u2502\n    \u2502  - Lists: [\"Q4 Targets\"]              \u2502\n    \u2502                                       \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 6:00 PM UTC \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502\n                                            \u2502\n                persist_custom_columns_data \u2502\n                                            \u2502\n                1. Fetch today's companies  \u2502\n                2. Query frontend for       \u2502\n                   matching entities        \u2502\n                3. Copy custom columns      \u2502\n                4. Associate with lists     \u2502\n                                            \u2502\n                Backend now has frontend    \u2502\n                annotations                 \u2502\n                                            \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502\n        \u25bc\n    Dagster jobs see\n    updated metadata\n    (for model retraining,\n    reporting, etc.)\n</code></pre> <p>Why Daily Sync: The job runs after the classification job (6:30 PM) to ensure newly classified companies immediately receive any pre-existing annotations from the frontend. This prevents data loss if a company is re-ingested or if team members tagged the company in Harmonic's UI before it reached OMVision.</p>"},{"location":"data-pipeline-processing/data_pipeline_processing/#33-job-dependencies","title":"3.3 Job Dependencies","text":"<p>OMVision's jobs form a directed acyclic graph (DAG) where downstream jobs depend on upstream outputs. Understanding these dependencies is critical for debugging, optimizing schedules, and extending the pipeline.</p> <pre><code>graph TB\n    subgraph \"Daily Schedule (3:00 PM UTC)\"\n        A1[ingest_signals_from_accern]\n        A2[ingest_signals_from_emails]\n        A3[ingest_companies_from_searches]\n        A4[ingest_people_from_searches]\n    end\n\n    subgraph \"Triggered by Sensors\"\n        B1[ingest_companies_from_signals]\n        B2[ingest_people_from_signals]\n    end\n\n    subgraph \"Daily Schedule (6:00-6:30 PM UTC)\"\n        C1[persist_custom_columns_data]\n        C2[classify_ingested_companies]\n    end\n\n    A1 --&gt;|SUCCESS sensor| B1\n    A1 --&gt;|SUCCESS sensor| B2\n    A2 --&gt;|SUCCESS sensor| B1\n    A2 --&gt;|SUCCESS sensor| B2\n\n    B1 -.-&gt;|data dependency| C2\n    A3 -.-&gt;|data dependency| C2\n\n    B1 -.-&gt;|data dependency| C1\n    B2 -.-&gt;|data dependency| C1\n    A3 -.-&gt;|data dependency| C1\n    A4 -.-&gt;|data dependency| C1\n\n    style A1 fill:#ffe6e6\n    style A2 fill:#ffe6e6\n    style A3 fill:#ffe6e6\n    style A4 fill:#ffe6e6\n    style B1 fill:#e6f3ff\n    style B2 fill:#e6f3ff\n    style C1 fill:#e6ffe6\n    style C2 fill:#e6ffe6</code></pre> <p>Legend:</p> <ul> <li>Red nodes: Signal ingestion (scheduled)</li> <li>Blue nodes: Entity extraction (sensor-triggered)</li> <li>Green nodes: Post-processing (scheduled)</li> <li>Solid arrows: Direct triggers (sensors)</li> <li>Dashed arrows: Data dependencies (no direct trigger)</li> </ul> <p>Dependency Chains:</p> <ol> <li>Accern \u2192 Entity Extraction \u2192 Classification:</li> <li><code>ingest_signals_from_accern</code> stores signals with extracted entities</li> <li>Sensor triggers <code>ingest_companies_from_signals</code>, which enriches and stores companies</li> <li> <p><code>classify_ingested_companies</code> (scheduled later) classifies those companies</p> </li> <li> <p>Harmonic Searches \u2192 Classification:</p> </li> <li><code>ingest_companies_from_searches</code> directly stores enriched companies</li> <li> <p><code>classify_ingested_companies</code> classifies them</p> </li> <li> <p>All Ingestion \u2192 Persistence:</p> </li> <li><code>persist_custom_columns_data</code> syncs metadata for all companies/people ingested today</li> <li>Depends implicitly on all ingestion jobs completing first</li> </ol> <p>Scheduling Rationale:</p> <ul> <li>3:00 PM: All ingestion jobs run concurrently (independent of each other)</li> <li>3:00-5:00 PM: Entity extraction completes (sensor-triggered)</li> <li>6:00 PM: Persistence runs (assumes extraction complete)</li> <li>6:30 PM: Classification runs (assumes new companies stored)</li> </ul> <p>This staggered timing provides buffer for upstream jobs to complete while avoiding race conditions.</p>"},{"location":"data-pipeline-processing/data_pipeline_processing/#34-signal-processing-jobs","title":"3.4 Signal Processing Jobs","text":"<p>This section details the operational logic of jobs responsible for ingesting and storing raw signals.</p>"},{"location":"data-pipeline-processing/data_pipeline_processing/#341-ingest_signals_from_accern","title":"3.4.1 ingest_signals_from_accern","text":"<p>Purpose: Fetch signals from Accern API, extract entities, enrich with URLs, filter, and store.</p> <p>Op Sequence:</p> <ol> <li><code>accern_source()</code> \u2192 Returns asset <code>source_name=\"Accern\"</code></li> <li><code>fetch_source_from_db(source_name=\"Accern\")</code> \u2192 Returns <code>DataSourceReturn</code></li> <li><code>ingest_data_from_channels(source)</code> \u2192 Returns <code>list[AccernFeed]</code></li> <li>Iterates source channels, calls <code>accern.fetch_feed(endpoint, token)</code></li> <li><code>get_signals_from_feeds(feeds)</code> \u2192 Returns <code>list[AccernSignal]</code></li> <li>Flattens feeds into signals</li> <li><code>get_unique_context_from_signals(signals)</code> \u2192 Returns <code>(list[dict], list[AccernSignal])</code></li> <li>Deduplicates by context tuple</li> <li><code>get_entities_from_signals(contexts)</code> \u2192 Returns <code>(list[OpenAiNerTags], list[OpenAiNerTags])</code></li> <li>Calls <code>openai.preprocess_text</code>, <code>openai.get_all_ner_tags</code>, <code>openai.filter_ner_tags</code> for each context</li> <li><code>extract_entity_context_from_signals(contexts, entities)</code> \u2192 Returns <code>list[OpenAiSignalContext]</code></li> <li>Calls <code>openai.extract_context_from_signal</code> for each</li> <li><code>company_filter_list()</code> \u2192 Returns <code>list[str]</code> (asset)</li> <li><code>enrich_companies_and_people(signal_contexts)</code> \u2192 Returns <code>list[NerTags]</code></li> <li>Calls <code>google.match_or_fetch_company_url</code> and <code>google.match_or_fetch_linkedin_profile</code> for each entity</li> <li><code>filter_entities(filter_list, entities)</code> \u2192 Returns <code>list[NerTags]</code></li> <li><code>combine_signals_and_entities(source, signals, entities, raw_entities)</code> \u2192 Returns <code>list[SignalCreate]</code></li> <li><code>store_in_db(signals)</code> \u2192 Inserts <code>Signal</code> records</li> </ol> <p>Key Logic:</p> <ul> <li>Deduplication: Multiple signals may reference the same article/event; deduplication avoids redundant NER processing</li> <li>Raw vs. filtered entities: Both are stored to enable comparison and debugging</li> <li>URL enrichment happens here: Unlike direct searches, signals don't have URLs upfront</li> </ul> <p>Sensor Trigger:</p> <p>Upon success, the <code>signal_ingestion_from_accern</code> sensor triggers: - <code>ingest_companies_from_signals</code> (with <code>source_name=\"Accern\"</code>) - <code>ingest_people_from_signals</code> (with <code>source_name=\"Accern\"</code>)</p> <p>Important Note: Even though we have a step called <code>enrich_companies_and_people(signal_contexts)</code>, we are not enriching companies with Harmonic data at this step. Enrichment in this job means finding the URL for the company. </p>"},{"location":"data-pipeline-processing/data_pipeline_processing/#342-ingest_signals_from_emails","title":"3.4.2 ingest_signals_from_emails","text":"<p>Purpose: Fetch emails, extract entities, enrich, filter, and store.</p> <p>Op Sequence:</p> <ol> <li><code>gmail_source()</code> \u2192 Returns asset <code>source_name=\"Gmail\"</code></li> <li><code>fetch_source_from_db(source_name=\"Gmail\")</code> \u2192 Returns <code>DataSourceReturn</code></li> <li><code>fetch_emails()</code> \u2192 Returns <code>list[MailMessage]</code></li> <li>Calls <code>gmail.get_emails()</code></li> <li><code>get_context_from_emails(emails)</code> \u2192 Returns <code>list[str]</code></li> <li>Extracts email body text</li> <li><code>get_entities_from_emails(email_bodies)</code> \u2192 Returns <code>(list[OpenAiNerTags], list[OpenAiNerTags])</code></li> <li>Same NER flow as Accern but with <code>vanilla_prompt=True</code></li> <li><code>extract_entity_context_from_emails(bodies, entities)</code> \u2192 Returns <code>list[OpenAiSignalContext]</code></li> <li><code>company_filter_list()</code> \u2192 Returns <code>list[str]</code></li> <li><code>enrich_companies_and_people(signal_contexts)</code> \u2192 Returns <code>list[NerTags]</code></li> <li><code>filter_entities(filter_list, entities)</code> \u2192 Returns <code>list[NerTags]</code></li> <li><code>combine_emails_and_entities(source, emails, entities, raw_entities)</code> \u2192 Returns <code>list[SignalCreate]</code></li> <li><code>store_email_signals_in_db(signals)</code> \u2192 Inserts <code>Signal</code> records</li> </ol> <p>Difference from Accern:</p> <ul> <li>No feed structure; each email is a single signal</li> <li>No deduplication step</li> <li>Uses vanilla OpenAI prompt (no Accern metadata)</li> </ul> <p>Sensor Trigger:</p> <p>Upon success, the <code>signal_ingestion_from_emails</code> sensor triggers:</p> <ul> <li><code>ingest_companies_from_signals</code> (with <code>source_name=\"Gmail\"</code>)</li> <li><code>ingest_people_from_signals</code> (with <code>source_name=\"Gmail\"</code>)</li> </ul>"},{"location":"data-pipeline-processing/data_pipeline_processing/#343-signal-sensors","title":"3.4.3 Signal Sensors","text":"<p>Architecture:</p> <p>Run status sensors monitor specific jobs and trigger downstream jobs upon successful completion. They implement the observer pattern in distributed orchestration.</p> <p><code>signal_ingestion_from_accern</code> Sensor:</p> <pre><code>@run_status_sensor(\n    run_status=DagsterRunStatus.SUCCESS,\n    monitored_jobs=[ingest_signals_from_accern],\n    request_jobs=[ingest_companies_from_signals, ingest_people_from_signals],\n    minimum_interval_seconds=7200,\n)\ndef signal_ingestion_from_accern(context):\n    company_op = get_op_config(\"Accern\")\n    people_op = get_op_config(\"Accern\", PipelineType.people)\n\n    yield RunRequest(\n        job_name=\"ingest_companies_from_signals\",\n        run_key=None,\n        run_config=RunConfig(company_op),\n    )\n    yield RunRequest(\n        job_name=\"ingest_people_from_signals\",\n        run_key=None,\n        run_config=RunConfig(people_op),\n    )\n</code></pre> <p>Behavior:</p> <ul> <li>Trigger condition: <code>ingest_signals_from_accern</code> completes with SUCCESS status</li> <li>Actions: Issues two <code>RunRequest</code> objects to launch downstream jobs</li> <li>Configuration injection: Passes <code>source_name=\"Accern\"</code> and appropriate watchlist config to each job</li> <li>Minimum interval: Won't re-trigger within 2 hours (prevents accidental cascades)</li> </ul> <p>Why Sensors Instead of Dependencies?</p> <p>Sensors provide loose coupling:</p> <ul> <li>Signal ingestion jobs can run independently (easier testing, manual re-runs)</li> <li>Entity extraction can process signals from multiple sources (Accern, Gmail) using the same job definition</li> <li>Failure in one source doesn't block another</li> </ul> <p>Monitoring:</p> <p>Sensors appear in the Dagster UI's \"Sensors\" tab, showing:</p> <ul> <li>Last tick time</li> <li>Trigger count</li> <li>Requested runs</li> </ul>"},{"location":"data-pipeline-processing/data_pipeline_processing/#35-entity-extraction-jobs","title":"3.5 Entity Extraction Jobs","text":"<p>These jobs process signals to extract, enrich, and store companies and people.</p>"},{"location":"data-pipeline-processing/data_pipeline_processing/#351-ingest_companies_from_signals","title":"3.5.1 ingest_companies_from_signals","text":"<p>Purpose: Extract companies from signals, enrich via Harmonic, filter, and store.</p> <p>Op Sequence:</p> <ol> <li><code>fetch_source_from_db(source_name)</code> \u2192 Returns <code>DataSourceReturn</code></li> <li><code>get_source_watchlist(source_name)</code> \u2192 Returns <code>Watchlist</code></li> <li>Fetches \"DealFlow - {source_name}\" watchlist from Harmonic</li> <li><code>get_all_signals_from_source(source)</code> \u2192 Returns <code>list[SignalWithTags]</code></li> <li>Queries signals where <code>source_id</code> matches and <code>source_company_ids IS NULL</code></li> <li><code>search_companies_with_harmonic(signals)</code> \u2192 Returns <code>dict[str, Optional[CompanyBase]]</code></li> <li>Extracts unique company names from <code>SignalWithTags.ner_tags.org</code></li> <li>Calls <code>harmonic.search_and_match_company(name)</code> for each</li> <li><code>parse_matched_companies(signals, search_results)</code> \u2192 Returns <code>(list[SignalWithCompanies], list[SignalWithCompanies])</code></li> <li>companies_to_insert: Exact name match found from search, AND the NER tag has no URL</li> <li>companies_to_enrich: Have URLs, OR not found by name search</li> <li><code>enrich_companies_with_harmonic(companies_to_enrich)</code> \u2192 Returns <code>list[SignalWithCompanies]</code></li> <li>Calls <code>harmonic.enrich_company(\"website_url\", url)</code> for each</li> <li>Marks as \"unknown\" if enrichment fails</li> <li><code>filter_companies(searched, enriched)</code> \u2192 Returns <code>(list[CompanyWithSignalId], list[SignalWithCompanyIds])</code></li> <li>Applies location, stage, funding, headcount, investor filters</li> <li><code>update_signals_in_db(updated_signals)</code> \u2192 Updates <code>Signal.source_company_ids</code></li> <li><code>store_companies_from_signals_in_db(filtered)</code> \u2192 Inserts <code>Company</code> records</li> <li><code>store_companies_metrics_from_signals_in_db(filtered, inserted)</code> \u2192 Inserts <code>CompanyMetric</code> records</li> <li><code>add_to_watchlist(watchlist, filtered)</code> \u2192 Adds companies to Harmonic watchlist</li> </ol> <p>Critical Logic:</p> <ul> <li>Two-phase enrichment: Name search (fallback) \u2192 URL enrichment (main)</li> <li>Filtering:</li> <li>Location: <code>company.location.country IN LOCATION_FILTER_LIST</code></li> <li>Stage: <code>company.stage IN FUNDING_ROUND_FILTER_LIST</code></li> <li>Funding: <code>company.funding.funding_total &lt; 15_000_000</code></li> <li>Headcount: <code>company.headcount &lt;= 75</code></li> <li>Investor: <code>company.investor_urn IS NULL</code></li> <li>Signal update: Links signals to final company IDs for traceability</li> </ul> <p>ECS Configuration:</p> <p>This job has custom resource limits: <pre><code>@job(tags={\"ecs/cpu\": \"1024\", \"ecs/memory\": \"6144\"})\n</code></pre> Allocates 1 vCPU and 6 GB RAM (higher than default) due to: - Large Harmonic API response payloads - Concurrent enrichment of multiple companies - In-memory deduplication of entities</p>"},{"location":"data-pipeline-processing/data_pipeline_processing/#352-ingest_people_from_signals","title":"3.5.2 ingest_people_from_signals","text":"<p>Purpose: Extract people from signals, enrich via Harmonic, and store.</p> <p>Op Sequence:</p> <p>Mirrors <code>ingest_companies_from_signals</code> with people-specific logic:</p> <ol> <li><code>fetch_source_from_db(source_name)</code></li> <li><code>get_source_people_watchlist(source_name)</code> \u2192 Returns <code>PeopleWatchlist</code></li> <li><code>get_empty_signals_from_source(source)</code> \u2192 Returns <code>list[SignalWithTags]</code></li> <li>Queries signals where <code>source_people_ids IS NULL</code></li> <li><code>enrich_people_with_harmonic(signals)</code> \u2192 Returns <code>list[SignalWithPeople]</code></li> <li>Calls <code>harmonic.enrich_people(\"linkedin_url\", url)</code> for each person</li> <li><code>filter_people(enriched)</code> \u2192 Returns <code>(list[SignalWithFilteredPeople], list[SignalWithPeopleIds])</code></li> <li>Currently no filtering logic (placeholder for future criteria)</li> <li><code>update_signals_with_people_ids(updated_signals)</code></li> <li><code>add_to_source_people_watchlist(watchlist, signals)</code></li> <li><code>store_people_from_signals_in_db(filtered)</code> \u2192 Inserts <code>Person</code> records</li> </ol> <p>Differences from Companies:</p> <ul> <li>No URL discovery (LinkedIn URLs come from entity context extraction)</li> <li>No filtering criteria (all enriched people are stored)</li> <li>Simpler flow due to fewer data quality issues</li> </ul>"},{"location":"data-pipeline-processing/data_pipeline_processing/#353-ingest_companies_from_searches","title":"3.5.3 ingest_companies_from_searches","text":"<p>Purpose: Ingest companies from Harmonic saved searches, store, and add to watchlist.</p> <p>Op Sequence:</p> <ol> <li><code>fetch_source_from_db(source_name=\"Harmonic Search\")</code></li> <li><code>get_source_watchlist(source_name)</code> \u2192 Returns <code>Watchlist</code></li> <li><code>get_saved_searches_from_harmonic()</code> \u2192 Returns <code>list[SearchList]</code></li> <li>Fetches searches prefixed with \"DealFlow\" (excluding filter list)</li> <li><code>get_companies_from_search(searches)</code> \u2192 Returns <code>list[SearchWithCompanies]</code></li> <li>Calls <code>harmonic.get_companies_by_search(search_id)</code> for each</li> <li><code>parse_searches_for_watchlist(searches)</code> \u2192 Returns <code>(list[str], list[SearchWithCompanyIds], list[CompanyBase])</code></li> <li>Extracts company URNs, IDs, and full objects</li> <li><code>add_to_harmonic_watchlist(watchlist, urns)</code></li> <li><code>store_harmonic_search_in_db(source, searches)</code> \u2192 Inserts <code>Search</code> records</li> <li><code>store_harmonic_companies_in_db(searches, inserted_searches)</code> \u2192 Inserts <code>Company</code> records</li> <li><code>store_company_metrics_in_db(inserted, all)</code> \u2192 Inserts <code>CompanyMetric</code> records</li> </ol> <p>Key Logic:</p> <ul> <li>Net new results: Harmonic searches are configured to return only new companies since last fetch</li> <li>No filtering: Companies from searches bypass OMVision's filters (assumed pre-filtered by search criteria)</li> <li>Direct enrichment: Companies arrive with full Harmonic data; no URL discovery or enrichment needed</li> </ul>"},{"location":"data-pipeline-processing/data_pipeline_processing/#354-ingest_people_from_searches","title":"3.5.4 ingest_people_from_searches","text":"<p>Purpose: Ingest people from Harmonic saved searches and store.</p> <p>Op Sequence:</p> <p>Mirrors <code>ingest_companies_from_searches</code> for people:</p> <ol> <li><code>fetch_source_from_db(source_name=\"Harmonic Search\")</code></li> <li><code>get_source_people_watchlist(source_name)</code> \u2192 Returns <code>PeopleWatchlist</code></li> <li><code>get_saved_people_searches_from_harmonic()</code> \u2192 Returns <code>list[SearchList]</code></li> <li><code>get_people_from_search(searches)</code> \u2192 Returns <code>list[SearchWithPeople]</code></li> <li><code>parse_searches_for_people_watchlist(searches)</code> \u2192 Returns <code>(list[str], list[SearchWithPeopleIds], list[PeopleBase])</code></li> <li><code>add_to_harmonic_people_watchlist(watchlist, urns)</code></li> <li><code>store_people_search_in_db(source, searches)</code> \u2192 Inserts <code>Search</code> records</li> <li><code>store_harmonic_people_in_db(searches, inserted_searches)</code> \u2192 Inserts <code>Person</code> records</li> </ol>"},{"location":"data-pipeline-processing/data_pipeline_processing/#36-classification-job","title":"3.6 Classification Job","text":"<p>Job: <code>classify_ingested_companies</code></p> <p>Purpose: Apply machine learning models to assign relevance ranks (0-4) to unclassified companies.</p> <p>Op Sequence:</p> <ol> <li><code>get_all_unclassified_companies()</code> \u2192 Returns <code>(pd.DataFrame, pd.DataFrame)</code></li> <li>nl_features: Description, highlights, employee_highlights, traction_metrics</li> <li> <p>other_features: Headcount, funding, stage, location, founding_date, etc.</p> </li> <li> <p><code>format_company_nl_features(nl_features)</code> \u2192 Returns <code>list[CompanyNLFeaturesFormatted]</code></p> </li> <li> <p>Structures NL fields into consistent schema</p> </li> <li> <p><code>extract_numerical_features_from_nl(formatted)</code> \u2192 Returns <code>list[CompanyExtractedRatingFeatures]</code></p> </li> <li>Calls OpenAI API with:<ul> <li>System message: Defines input features and output ratings (0.0-1.0)</li> <li>User message: Provides company NL features</li> </ul> </li> <li> <p>Returns ratings: product_maturity, market_opportunity, founder_strength, technology_moat, traction_growth</p> </li> <li> <p><code>prepare_input_dataframe(extracted, other_features)</code> \u2192 Returns <code>pd.DataFrame</code></p> </li> <li>Merges NL ratings with other features</li> <li> <p>Creates unified feature set</p> </li> <li> <p><code>preprocess_input_features(df)</code> \u2192 Returns <code>(pd.DataFrame, pd.DataFrame)</code></p> </li> <li>Date conversions: Converts dates to timestamps, calculates age/recency</li> <li>Categorical encoding: Maps funding type, stage to integers; label-encodes country</li> <li>Feature scaling: Applies MinMaxScaler to numerical columns</li> <li> <p>Splits:</p> <ul> <li>primary_df: Complete data (no NaN)</li> <li>secondary_df: Incomplete data (has NaN)</li> </ul> </li> <li> <p><code>get_primary_company_classes(primary_df)</code> \u2192 Returns <code>list[CompanyClassification]</code></p> </li> <li>Loads <code>lightgbm_model.pkl</code></li> <li> <p>Predicts ranks using all features</p> </li> <li> <p><code>update_company_classes_in_db(primary_classifications)</code></p> </li> <li> <p>Bulk updates <code>Company.rank</code></p> </li> <li> <p><code>get_secondary_company_classes(secondary_df)</code> \u2192 Returns <code>list[CompanyClassification]</code></p> </li> <li>Loads <code>lightgbm_nan_model.pkl</code></li> <li> <p>Predicts ranks using NL features only</p> </li> <li> <p><code>update_company_classes_in_db(secondary_classifications)</code></p> </li> </ol> <p>Model Details:</p> <ul> <li>Algorithm: LightGBM with ordinal classification wrapper</li> <li>Ordinal classes: 0 (lowest relevance) to 4 (highest relevance)</li> <li>Training data: Historical companies with manual rank assignments from users</li> <li>Features:</li> <li>Numerical: Headcount, funding amount, company age, time since funding</li> <li>Categorical: Stage, funding type, location</li> <li>NL-derived: Product maturity, market opportunity, founder strength, tech moat, traction</li> <li>Evaluation metric: Accuracy (correct rank prediction)</li> </ul> <p>Why OpenAI for Feature Extraction?</p> <p>Traditional feature engineering struggles to quantify qualitative descriptions. OpenAI's language models excel at semantic understanding and can reliably score companies based on textual descriptions, providing features unavailable from structured data alone.</p> <p>Why Two Models?</p> <ul> <li>Primary: Maximizes accuracy when all data available</li> <li>Secondary: Ensures no company is left unclassified due to missing data</li> </ul>"},{"location":"data-pipeline-processing/data_pipeline_processing/#37-data-persistence-jobs","title":"3.7 Data Persistence Jobs","text":""},{"location":"data-pipeline-processing/data_pipeline_processing/#371-persist_custom_columns_data","title":"3.7.1 persist_custom_columns_data","text":"<p>Purpose: Sync user-generated metadata from frontend to backend.</p> <p>Op Sequence:</p> <p>For Companies:</p> <ol> <li><code>get_companies_to_harmonise()</code> \u2192 Returns <code>list[CompanyCustomColumns]</code></li> <li> <p>Fetches companies created today</p> </li> <li> <p><code>get_custom_columns_data(ingested)</code> \u2192 Returns <code>(list[CompanyCustomColumns], list[CompanyCustomColumns])</code></p> </li> <li>Queries frontend DB by <code>(name, source_company_id)</code></li> <li> <p>Returns:</p> <ul> <li>custom_columns: Scalar metadata (relevence_stage, comments, is_hidden)</li> <li>lists: List associations (list_ids)</li> </ul> </li> <li> <p><code>update_custom_columns(ingested, custom_columns)</code></p> </li> <li>Matches ingested companies to frontend data</li> <li> <p>Bulk updates backend <code>Company</code> records</p> </li> <li> <p><code>update_lists(ingested, lists)</code></p> </li> <li>Updates <code>ListEntityAssociation</code> mappings</li> </ol> <p>For People:</p> <ol> <li><code>get_people_to_harmonise()</code> \u2192 Returns <code>list[PersonCustomColumns]</code></li> <li><code>get_custom_columns_data_for_people(ingested)</code></li> <li><code>update_custom_columns_for_people(ingested, custom_columns)</code></li> <li><code>update_lists_for_people(ingested, lists)</code></li> </ol> <p>Data Sync Direction:</p> <p>Frontend \u2192 Backend (unidirectional)</p> <p>Rationale:</p> <p>The frontend serves as the \"source of truth\" for user interactions. The backend must reflect these interactions to:</p> <ul> <li>Enable accurate ML training (user feedback as labels)</li> <li>Maintain data consistency across systems</li> <li>Support analytics on user behavior</li> </ul>"},{"location":"data-pipeline-processing/data_pipeline_processing/#372-upsert_data_sources","title":"3.7.2 upsert_data_sources","text":"<p>Purpose: Initialize or update data source configurations.</p> <p>Op Sequence:</p> <ol> <li><code>get_default_sources()</code> \u2192 Returns <code>list[DataSourceBase]</code></li> <li> <p>Loads default sources from <code>app/constants/data_sources.py</code></p> </li> <li> <p><code>upsert_sources_in_db(default_sources)</code> \u2192 Inserts/updates <code>Source</code> records</p> </li> <li>Uses <code>db.bulk_insert_rows</code> with upsert semantics</li> <li>Updates <code>name</code>, <code>description</code>, <code>base_url</code>, <code>channels</code></li> </ol> <p>Usage:</p> <p>This job typically runs once during initial setup or after modifying source configurations. It ensures the database has the latest source metadata, which other jobs reference via <code>fetch_source_from_db</code>.</p> <p>Default Sources:</p> <ul> <li>Accern: Three channels (venture deal flow, Fund I tracking, Fund II tracking)</li> <li>Gmail: Newsletter monitoring account</li> <li>Harmonic Search: API for saved searches</li> </ul>"},{"location":"data-pipeline-processing/data_pipeline_processing/#summary","title":"Summary","text":"<p>OMVision's data pipeline orchestrates a complex workflow transforming raw signals into actionable investment opportunities. The pipeline's design emphasizes:</p> <ul> <li>Modularity: Each job has a single responsibility, enabling independent testing and maintenance</li> <li>Scalability: Dagster's ECS integration allows horizontal scaling; resource-intensive jobs (entity extraction, enrichment) allocate additional CPU/memory</li> <li>Observability: Centralized logging, run history, and sensor monitoring provide visibility into pipeline health</li> <li>Extensibility: Adding new data sources requires defining new jobs and sensors, but doesn't necessitate modifying existing logic</li> </ul> <p>The combination of Dagster orchestration, OpenAI-powered NER, Harmonic enrichment, and ML classification creates a robust, automated deal sourcing engine that processes thousands of signals daily while surfacing only the most relevant early-stage companies for manual review.</p>"},{"location":"external-integrations/external_integrations/","title":"6. External Integrations","text":"<p>OMVision interfaces with five external APIs and data providers to collect, enrich, and analyze startup information. Each integration serves a distinct role in the data pipeline: Accern and Gmail provide signal sources, Harmonic enriches entity data, Google Custom Search discovers URLs, and OpenAI extracts structured information from unstructured text.</p> <p>This section documents how OMVision authenticates with, consumes data from, and handles errors across all external systems. Integration logic is implemented as Dagster resources (<code>app/resources/</code>), which are instantiated once per job run and injected into operations as needed.</p>"},{"location":"external-integrations/external_integrations/#61-accern-api","title":"6.1 Accern API","text":"<p>Accern is a portfolio company of OMVC that provides NLP-driven intelligence feeds for identifying venture funding events, partnerships, and market signals. Accern delivers data through topically-focused channels, each representing a distinct use case such as \"real-time venture deal flow\" or \"co-investor tracking.\"</p> <p>OMVision maintains three active Accern channels, configured in <code>app/constants/data_sources.py</code>. Each channel has a dedicated API endpoint and JWT authentication token.</p>"},{"location":"external-integrations/external_integrations/#611-authentication-setup","title":"6.1.1 Authentication &amp; Setup","text":"<p>Resource Configuration</p> <p>The <code>AccernResource</code> (<code>app/resources/accern_api.py</code>) manages all interactions with the Accern API:</p> <pre><code>class AccernResource(ConfigurableResource):\n    \"\"\"\n    A resource class for interacting with the Accern API.\n\n    Attributes:\n        base_url (str): The base URL for the Accern API. Default is \"https://app.accern.com/\".\n    \"\"\"\n    base_url: str = \"https://app.accern.com/\"\n</code></pre> <p>The resource is instantiated in <code>app/main.py</code> with configuration from environment variables:</p> <pre><code>\"accern\": AccernResource()\n</code></pre> <p>Channel Configuration</p> <p>Channels are defined in <code>app/constants/data_sources.py</code> with the following structure:</p> <pre><code>DataSourceBase(\n    name=\"Accern\",\n    description=\"Accern API for incoming data feeds\",\n    base_url=\"https://app.accern.com/\",\n    channels=[\n        Channel(\n            api_key=\"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9...\",\n            api_endpoint=\"feed/real-time-venture-deal-flow-bcc2d312-vectr\"\n        ),\n        Channel(\n            api_key=\"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9...\",\n            api_endpoint=\"feed/deal-flow-fund-i-co-investor-tracking-6706ac78-vectr\"\n        ),\n        Channel(\n            api_key=\"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9...\",\n            api_endpoint=\"feed/deal-flow-fund-ii-co-investor-tracking-e1c5e74b-vectr\"\n        ),\n    ],\n)\n</code></pre> <p>Authentication Method</p> <p>Accern uses JWT bearer tokens for authentication. Each channel's <code>api_key</code> is a signed JWT that grants access to a specific feed endpoint. Tokens are passed as query parameters in API requests:</p> <pre><code>GET https://app.accern.com/feed/{endpoint}?token={api_key}&amp;published_at=[{start}..{end}]\n</code></pre> <p>Required Environment Variables</p> <p>None. Channel credentials are hardcoded in <code>data_sources.py</code> and persisted to the database during system initialization via the <code>upsert_data_sources</code> job.</p>"},{"location":"external-integrations/external_integrations/#612-data-ingestion-process","title":"6.1.2 Data Ingestion Process","text":"<p>The <code>ingest_signals_from_accern</code> job (<code>app/jobs/ingest_signals_from_accern.py</code>) orchestrates the following workflow:</p> <pre><code>sequenceDiagram\n    participant Job as ingest_signals_from_accern\n    participant DB as PostgreSQL\n    participant Accern as Accern API\n    participant OpenAI as OpenAI API\n\n    Job-&gt;&gt;DB: fetch_source_from_db(\"Accern\")\n    DB--&gt;&gt;Job: DataSource + Channels\n\n    loop For each channel\n        Job-&gt;&gt;Accern: GET /feed/{endpoint}?token={key}&amp;published_at=[...]\n        Accern--&gt;&gt;Job: AccernFeed (signals list)\n    end\n\n    Job-&gt;&gt;Job: get_signals_from_feeds (aggregate)\n    Job-&gt;&gt;Job: get_unique_context_from_signals (deduplicate)\n\n    loop For each unique context\n        Job-&gt;&gt;OpenAI: preprocess_text + get_all_ner_tags\n        OpenAI--&gt;&gt;Job: OpenAiNerTags\n        Job-&gt;&gt;OpenAI: extract_context_from_signal\n        OpenAI--&gt;&gt;Job: OpenAiSignalContext\n    end\n\n    Job-&gt;&gt;DB: store_in_db (Signal records)</code></pre> <p>Step-by-Step Breakdown</p> <ol> <li>Fetch Source Metadata (<code>fetch_source_from_db</code>)</li> <li> <p>Retrieves the \"Accern\" data source record from the database, including all associated channels with their API credentials</p> </li> <li> <p>Ingest Data from Channels (<code>ingest_data_from_channels</code>)</p> </li> <li>For each configured channel, calls <code>AccernResource.fetch_feed()</code> to retrieve signals from the past 24 hours</li> <li> <p>Time window: 11:00 AM previous day to 11:00 AM current day (America/New_York timezone)</p> </li> <li> <p>Extract Signals from Feeds (<code>get_signals_from_feeds</code>)</p> </li> <li> <p>Flattens the list of <code>AccernFeed</code> objects into a single list of <code>AccernSignal</code> objects</p> </li> <li> <p>Deduplicate Signal Context (<code>get_unique_context_from_signals</code>)</p> </li> <li>Removes duplicate signals using a composite key of:<ul> <li><code>entity_text</code> (tuple)</li> <li><code>event_text</code> (tuple)</li> <li><code>entity_name</code></li> <li><code>entity_type</code></li> <li><code>doc_title</code></li> <li><code>doc_url</code></li> </ul> </li> <li> <p>Returns both unique contexts and corresponding unique signals</p> </li> <li> <p>Entity Extraction (See \u00a76.5 OpenAI Integration)</p> </li> <li>Preprocesses text and extracts named entities</li> <li>Filters irrelevant entities (e.g., large organizations, government agencies)</li> <li> <p>Extracts additional context for each entity</p> </li> <li> <p>URL Enrichment (See \u00a76.4 Google Custom Search)</p> </li> <li> <p>Discovers company websites and LinkedIn profiles for extracted entities</p> </li> <li> <p>Entity Filtering (<code>filter_entities</code>)</p> </li> <li> <p>Removes entities that match the company filter list (manually curated exclusion list)</p> </li> <li> <p>Store in Database (<code>store_in_db</code>)</p> </li> <li>Persists <code>Signal</code> records with both raw and filtered entity tags</li> </ol> <p>Fetch Feed Implementation</p> <pre><code>def fetch_feed(self, endpoint: str, token: str) -&gt; AccernFeed:\n    \"\"\"\n    Fetches feed data from the Accern API for the past 24 hours using the given endpoint and token.\n    \"\"\"\n    ny_tz = pytz.timezone(\"America/New_York\")\n    end_date = datetime.now(ny_tz).replace(hour=11, minute=0, second=0, microsecond=0)\n    start_date = end_date - timedelta(hours=24)\n\n    start_str = start_date.strftime(\"%Y-%m-%dT%H:%M\")\n    end_str = end_date.strftime(\"%Y-%m-%dT%H:%M\")\n    endpoint_with_queries = f\"{self.base_url}{endpoint}?token={token}&amp;published_at=[{start_str}..{end_str}]\"\n\n    response = requests.get(\n        endpoint_with_queries,\n        headers={\"user-agent\": \"dagster\"},\n    ).json()\n\n    return AccernFeed.model_validate(response)\n</code></pre> <p>Error Handling</p> <ul> <li>HTTP errors from <code>requests.get()</code> propagate as unhandled exceptions, failing the Dagster job</li> <li>Failed jobs are retried according to Dagster's run status sensor logic</li> <li>No explicit rate limiting (Accern API does not impose rate limits on authenticated channels)</li> </ul> <p>Integration with Data Pipeline</p> <p>The <code>ingest_signals_from_accern</code> job is scheduled to run hourly at <code>:00</code> (see \u00a73.3 Scheduling &amp; Sensors). Upon successful completion, the <code>signal_ingestion_from_accern</code> sensor triggers downstream jobs:</p> <ul> <li><code>ingest_companies_from_signals</code> (extracts and enriches companies)</li> <li><code>ingest_people_from_signals</code> (extracts and enriches people)</li> </ul>"},{"location":"external-integrations/external_integrations/#613-data-schema","title":"6.1.3 Data Schema","text":"<p>AccernFeed</p> <p>The top-level response object returned by the Accern API:</p> <pre><code>class AccernFeed(BaseModel):\n    start_harvested_at: str       # Start of harvest time window\n    end_harvested_at: str         # End of harvest time window\n    start_published_at: str       # Start of publication time window\n    end_published_at: str         # End of publication time window\n    total: int                    # Number of signals in this feed\n    overall_total: int            # Total signals available (may exceed returned count)\n    signals: Optional[list[AccernSignal]]  # List of signal objects\n</code></pre> <p>AccernSignal</p> <p>Individual signal records containing entity and event information:</p> Field Type Description <code>entity_text</code> <code>list[str]</code> Text snippets describing entities (companies, people) <code>event_text</code> <code>list[str]</code> Text snippets describing events (funding, acquisitions) <code>entity_name</code> <code>Optional[str]</code> Primary entity mentioned in the signal <code>entity_type</code> <code>Optional[str]</code> Entity classification (Company, Person, etc.) <code>entity_accern_id</code> <code>Optional[str]</code> Accern's internal entity identifier <code>entity_sentiment</code> <code>Optional[float]</code> Sentiment score for entity mention <code>entity_relevance</code> <code>Optional[float]</code> Relevance score (0-1) <code>event</code> <code>Optional[str]</code> Event classification (Funding, Acquisition, etc.) <code>event_group</code> <code>Optional[str]</code> High-level event category <code>event_sentiment</code> <code>Optional[float]</code> Sentiment score for event <code>event_relevance</code> <code>Optional[float]</code> Event relevance score (0-1) <code>doc_title</code> <code>Optional[str]</code> Title of source document/article <code>doc_url</code> <code>Optional[str]</code> URL of source document <code>doc_source</code> <code>Optional[str]</code> Publication name (e.g., \"TechCrunch\") <code>doc_sentiment</code> <code>Optional[float]</code> Overall document sentiment <code>published_at</code> <code>Optional[datetime]</code> Publication timestamp <code>crawled_at</code> <code>Optional[datetime]</code> Time Accern discovered the document <code>harvested_at</code> <code>Optional[datetime]</code> Time Accern processed the document <code>signal_id</code> <code>Optional[str]</code> Unique signal identifier <code>signal_relevance</code> <code>Optional[float]</code> Overall signal relevance score <code>signal_sentiment</code> <code>Optional[float]</code> Overall signal sentiment <code>signal_tag</code> <code>Optional[str]</code> Signal classification tag <code>primary_signal</code> <code>Optional[bool]</code> Whether this is the primary signal for the entity <code>doc_cluster_id</code> <code>Optional[str]</code> Cluster ID for related documents <code>doc_id</code> <code>Optional[str]</code> Unique document identifier <code>doc_type</code> <code>Optional[str]</code> Document type (article, blog, press release) <code>entity_ticker</code> <code>Optional[str]</code> Stock ticker symbol (if applicable) <code>entity_hits</code> <code>Optional[list[str]]</code> Entity mention locations in text <code>event_hits</code> <code>Optional[list[str]]</code> Event mention locations in text <code>event_accern_id</code> <code>Optional[str]</code> Accern's internal event identifier <code>provider_id</code> <code>Optional[float]</code> Content provider identifier <p>Example Signal</p> <pre><code>{\n  \"entity_text\": [\"DeepTech, an AI infrastructure startup\"],\n  \"event_text\": [\"raised $50M in Series A funding\"],\n  \"entity_name\": \"DeepTech\",\n  \"entity_type\": \"Company\",\n  \"entity_sentiment\": 0.85,\n  \"entity_relevance\": 0.92,\n  \"event\": \"Funding\",\n  \"event_group\": \"Investment\",\n  \"event_sentiment\": 0.78,\n  \"event_relevance\": 0.95,\n  \"doc_title\": \"DeepTech Raises $50M to Scale AI Infrastructure Platform\",\n  \"doc_url\": \"https://techcrunch.com/2025/11/04/deeptech-raises-50m\",\n  \"doc_source\": \"TechCrunch\",\n  \"published_at\": \"2025-11-04T09:30:00Z\",\n  \"signal_id\": \"sig_abc123\",\n  \"signal_relevance\": 0.93,\n  \"primary_signal\": true\n}\n</code></pre>"},{"location":"external-integrations/external_integrations/#62-harmonic-api","title":"6.2 Harmonic API","text":"<p>Harmonic is a B2B company intelligence platform that provides structured data on companies and people. Unlike Accern and Gmail (which require entity extraction from unstructured text), Harmonic returns fully identified and enriched entities with comprehensive metadata.</p> <p>OMVision leverages Harmonic for three purposes:</p> <ol> <li>Saved Search Ingestion: Automatically retrieves companies and people from user-defined searches</li> <li>Entity Enrichment: Enriches companies and people extracted from signals with structured metadata</li> <li>Watchlist Management: Adds discovered entities to Harmonic watchlists for tracking</li> </ol>"},{"location":"external-integrations/external_integrations/#621-resource-configuration","title":"6.2.1 Resource Configuration","text":"<p>Resource Definition</p> <p>The <code>HarmonicResource</code> (<code>app/resources/harmonic_api.py</code>) manages all Harmonic API interactions:</p> <pre><code>class HarmonicResource(ConfigurableResource):\n    \"\"\"\n    A resource class for interacting with the Harmonic API.\n\n    Attributes:\n        api_key (str): The API key used to authenticate requests to the Harmonic API.\n        _base_url (str): The base URL for the Harmonic API.\n        _headers (dict[str, str]): Headers used for the API requests.\n    \"\"\"\n    api_key: str\n    _base_url: str = PrivateAttr()\n    _headers: dict[str, str] = PrivateAttr()\n\n    def setup_for_execution(self, context: InitResourceContext):\n        \"\"\"Sets up the base URL and headers for making API requests to Harmonic.\"\"\"\n        self._base_url = \"https://api.harmonic.ai/\"\n        self._headers = {\n            \"apikey\": self.api_key,\n            \"Content-Type\": \"application/json\",\n        }\n</code></pre> <p>Instantiation</p> <p>Configured in <code>app/main.py</code>:</p> <pre><code>\"harmonic\": HarmonicResource(\n    api_key=os.getenv(\"HARMONIC_API_KEY\")\n)\n</code></pre> <p>Authentication Method</p> <p>Harmonic uses API key authentication passed in request headers:</p> <pre><code>GET https://api.harmonic.ai/{endpoint}\nHeaders:\n  apikey: {HARMONIC_API_KEY}\n  Content-Type: application/json\n</code></pre> <p>Required Environment Variables</p> Variable Description <code>HARMONIC_API_KEY</code> API key for Harmonic platform access <p>Configuration in Data Sources</p> <p>Harmonic is also configured in <code>app/constants/data_sources.py</code> for database persistence:</p> <pre><code>DataSourceBase(\n    name=\"Harmonic Search\",\n    description=\"Harmonic API for company data\",\n    base_url=\"https://api.harmonic.ai\",\n    channels=[\n        Channel(\n            api_key=\"bvudcyYYlP6g0kQPEe097iA5ERcYfiuX\",\n            api_endpoint=\"\",\n        ),\n    ],\n)\n</code></pre>"},{"location":"external-integrations/external_integrations/#622-search-operations","title":"6.2.2 Search Operations","text":"<p>Harmonic provides search functionality for both companies and people. OMVision uses saved searches (user-defined queries in Harmonic's UI) to automatically ingest entities matching specific criteria.</p> <p>Fetching Saved Searches</p> <pre><code>def fetch_searches(self, search_type: SearchType) -&gt; list[SearchList]:\n    \"\"\"\n    Fetches all saved searches of the specified type from the Harmonic API.\n\n    Args:\n        search_type: Either SearchType.companies or SearchType.people\n\n    Returns:\n        list[SearchList]: List of saved search objects\n    \"\"\"\n    endpoint = \"searches\"\n    params = {\"search_type\": search_type.value}\n    return self._fetch_all_pages(endpoint, SearchList, params)\n</code></pre> <p>Pagination</p> <p>Harmonic API results are paginated. The <code>_fetch_all_pages</code> method automatically iterates through all pages:</p> <pre><code>def _fetch_all_pages(\n    self,\n    endpoint: str,\n    model: Type[T],\n    params: Optional[dict[str, any]] = {\"size\": 50},\n) -&gt; list[T]:\n    \"\"\"\n    Fetches all paginated results from the Harmonic API for the given endpoint.\n    \"\"\"\n    all_items = []\n    cursor = None\n\n    while True:\n        if cursor:\n            params[\"cursor\"] = cursor\n        response = requests.get(\n            f\"{self._base_url}{endpoint}\", headers=self._headers, params=params\n        )\n        response.raise_for_status()\n        data = response.json()\n\n        all_items.extend([model(**item) for item in data[\"results\"]])\n\n        if not data[\"page_info\"][\"has_next\"]:\n            break\n        cursor = data[\"page_info\"][\"next\"]\n\n    return all_items\n</code></pre> <p>Search Filtering</p> <p>OMVision only ingests searches whose names start with \"DealFlow\":</p> <pre><code>def get_saved_searches_from_harmonic() -&gt; list[SearchList]:\n    \"\"\"Fetches all saved company searches prefixed with 'DealFlow'.\"\"\"\n    searches = harmonic.fetch_searches(SearchType.companies)\n    return [s for s in searches if s.name.startswith(\"DealFlow\") and \"Filter\" not in s.name]\n</code></pre> <p>This naming convention allows investment team members to create personal searches without triggering automatic ingestion.</p> <p>Fetching Search Results</p> <p>Once a search is identified, its results are retrieved:</p> <pre><code>def fetch_companies_from_search(self, search_id: str) -&gt; list[CompanyBase]:\n    \"\"\"\n    Fetches all companies from a specific saved search.\n\n    Args:\n        search_id: Unique identifier for the saved search\n\n    Returns:\n        list[CompanyBase]: Fully enriched company objects\n    \"\"\"\n    endpoint = f\"searches/{search_id}/companies\"\n    return self._fetch_all_pages(endpoint, CompanyBase)\n</code></pre> <p>Watchlist Operations</p> <p>Harmonic watchlists track entities of interest:</p> <pre><code>def fetch_watchlists(self) -&gt; list[Watchlist]:\n    \"\"\"Fetches all company watchlists from the Harmonic API.\"\"\"\n    endpoint = \"watchlists/companies\"\n    watchlists = self._fetch_all_pages(endpoint, Watchlist)\n    return [w for w in watchlists if w.name.startswith(\"DealFlow\")]\n\ndef add_to_watchlist(self, watchlist_id: str, company_urns: list[str]) -&gt; None:\n    \"\"\"\n    Adds companies to a Harmonic watchlist.\n\n    Args:\n        watchlist_id: Unique identifier for the watchlist\n        company_urns: List of Harmonic URNs for companies to add\n    \"\"\"\n    endpoint = f\"watchlists/companies/{watchlist_id}/add\"\n    payload = {\"company_urns\": company_urns}\n    response = requests.post(\n        f\"{self._base_url}{endpoint}\",\n        headers=self._headers,\n        json=payload\n    )\n    response.raise_for_status()\n</code></pre>"},{"location":"external-integrations/external_integrations/#623-data-enrichment","title":"6.2.3 Data Enrichment","text":"<p>Harmonic enrichment transforms entity names or URLs into fully structured company and people records.</p> <p>Company Enrichment Flow</p> <pre><code>sequenceDiagram\n    participant Job as Entity Extraction Job\n    participant Harmonic as Harmonic API\n    participant DB as PostgreSQL\n\n    Job-&gt;&gt;Job: Extract company name/URL from signal\n\n    alt URL available\n        Job-&gt;&gt;Harmonic: POST /companies?website_url={url}\n        Harmonic--&gt;&gt;Job: CompanyBase (enriched)\n    else No URL, name available\n        Job-&gt;&gt;Harmonic: POST /companies?name={name}\n        Harmonic--&gt;&gt;Job: CompanyBase or 404\n    end\n\n    alt Enrichment successful\n        Job-&gt;&gt;DB: Insert Company + CompanyMetric\n        Job-&gt;&gt;Harmonic: Add to watchlist\n    else Enrichment failed\n        Job-&gt;&gt;Job: Skip company (not stored)\n    end</code></pre> <p>Enrichment by URL</p> <p>The primary enrichment method uses company website URLs:</p> <pre><code>def enrich_company(self, identifier_type: str, identifier_value: str) -&gt; Optional[CompanyBase]:\n    \"\"\"\n    Enriches a company using the Harmonic API.\n\n    Args:\n        identifier_type: \"website_url\", \"linkedin_url\", or \"id\"\n        identifier_value: The identifier value (e.g., \"https://deeptech.ai\")\n\n    Returns:\n        CompanyBase: Fully enriched company object, or None if not found\n    \"\"\"\n    params = {identifier_type: identifier_value}\n\n    try:\n        response = requests.post(\n            f\"{self._base_url}companies\",\n            headers=self._headers,\n            params=params\n        )\n        response.raise_for_status()\n        data = response.json()\n        return CompanyBase(**data)\n    except requests.RequestException as e:\n        log.info(f\"API call failed: {e}\")\n        return None\n</code></pre> <p>Enrichment by Name</p> <p>When no URL is available, OMVision attempts enrichment by company name:</p> <pre><code>enriched_company = harmonic.enrich_company(\"name\", \"DeepTech\")\n</code></pre> <p>Name-based enrichment is less precise and may return incorrect matches. Failed enrichments return <code>None</code> and the company is not stored.</p> <p>People Enrichment</p> <p>People enrichment follows an identical pattern using LinkedIn URLs:</p> <pre><code>def enrich_people(self, identifier_type: str, identifier_value: str) -&gt; Optional[PeopleBase]:\n    \"\"\"\n    Enriches a person using the Harmonic API.\n\n    Args:\n        identifier_type: \"linkedin_url\" or \"id\"\n        identifier_value: The identifier value (e.g., \"https://linkedin.com/in/jane-smith\")\n\n    Returns:\n        PeopleBase: Fully enriched person object, or None if not found\n    \"\"\"\n    params = {identifier_type: identifier_value}\n\n    try:\n        response = requests.post(\n            f\"{self._base_url}people\",\n            headers=self._headers,\n            params=params\n        )\n        response.raise_for_status()\n        data = response.json()\n        return PeopleBase(**data)\n    except requests.RequestException as e:\n        log.info(f\"API call failed: {e}\")\n        return None\n</code></pre> <p>Enriched Data Structure</p> <p>A fully enriched <code>CompanyBase</code> object contains:</p> <ul> <li>Core Attributes: name, legal_name, description, contact, founding_date, website_urls, logo_url, ownership_status, location, tags, socials</li> <li>Metrics: stage, headcount, traction_metrics (web traffic, social metrics), funding details, investor URNs, funding_rounds</li> <li>People: employees with roles, LinkedIn profiles, experience, education</li> <li>Highlights: company highlights (partnerships, products) and employee highlights (former employers, skills)</li> </ul> <p>Error Handling</p> <ul> <li>HTTP 404: Company/person not found in Harmonic's database \u2192 Returns <code>None</code></li> <li>HTTP 4xx/5xx: API errors propagate as unhandled exceptions, failing the Dagster job</li> <li>Network errors: Caught by <code>requests.RequestException</code>, logged, and return <code>None</code></li> </ul> <p>Rate Limiting</p> <p>Harmonic does not publicly document rate limits. OMVision does not implement explicit rate limiting for Harmonic API calls. If rate limiting becomes necessary, the <code>RateLimiter</code> utility class (\u00a76.4.2) can be applied.</p> <p>Integration with Data Pipeline</p> <p>Harmonic enrichment occurs in:</p> <ol> <li><code>ingest_companies_from_signals</code>: Enriches companies extracted from Accern/Gmail signals</li> <li><code>ingest_companies_from_searches</code>: Retrieves pre-enriched companies from saved searches</li> <li><code>ingest_people_from_signals</code>: Enriches people extracted from signals</li> <li><code>ingest_people_from_searches</code>: Retrieves pre-enriched people from saved searches</li> </ol>"},{"location":"external-integrations/external_integrations/#63-gmail-integration","title":"6.3 Gmail Integration","text":"<p>OMVision monitors a dedicated Gmail inbox (<code>newsletters@omvc.co</code>) that receives venture capital newsletters, startup announcement emails, and industry alerts. These emails frequently mention early-stage companies, funding rounds, and product launches\u2014all valuable deal flow signals.</p> <p>Unlike Accern signals with structured entity/event fields, email bodies require full text extraction and NER processing to discover entities.</p>"},{"location":"external-integrations/external_integrations/#631-service-account-setup","title":"6.3.1 Service Account Setup","text":"<p>Gmail integration uses a Google service account with domain-wide delegation, allowing OMVision to access the <code>newsletters@omvc.co</code> inbox without requiring user-specific OAuth tokens.</p> <p>Resource Configuration</p> <p>The <code>GmailResource</code> (<code>app/resources/mail_client.py</code>) manages Gmail API access:</p> <pre><code>class GmailResource(ConfigurableResource):\n    \"\"\"\n    A resource class for interacting with Gmail via a service account.\n\n    Attributes:\n        email_address (str): The email address used to impersonate when accessing Gmail.\n        service_account_info (str): Base64-encoded service account information.\n        _service (PrivateAttr): The Gmail API service object.\n    \"\"\"\n    email_address: str = \"newsletters@omvc.co\"\n    service_account_info: str\n    _service = PrivateAttr()\n\n    def setup_for_execution(self, context: InitResourceContext):\n        \"\"\"Sets up the Gmail API service for execution.\"\"\"\n        self._service = self._get_service()\n</code></pre> <p>Instantiation</p> <p>Configured in <code>app/main.py</code>:</p> <pre><code>\"gmail\": GmailResource(\n    service_account_info=os.getenv(\"GMAIL_SERVICE_ACCOUNT_KEY\")\n)\n</code></pre> <p>Authentication Method</p> <p>Gmail uses OAuth 2.0 with service account credentials:</p> <pre><code>def _authenticate_gmail(self):\n    \"\"\"\n    Authenticates with Gmail using the provided service account information.\n\n    Returns:\n        Credentials: Google API credentials with delegated access to the specified email.\n    \"\"\"\n    if not self.service_account_info:\n        raise ValueError(\"Service account info not found in environment variables\")\n\n    service_account_info = base64.b64decode(self.service_account_info).decode(\"utf-8\")\n    creds = Credentials.from_service_account_info(\n        json.loads(service_account_info),\n        scopes=[\"https://www.googleapis.com/auth/gmail.readonly\"],\n    )\n    delegated_creds = creds.with_subject(self.email_address)\n    return delegated_creds\n</code></pre> <p>Service Account Setup Steps</p> <p>(These steps are performed once during initial system setup, not at runtime):</p> <ol> <li>Create a service account in Google Cloud Console</li> <li>Enable Gmail API for the project</li> <li>Configure domain-wide delegation in Google Workspace Admin Console</li> <li>Grant the service account <code>gmail.readonly</code> scope for the domain</li> <li>Download service account JSON key</li> <li>Base64-encode the JSON key and store in <code>GMAIL_SERVICE_ACCOUNT_KEY</code> environment variable</li> </ol> <p>Required Environment Variables</p> Variable Description <code>GMAIL_SERVICE_ACCOUNT_KEY</code> Base64-encoded Google service account JSON key with domain-wide delegation <p>Scopes</p> <pre><code>SCOPES = [\"https://www.googleapis.com/auth/gmail.readonly\"]\n</code></pre> <p>OMVision only requires read access to Gmail. No write or send permissions are granted.</p>"},{"location":"external-integrations/external_integrations/#632-email-processing","title":"6.3.2 Email Processing","text":"<p>The <code>ingest_signals_from_emails</code> job (<code>app/jobs/ingest_signals_from_emails.py</code>) processes emails through the following sequence:</p> <pre><code>sequenceDiagram\n    participant Job as ingest_signals_from_emails\n    participant Gmail as Gmail API\n    participant OpenAI as OpenAI API\n    participant DB as PostgreSQL\n\n    Job-&gt;&gt;DB: fetch_source_from_db(\"Gmail\")\n    DB--&gt;&gt;Job: DataSource\n\n    Job-&gt;&gt;Gmail: GET /users/me/messages?q=after:{timestamp}\n    Gmail--&gt;&gt;Job: List of message IDs\n\n    loop For each message ID\n        Job-&gt;&gt;Gmail: GET /users/me/messages/{id}?format=full\n        Gmail--&gt;&gt;Job: Full message (headers + body)\n        Job-&gt;&gt;Job: _clean_message (strip HTML/CSS)\n    end\n\n    Job-&gt;&gt;Job: get_context_from_emails (extract body text)\n\n    loop For each email body\n        Job-&gt;&gt;OpenAI: preprocess_text + get_all_ner_tags\n        OpenAI--&gt;&gt;Job: OpenAiNerTags\n        Job-&gt;&gt;OpenAI: extract_context_from_signal\n        OpenAI--&gt;&gt;Job: OpenAiSignalContext\n    end\n\n    Job-&gt;&gt;DB: store_in_db (Signal records)</code></pre> <p>Fetching Emails</p> <pre><code>def get_emails(self) -&gt; list[MailMessage]:\n    \"\"\"\n    Fetches email messages from the Gmail API for the past 24 hours.\n\n    Returns:\n        list[MailMessage]: A list of email messages, cleaned and with full content.\n    \"\"\"\n    try:\n        ny_tz = pytz.timezone(\"America/New_York\")\n        end_date = datetime.now(ny_tz).replace(hour=11, minute=0, second=0, microsecond=0)\n        start_date = end_date - timedelta(hours=24)\n        query = f\"after:{int(start_date.timestamp())}\"\n\n        # Fetch messages from the past day\n        results = (\n            self._service.users().messages().list(userId=\"me\", q=query).execute()\n        )\n        messages = results.get(\"messages\", [])\n        messages_with_data = []\n\n        for message in messages:\n            message_id = message.get(\"id\")\n            full_message = self._get_full_message(message_id)\n            if full_message.body:\n                full_message.body = self._clean_message(full_message.body)\n            messages_with_data.append(full_message)\n\n        return messages_with_data\n    except Exception as e:\n        raise Exception(f\"Failed to retrieve emails: {e}\")\n</code></pre> <p>Message Retrieval</p> <pre><code>def _get_full_message(self, message_id: str) -&gt; MailMessage:\n    \"\"\"\n    Retrieves the full content of an email message by ID.\n\n    Args:\n        message_id: The ID of the email message.\n\n    Returns:\n        MailMessage: The full email message, including sender, date, and body.\n    \"\"\"\n    message = (\n        self._service.users()\n        .messages()\n        .get(userId=\"me\", id=message_id, format=\"full\")\n        .execute()\n    )\n    headers = message.get(\"payload\", {}).get(\"headers\", [])\n    sender = self._extract_header(headers, \"From\")\n    date = self._extract_header(headers, \"Date\")\n    body = self._extract_body(message.get(\"payload\", {}))\n\n    return MailMessage(sender=sender, date=date, body=body)\n</code></pre> <p>HTML Cleaning</p> <p>Email bodies often contain HTML markup, CSS styles, and formatting artifacts. The <code>_clean_message</code> method strips these:</p> <pre><code>def _clean_message(self, message: str) -&gt; str:\n    \"\"\"\n    Cleans an email message by removing CSS and extracting plain text content.\n\n    Args:\n        message: The raw email message content.\n\n    Returns:\n        str: The cleaned message content, with unnecessary elements removed.\n    \"\"\"\n    try:\n        message_no_css = re.sub(r\"\\*{.*?}}\\r\\n\", \"\", message, flags=re.DOTALL)\n        soup = BeautifulSoup(message_no_css, \"html.parser\")\n        clean_text = soup.get_text(separator=\" \").strip()\n        return clean_text\n    except:\n        return message\n</code></pre> <p>Text Extraction Process</p> <ol> <li>Remove CSS blocks using regex: <code>\\*{.*?}}</code></li> <li>Parse HTML with BeautifulSoup</li> <li>Extract plain text with spaces as separators</li> <li>Strip leading/trailing whitespace</li> <li>Fallback to original message if parsing fails</li> </ol> <p>MailMessage Schema</p> <pre><code>class MailMessage(BaseModel):\n    sender: Optional[str]  # Email address of sender\n    date: Optional[str]    # Date string from email headers\n    body: str              # Cleaned plain text body\n</code></pre>"},{"location":"external-integrations/external_integrations/#633-signal-extraction","title":"6.3.3 Signal Extraction","text":"<p>Once emails are fetched and cleaned, their bodies are processed as unstructured text:</p> <pre><code>@op\ndef get_context_from_emails(emails: list[MailMessage]) -&gt; list[str]:\n    \"\"\"\n    Extracts the body content from each email message.\n\n    Args:\n        emails: A list of email messages.\n\n    Returns:\n        list[str]: A list of email body content as strings.\n    \"\"\"\n    return [f\"{email.body}\" for email in emails]\n</code></pre> <p>This operation extracts email bodies as plain strings, which are then processed by OpenAI NER (\u00a76.5) to identify companies and people.</p> <p>Differences from Accern Signals</p> <ul> <li>No structured entity/event fields: Email bodies are raw text without pre-identified entities</li> <li>No deduplication: Each email represents a distinct temporal signal, even if multiple emails mention the same company</li> <li>Higher NER complexity: Emails contain more noise (greetings, signatures, advertisements) requiring more robust filtering</li> </ul> <p>Error Handling</p> <ul> <li>Gmail API errors: Propagate as unhandled exceptions, failing the Dagster job</li> <li>HTML parsing errors: Caught by try/except in <code>_clean_message</code>, falls back to raw message</li> <li>Empty emails: Stored as signals with empty body text (filtered out during NER)</li> </ul> <p>Integration with Data Pipeline</p> <p>The <code>ingest_signals_from_emails</code> job is scheduled to run daily at 3:00 PM (see \u00a73.3 Scheduling &amp; Sensors). Upon successful completion, the <code>signal_ingestion_from_gmail</code> sensor triggers:</p> <ul> <li><code>ingest_companies_from_signals</code> (with <code>source_name=\"Gmail\"</code>)</li> <li><code>ingest_people_from_signals</code> (with <code>source_name=\"Gmail\"</code>)</li> </ul>"},{"location":"external-integrations/external_integrations/#64-google-custom-search","title":"6.4 Google Custom Search","text":"<p>Google Custom Search API enables OMVision to discover company websites and LinkedIn profiles for entities extracted from unstructured signals. When Accern or Gmail signals mention a company without providing a URL, OMVision constructs a search query and uses fuzzy matching to identify the most relevant result.</p> <p>This integration is critical for URL-based enrichment with Harmonic, which requires website URLs rather than company names.</p>"},{"location":"external-integrations/external_integrations/#641-api-configuration","title":"6.4.1 API Configuration","text":"<p>Resource Definition</p> <p>The <code>WebSearchResource</code> (<code>app/resources/web_search.py</code>) manages Google Custom Search operations:</p> <pre><code>class WebSearchResource(ConfigurableResource):\n    \"\"\"\n    A resource class for performing web searches using Google's Custom Search API.\n\n    Attributes:\n        api_key (str): The API key for authenticating requests to Google Custom Search API.\n        cse_id (str): The custom search engine ID used for querying Google Custom Search.\n        _service (PrivateAttr): The Google Custom Search API service object.\n        _rate_limiter (PrivateAttr): A rate limiter to control API requests.\n    \"\"\"\n    api_key: str\n    cse_id: str\n    _service = PrivateAttr()\n    _rate_limiter = PrivateAttr()\n\n    def setup_for_execution(self, context: InitResourceContext):\n        \"\"\"Sets up the Google Custom Search API service and rate limiter.\"\"\"\n        self._service = build(\"customsearch\", \"v1\", developerKey=self.api_key)\n        self._rate_limiter = RateLimiter(100, 60)  # 100 requests per 60 seconds\n</code></pre> <p>Instantiation</p> <p>Configured in <code>app/main.py</code>:</p> <pre><code>\"google\": WebSearchResource(\n    api_key=os.getenv(\"GOOGLE_SEARCH_API_KEY\"),\n    cse_id=os.getenv(\"GOOGLE_SEARCH_ENGINE_ID\"),\n)\n</code></pre> <p>Authentication Method</p> <p>Google Custom Search uses API key authentication passed as a request parameter:</p> <pre><code>GET https://www.googleapis.com/customsearch/v1?key={API_KEY}&amp;cx={CSE_ID}&amp;q={query}\n</code></pre> <p>Required Environment Variables</p> Variable Description <code>GOOGLE_SEARCH_API_KEY</code> API key for Google Custom Search <code>GOOGLE_SEARCH_ENGINE_ID</code> Custom Search Engine ID (created in Google Programmable Search Engine console) <p>Custom Search Engine Setup</p> <p>(Performed once during initial configuration):</p> <ol> <li>Create a Programmable Search Engine at https://programmablesearchengine.google.com</li> <li>Configure to search the entire web (not restricted to specific sites)</li> <li>Enable image search and safe search as needed</li> <li>Copy the Search Engine ID (CSE ID)</li> <li>Enable Custom Search API in Google Cloud Console</li> <li>Generate API key with Custom Search API permissions</li> </ol>"},{"location":"external-integrations/external_integrations/#642-rate-limiting","title":"6.4.2 Rate Limiting","text":"<p>Google Custom Search API enforces strict rate limits:</p> <ul> <li>Free tier: 100 queries per day</li> <li>Paid tier: 10,000 queries per day (with billing enabled)</li> <li>Per-second limit: ~100 queries per minute</li> </ul> <p>OMVision implements a token bucket rate limiter to respect these limits and prevent throttling.</p> <p>RateLimiter Implementation</p> <pre><code>class RateLimiter:\n    def __init__(self, max_calls, period, threshold=0.90):\n        \"\"\"\n        :param max_calls: The maximum number of calls allowed within the period.\n        :param period: The time period in seconds in which max_calls is allowed.\n        :param threshold: The percentage (as a float) of max_calls allowed (default 90%).\n        \"\"\"\n        self.max_calls = max_calls\n        self.period = period\n        self.threshold = threshold\n        self.threshold_limit = int(max_calls * threshold)\n        self._lock = Lock()\n        self._request_counter = 0\n        self._first_request_time = None\n\n    def acquire(self):\n        with self._lock:\n            current_time = time.time()\n            if self._first_request_time is None:\n                self._first_request_time = current_time\n\n            elapsed_time = current_time - self._first_request_time\n\n            if elapsed_time &gt; self.period:\n                self._request_counter = 0\n                self._first_request_time = current_time\n\n            if self._request_counter &gt;= self.threshold_limit:\n                time_to_wait = ceil(self.period - elapsed_time)\n                print(f\"Rate limit hit. Sleeping for {time_to_wait} seconds.\")\n                time.sleep(time_to_wait)\n                self._first_request_time = time.time()\n                self._request_counter = 0\n\n            self._request_counter += 1\n</code></pre> <p>Configuration for Google Search</p> <pre><code>self._rate_limiter = RateLimiter(100, 60)  # 100 requests per 60 seconds\n</code></pre> <p>This configuration enforces 90% of the maximum rate (90 requests per minute) to provide a safety buffer.</p> <p>Usage Pattern</p> <p>Before each API call, the rate limiter's <code>acquire()</code> method is invoked:</p> <pre><code>def _google_custom_search(self, query, website=None):\n    \"\"\"Performs a Google Custom Search query.\"\"\"\n    self._rate_limiter.acquire()  # Blocks if rate limit exceeded\n\n    if website is not None:\n        res = (\n            self._service.cse()\n            .list(q=query, cx=self.cse_id, siteSearch=website, siteSearchFilter=\"i\")\n            .execute()\n        )\n    else:\n        res = self._service.cse().list(q=query, cx=self.cse_id).execute()\n\n    results = res.get(\"items\", [])\n    return results\n</code></pre> <p>If the rate limit is exceeded, <code>acquire()</code> blocks the thread and sleeps until the rate window resets.</p> <p>Rate Limit Behavior</p> Scenario Behavior Under threshold Request proceeds immediately At threshold Thread sleeps until rate window resets Multiple threads Lock ensures thread-safe counter updates"},{"location":"external-integrations/external_integrations/#643-entity-matching","title":"6.4.3 Entity Matching","text":"<p>Google Custom Search returns a list of search results, each containing a title, URL, and snippet. OMVision uses fuzzy matching to identify the best result for a given entity.</p> <p>URL Discovery Flow</p> <pre><code>sequenceDiagram\n    participant Job as Entity Extraction\n    participant Google as Google Custom Search\n    participant Matcher as Fuzzy Matcher\n\n    alt Entity has link in extracted context\n        Job-&gt;&gt;Matcher: _match_entity_with_url(entity)\n        Matcher--&gt;&gt;Job: Validated URL or empty string\n    end\n\n    alt No valid link or validation failed\n        Job-&gt;&gt;Google: _google_custom_search(query)\n        Google--&gt;&gt;Job: List of search results\n        Job-&gt;&gt;Matcher: _find_best_match(results, entity)\n        loop For each result\n            Matcher-&gt;&gt;Matcher: Parse URL to extract name\n            Matcher-&gt;&gt;Matcher: fuzz.partial_ratio(extracted_name, entity_name)\n            Matcher-&gt;&gt;Matcher: fuzz.partial_ratio(descriptor, result_title)\n        end\n        Matcher--&gt;&gt;Job: Best match URL\n    end</code></pre> <p>Match or Fetch Pattern</p> <pre><code>def match_or_fetch_company_url(self, company: OpenAiEntityContext) -&gt; str:\n    \"\"\"\n    Matches or fetches a company URL based on the company's name and descriptors.\n\n    Args:\n        company: The company entity context.\n\n    Returns:\n        str: The matched or fetched company URL.\n    \"\"\"\n    # Try to match with existing link first\n    matched_url = self._match_entity_with_url(company)\n\n    if not matched_url:\n        # No match found, search Google\n        query = (\n            f\"{company.name} {company.descriptors[0]}\"\n            if company.descriptors\n            else f\"{company.name} website\"\n        )\n        results = self._google_custom_search(query)\n        matched_url = self._find_best_match(\n            results,\n            company.name,\n            company.descriptors[0] if company.descriptors else \"\",\n        )\n\n    return matched_url\n</code></pre> <p>URL Validation</p> <p>If the entity context already contains a link, it is validated using fuzzy matching:</p> <pre><code>def _match_entity_with_url(\n    self,\n    entity: OpenAiEntityContext,\n    entity_type: EntityType = EntityType.org,\n    match_threshold: int = 80,\n):\n    \"\"\"\n    Matches an entity with a URL by performing fuzzy matching on the entity's name and URL.\n\n    Args:\n        entity: The entity to match.\n        entity_type: The type of entity (default: EntityType.org).\n        match_threshold: Minimum score required for a match (default: 80).\n\n    Returns:\n        str: The matched URL or an empty string if no match is found.\n    \"\"\"\n    entity_link = \"\"\n\n    if entity_type == EntityType.person:\n        if \"linkedin.com/in\" not in entity.link:\n            return entity_link\n\n    if entity.link:\n        parsed_entity_link = urlparse(entity.link)\n        extracted_name = (\n            self._parse_company_name_from_link(parsed_entity_link)\n            if entity_type == EntityType.org\n            else self._parse_profile_name_from_link(parsed_entity_link)\n        )\n        match_score, _ = self._get_match_scores(extracted_name, \"\", entity.name, \"\")\n\n        if match_score &gt;= match_threshold:\n            entity_link = entity.link\n\n    return entity_link\n</code></pre> <p>Fuzzy Matching Algorithm</p> <pre><code>def _get_match_scores(\n    self,\n    profile_name: str,\n    result_title: str,\n    person_name: str,\n    person_descriptor: str,\n    match_threshold: int = 80,\n    similarity_threshold: int = 25,\n):\n    \"\"\"\n    Calculates match score and similarity score between a profile name and result title.\n\n    Args:\n        profile_name: Extracted profile/company name from the result.\n        result_title: The title of the search result.\n        person_name: The name of the entity to match.\n        person_descriptor: The descriptor of the entity to match.\n        match_threshold: Minimum score required for a match (default: 80).\n        similarity_threshold: Minimum score for similarity (default: 25).\n\n    Returns:\n        tuple[int, int]: A tuple containing the match score and similarity score.\n    \"\"\"\n    match_score = fuzz.partial_ratio(profile_name.lower(), person_name.lower())\n    if match_score &gt;= match_threshold:\n        similarity_score = fuzz.partial_ratio(\n            person_descriptor.lower(), result_title.lower()\n        )\n        if similarity_score &gt;= similarity_threshold:\n            return match_score, similarity_score\n        else:\n            return match_score, 0\n    return 0, 0\n</code></pre> <p>Scoring Logic</p> <ol> <li>Match Score: Fuzzy match between extracted URL name and entity name</li> <li>Must be \u2265 80 to be considered</li> <li>Similarity Score: Fuzzy match between entity descriptor and search result title</li> <li>Must be \u2265 25 to be considered</li> <li>Used as a tiebreaker when multiple results have high match scores</li> </ol> <p>Best Match Selection</p> <pre><code>def _find_best_match(\n    self,\n    results,\n    entity_name: str,\n    entity_descriptor: str,\n    entity_type: EntityType = EntityType.org,\n):\n    \"\"\"\n    Finds the best match for an entity from search results based on match and similarity scores.\n\n    Returns:\n        str: The URL of the best match.\n    \"\"\"\n    highest_match_score = 0\n    highest_similarity_score = 0\n    best_match_url = \"\"\n\n    for result in results:\n        result_title = result.get(\"title\", \"\")\n        result_link = result.get(\"link\", \"\")\n\n        if result_link:\n            parsed_link = urlparse(result_link)\n            if entity_type == EntityType.person:\n                result_title = result_title.replace(\" | LinkedIn\", \"\")\n                extracted_name_from_link = self._parse_profile_name_from_link(parsed_link)\n            else:\n                extracted_name_from_link = self._parse_company_name_from_link(parsed_link)\n\n            match_score, similarity_score = self._get_match_scores(\n                extracted_name_from_link,\n                result_title,\n                entity_name,\n                entity_descriptor,\n            )\n\n            if match_score &gt; highest_match_score:\n                highest_match_score = match_score\n\n                if similarity_score &gt; highest_similarity_score:\n                    highest_similarity_score = similarity_score\n                    best_match_url = (\n                        parsed_link.scheme + \"://\" + parsed_link.netloc + parsed_link.path\n                    )\n\n    return best_match_url\n</code></pre> <p>Example Matching</p> <p>Input:</p> <ul> <li>Entity name: \"DeepTech\"</li> <li>Entity descriptor: \"AI infrastructure startup\"</li> </ul> <p>Google Search Query: <pre><code>\"DeepTech AI infrastructure startup\"\n</code></pre></p> <p>Search Results:</p> Result Title Link Match Score Similarity Score Selected? 1 DeepTech - AI Infrastructure Platform https://deeptech.ai 100 95 Yes 2 DeepTech | Crunchbase https://crunchbase.com/organization/deeptech 0 N/A No 3 DeepTech Review - TechCrunch https://techcrunch.com/deeptech-review 0 N/A No <p>Best Match: <code>https://deeptech.ai</code> with match_score=100, similarity_score=95</p> <p>Error Handling</p> <ul> <li>No search results: Returns empty string (company not stored)</li> <li>Low match scores: Returns empty string (ambiguous match)</li> <li>API errors: Propagate as unhandled exceptions, failing the Dagster job</li> </ul> <p>Integration with Data Pipeline</p> <p>Google Custom Search is invoked by:</p> <ul> <li><code>ingest_signals_from_accern</code>: Discovers URLs for companies mentioned in signals</li> <li><code>ingest_signals_from_emails</code>: Discovers URLs for companies mentioned in emails</li> <li><code>ingest_companies_from_signals</code>: Enriches extracted companies with URLs before Harmonic enrichment</li> </ul>"},{"location":"external-integrations/external_integrations/#65-openai-integration","title":"6.5 OpenAI Integration","text":"<p>OpenAI's GPT models power OMVision's entity extraction, context analysis, and feature rating capabilities. The integration uses structured outputs (JSON mode) to ensure reliable, type-safe responses.</p> <p>OMVision leverages OpenAI for three primary tasks:</p> <ol> <li>Named Entity Recognition (NER): Extract companies, people, and locations from unstructured text</li> <li>Entity Filtering: Remove irrelevant entities (large corporations, government agencies)</li> <li>Company Rating Extraction: Transform natural language features into numerical ratings for ML classification</li> </ol>"},{"location":"external-integrations/external_integrations/#651-api-setup","title":"6.5.1 API Setup","text":"<p>Resource Configuration</p> <p>The <code>OpenAIResource</code> (<code>app/resources/open_ai.py</code>) manages all OpenAI API interactions:</p> <pre><code>class OpenAIResource(ConfigurableResource):\n    \"\"\"\n    A resource class for interacting with OpenAI's models to perform various tasks.\n\n    Attributes:\n        preprocess_model (str): Model for preprocessing text (default: \"gpt-4o-mini\").\n        max_preprocess_context (int): Max context length for preprocessing (default: 128000).\n        extraction_model (str): Model for entity extraction (default: \"gpt-4o-2024-08-06\").\n        chunk_size (int): Maximum chunk size for tokenizing input (default: 1200).\n        api_key (str): API key for authenticating requests to OpenAI's API.\n        labels (list[str]): List of NER labels used during entity extraction.\n        _client (OpenAI): OpenAI client for API interactions.\n        _encoding (Encoding): Token encoding for handling model input/output.\n    \"\"\"\n    preprocess_model: str = \"gpt-4o-mini\"\n    max_preprocess_context: int = 128000\n    extraction_model: str = \"gpt-4o-2024-08-06\"\n    chunk_size: int = 1200\n    api_key: str\n    labels: list[str] = [\n        \"person (people, investors, entrepreneurs, etc.)\",\n        \"org (organizations, companies, startups, agencies, institutions, etc.)\",\n        \"gpe (geopolitical entities like countries, cities, states, etc.)\",\n    ]\n\n    _client: OpenAI = PrivateAttr()\n    _encoding: Encoding = PrivateAttr()\n\n    def setup_for_execution(self, context: InitResourceContext):\n        \"\"\"Initializes the OpenAI client and token encoding before job execution.\"\"\"\n        self._client = OpenAI(api_key=self.api_key)\n        self._encoding = encoding_for_model(self.extraction_model)\n</code></pre> <p>Instantiation</p> <p>Configured in <code>app/main.py</code>:</p> <pre><code>\"openai\": OpenAIResource(\n    api_key=os.getenv(\"OPENAI_API_KEY\")\n)\n</code></pre> <p>Authentication Method</p> <p>OpenAI uses API key authentication passed in request headers:</p> <pre><code>POST https://api.openai.com/v1/chat/completions\nHeaders:\n  Authorization: Bearer {OPENAI_API_KEY}\n  Content-Type: application/json\n</code></pre> <p>Required Environment Variables</p> Variable Description <code>OPENAI_API_KEY</code> API key for OpenAI platform access (organization-scoped) <p>Model Selection</p> <ul> <li>Preprocessing: <code>gpt-4o-mini</code> (fast, cost-effective for text cleaning)</li> <li>Extraction: <code>gpt-4o-2024-08-06</code> (high accuracy for structured outputs)</li> </ul>"},{"location":"external-integrations/external_integrations/#652-ner-tag-extraction","title":"6.5.2 NER Tag Extraction","text":"<p>OMVision uses OpenAI to extract named entities from unstructured text, identifying companies, people, and geographic locations.</p> <p>NER Pipeline Flow</p> <pre><code>sequenceDiagram\n    participant Job as Signal Processing Job\n    participant OpenAI as OpenAI API\n    participant Pydantic as Pydantic Validator\n\n    Job-&gt;&gt;OpenAI: preprocess_text(raw_signal)\n    OpenAI--&gt;&gt;Job: Cleaned, summarized text\n\n    Job-&gt;&gt;Job: Chunk text (if &gt; 1200 tokens)\n\n    loop For each chunk\n        Job-&gt;&gt;OpenAI: get_all_ner_tags(chunk)\n        Note over OpenAI: System: NER extraction prompt&lt;br/&gt;User: Preprocessed text + metadata\n        OpenAI--&gt;&gt;Job: OpenAiNerTags (person, org, gpe lists)\n    end\n\n    Job-&gt;&gt;Job: Combine results from all chunks\n\n    Job-&gt;&gt;OpenAI: filter_ner_tags(preprocessed_text, entities)\n    Note over OpenAI: System: Entity filtering prompt&lt;br/&gt;User: Text + extracted entities\n    OpenAI--&gt;&gt;Job: Filtered OpenAiNerTags\n\n    Job-&gt;&gt;Pydantic: Validate schema\n    Pydantic--&gt;&gt;Job: Type-safe OpenAiNerTags object</code></pre> <p>Text Preprocessing</p> <p>Before entity extraction, raw signal text is cleaned and summarized:</p> <pre><code>def preprocess_text(self, source_text: str) -&gt; str:\n    \"\"\"\n    Preprocesses signal text by removing irrelevant information and summarizing.\n\n    Args:\n        source_text: The raw signal text to preprocess.\n\n    Returns:\n        str: Cleaned and summarized text suitable for NER.\n    \"\"\"\n    messages = [\n        {\"role\": \"system\", \"content\": self._preprocessing_system_prompt()},\n        {\"role\": \"user\", \"content\": source_text},\n    ]\n\n    response = self._client.chat.completions.create(\n        model=self.preprocess_model,\n        messages=messages,\n        temperature=0,\n    )\n\n    return response.choices[0].message.content\n</code></pre> <p>The preprocessing prompt removes:</p> <ul> <li>HTML artifacts and formatting</li> <li>Advertisements and boilerplate text</li> <li>Irrelevant metadata</li> <li>Duplicate information</li> </ul> <p>Text Chunking</p> <p>Long texts exceeding 1200 tokens are split into chunks:</p> <pre><code>def _chunk_text(self, text: str) -&gt; list[str]:\n    \"\"\"\n    Splits text into chunks of approximately chunk_size tokens.\n\n    Args:\n        text: The text to chunk.\n\n    Returns:\n        list[str]: List of text chunks.\n    \"\"\"\n    tokens = self._encoding.encode(text)\n    chunks = []\n\n    for i in range(0, len(tokens), self.chunk_size):\n        chunk_tokens = tokens[i:i + self.chunk_size]\n        chunk_text = self._encoding.decode(chunk_tokens)\n        chunks.append(chunk_text)\n\n    return chunks\n</code></pre> <p>NER Extraction</p> <pre><code>def get_all_ner_tags(\n    self,\n    preprocessed_text: str,\n    additional_context: Optional[dict] = None\n) -&gt; OpenAiNerTags:\n    \"\"\"\n    Extracts named entities from preprocessed text.\n\n    Args:\n        preprocessed_text: Cleaned and summarized text.\n        additional_context: Optional metadata (entity_name, doc_title, etc.).\n\n    Returns:\n        OpenAiNerTags: Structured entity lists (person, org, gpe).\n    \"\"\"\n    chunks = self._chunk_text(preprocessed_text)\n    ner_tags_for_all_chunks = []\n\n    for chunk in chunks:\n        user_message_content = chunk\n        if additional_context:\n            user_message_content += f\"\\n\\nAdditional Context:\\n{json.dumps(additional_context)}\"\n\n        messages = [\n            {\"role\": \"system\", \"content\": self._system_message(self.labels)},\n            {\"role\": \"user\", \"content\": user_message_content},\n        ]\n\n        response = self._client.beta.chat.completions.parse(\n            model=self.extraction_model,\n            messages=messages,\n            temperature=0,\n            response_format=OpenAiNerTags,\n        )\n\n        message = response.choices[0].message\n        if message.parsed:\n            ner_tags_for_all_chunks.append(message.parsed)\n\n    # Combine results from all chunks\n    combined_ner_tags = OpenAiNerTags(person=[], org=[], gpe=[])\n    for ner_tags in ner_tags_for_all_chunks:\n        combined_ner_tags.person.extend(ner_tags.person)\n        combined_ner_tags.org.extend(ner_tags.org)\n        combined_ner_tags.gpe.extend(ner_tags.gpe)\n\n    return combined_ner_tags\n</code></pre> <p>System Prompt</p> <pre><code>def _system_message(self, labels):\n    \"\"\"Generates a system message for NER extraction, defining entity types.\"\"\"\n    return f\"\"\"\n    You are an expert in Natural Language Processing. Your task is to identify common Named Entities (NER) in a given natural language signal text.\n    The possible common Named Entities (NER) types are exclusively: ({\", \".join(labels)}).\n    \"\"\"\n</code></pre> <p>Additional Context</p> <p>For Accern signals, additional metadata is provided to improve extraction accuracy:</p> <pre><code>additional_context = {\n    \"entity_name\": signal.entity_name,\n    \"entity_type\": signal.entity_type,\n    \"doc_title\": signal.doc_title,\n    \"doc_url\": signal.doc_url\n}\n</code></pre> <p>This context helps the model disambiguate entities and prioritize relevant mentions.</p> <p>Structured Output Schema</p> <pre><code>class OpenAiNerTags(BaseModel):\n    person: list[str]  # List of person names\n    org: list[str]     # List of organization names\n    gpe: list[str]     # List of geopolitical entity names\n</code></pre> <p>Using <code>response_format=OpenAiNerTags</code> ensures OpenAI returns JSON matching this exact schema, eliminating parsing errors.</p> <p>Entity Filtering</p> <p>After initial extraction, irrelevant entities are filtered out:</p> <pre><code>def filter_ner_tags(\n    self,\n    preprocessed_text: str,\n    entities: OpenAiNerTags\n) -&gt; OpenAiNerTags:\n    \"\"\"\n    Filters extracted entities to remove large organizations, government agencies, etc.\n\n    Args:\n        preprocessed_text: The preprocessed text.\n        entities: The NER tags to filter.\n\n    Returns:\n        OpenAiNerTags: Filtered NER tags.\n    \"\"\"\n    entities_str = json.dumps(entities.model_dump())\n    messages = [\n        {\"role\": \"system\", \"content\": self._filter_text_system_prompt()},\n        {\n            \"role\": \"user\",\n            \"content\": f\"\"\"Source text: {preprocessed_text} \\n\\n\\n Extracted entities: {entities_str}\\n\"\"\",\n        },\n    ]\n\n    response = self._client.beta.chat.completions.parse(\n        model=self.extraction_model,\n        messages=messages,\n        temperature=0,\n        response_format=OpenAiNerTags,\n    )\n\n    message = response.choices[0].message\n    if message.parsed:\n        return message.parsed\n    else:\n        print(f\"Unable to filter NER tags - {message.refusal}\")\n        return entities\n</code></pre> <p>Filtering Criteria</p> <p>The filtering prompt instructs the model to remove:</p> <ul> <li>Large public corporations (e.g., Google, Microsoft)</li> <li>Government agencies and institutions</li> <li>Universities and research institutions (unless they are the primary entity)</li> <li>Generic organization references (e.g., \"the company\", \"the startup\")</li> </ul> <p>Context Extraction</p> <p>After filtering, additional context is extracted for each entity:</p> <pre><code>def extract_context_from_signal(\n    self,\n    original_source: str,\n    entities: dict\n) -&gt; OpenAiSignalContext:\n    \"\"\"\n    Extracts context from a given signal and corresponding entities.\n\n    Args:\n        original_source: The original source text for the signal.\n        entities: The extracted entities associated with the signal.\n\n    Returns:\n        OpenAiSignalContext: The extracted context for the signal and its entities.\n    \"\"\"\n    entities_str = json.dumps(entities)\n    messages = [\n        {\"role\": \"system\", \"content\": self._context_extraction_prompt()},\n        {\n            \"role\": \"user\",\n            \"content\": f\"\"\"Source text: {original_source} \\n\\n\\n Extracted entities: {entities_str}\\n\"\"\",\n        },\n    ]\n\n    response = self._client.beta.chat.completions.parse(\n        model=self.extraction_model,\n        messages=messages,\n        temperature=0,\n        response_format=OpenAiSignalContext,\n    )\n\n    message = response.choices[0].message\n    if message.parsed:\n        return message.parsed\n    else:\n        print(f\"Unable to extract data - {message.refusal}\")\n        return entities\n</code></pre> <p>OpenAiSignalContext Schema</p> <pre><code>class OpenAiEntityContext(BaseModel):\n    name: str                     # Entity name\n    link: str                     # Entity URL (if mentioned)\n    descriptors: list[str]        # Descriptive phrases about the entity\n\nclass OpenAiSignalContext(BaseModel):\n    companies: list[OpenAiEntityContext]\n    people: list[OpenAiEntityContext]\n</code></pre> <p>This structured output provides:</p> <ul> <li>name: The entity's name as mentioned in the text</li> <li>link: Any URL mentioned in association with the entity</li> <li>descriptors: Phrases describing what the entity does or is known for</li> </ul> <p>Error Handling</p> <ul> <li>Parsing failures: If OpenAI returns malformed JSON, <code>message.parsed</code> is <code>None</code> and the operation logs the error</li> <li>Refusals: If OpenAI refuses to process content (e.g., policy violations), <code>message.refusal</code> contains the reason</li> <li>Network errors: Propagate as unhandled exceptions, failing the Dagster job</li> <li>Token limits: Text exceeding context limits is chunked; chunks exceeding limits are skipped</li> </ul> <p>Rate Limiting</p> <p>OpenAI does not require explicit rate limiting in OMVision's usage patterns. The API enforces per-organization rate limits (RPM and TPM), which are monitored via OpenAI's dashboard. If rate limit errors occur, the <code>tenacity</code> library (used elsewhere in the codebase) can be applied for exponential backoff retries.</p>"},{"location":"external-integrations/external_integrations/#653-company-rating-extraction","title":"6.5.3 Company Rating Extraction","text":"<p>In addition to NER, OpenAI transforms natural language company features into numerical ratings for ML classification (see \u00a75 Machine Learning Components).</p> <p>Feature Rating Flow</p> <pre><code>sequenceDiagram\n    participant Job as Classification Job\n    participant OpenAI as OpenAI API\n    participant ML as ML Classifier\n\n    Job-&gt;&gt;Job: Extract CompanyNLFeatures (descriptions, highlights, bios)\n    Job-&gt;&gt;Job: Format as CompanyNLFeaturesFormatted\n\n    Job-&gt;&gt;OpenAI: transform_to_numerical_features(formatted_features)\n    Note over OpenAI: System: Feature extraction prompt&lt;br/&gt;with input/output definitions\n    OpenAI--&gt;&gt;Job: OpenAiCompanyExtractedRatings\n\n    Job-&gt;&gt;ML: Combine with structured features\n    ML-&gt;&gt;ML: Predict company relevance score</code></pre> <p>Transformation Method</p> <pre><code>def transform_to_numerical_features(\n    self,\n    formatted_nl_features: CompanyNLFeaturesFormatted\n) -&gt; OpenAiCompanyExtractedRatings:\n    \"\"\"\n    Transforms natural language features into numerical ratings.\n\n    Args:\n        formatted_nl_features: Structured NL features with descriptions, highlights, etc.\n\n    Returns:\n        OpenAiCompanyExtractedRatings: Numerical ratings (0.0-1.0) for each feature.\n    \"\"\"\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": self._system_message_for_feature_extraction(\n                INPUT_FEATURE_DEFINTIIONS, OUTPUT_RATING_DEFINITIONS\n            ),\n        },\n        {\n            \"role\": \"user\",\n            \"content\": self._user_message_for_feature_extraction(\n                formatted_nl_features.model_dump()\n            ),\n        },\n    ]\n\n    response = self._client.beta.chat.completions.parse(\n        model=self.extraction_model,\n        messages=messages,\n        temperature=0,\n        response_format=OpenAiCompanyExtractedRatings,\n    )\n\n    message = response.choices[0].message\n    if message.parsed:\n        return message.parsed\n    else:\n        print(f\"Unable to extract features - {message.refusal}\")\n        return OpenAiCompanyExtractedRatings(\n            company_relevance=0.0,\n            founder_strength=0.0,\n            investor_relevance=0.0,\n            team_strength=0.0,\n        )\n</code></pre> <p>Input Features</p> <p>The system prompt defines input features and their meanings:</p> <pre><code>INPUT_FEATURE_DEFINTIIONS = {\n    \"company_description\": \"Description of what the company does\",\n    \"company_highlights\": \"Notable achievements, partnerships, or products\",\n    \"founder_bios\": \"Background and experience of founders\",\n    \"investor_names\": \"Names of investors who have funded the company\",\n    # ... additional features\n}\n</code></pre> <p>Output Ratings</p> <pre><code>OUTPUT_RATING_DEFINITIONS = {\n    \"company_relevance\": \"How relevant the company is to OMVC's investment thesis (0.0-1.0)\",\n    \"founder_strength\": \"Quality and experience of the founding team (0.0-1.0)\",\n    \"investor_relevance\": \"Quality and relevance of existing investors (0.0-1.0)\",\n    \"team_strength\": \"Overall team quality and composition (0.0-1.0)\",\n}\n</code></pre> <p>Output Schema</p> <pre><code>class OpenAiCompanyExtractedRatings(BaseModel):\n    company_relevance: float  # 0.0 - 1.0\n    founder_strength: float   # 0.0 - 1.0\n    investor_relevance: float # 0.0 - 1.0\n    team_strength: float      # 0.0 - 1.0\n</code></pre> <p>System Prompt Construction</p> <pre><code>def _system_message_for_feature_extraction(\n    self,\n    input_features_definitions: dict,\n    output_ratings_definitions: dict,\n    examples: Optional[list] = [],\n) -&gt; str:\n    \"\"\"\n    Generates a system message for feature extraction, defining input and output features.\n    \"\"\"\n    prompt = f\"\"\"You are an AI assistant to our investment firm that extracts numerical ratings (granular values between 0.00 and 1.00) from a set of natural language features for companies.\n\nInput Features:\n\"\"\"\n    for feature, description in input_features_definitions.items():\n        prompt += f\"- {feature}: {description}\\n\"\n\n    prompt += \"\\nOutput Ratings:\\n\"\n    for rating, description in output_ratings_definitions.items():\n        prompt += f\"- {rating}: {description}\\n\"\n\n    if examples:\n        prompt += \"\\nExamples:\\n\"\n        for i, example in enumerate(examples):\n            prompt += f\"Example {i+1}:\\n\"\n            prompt += \"Input Features:\\n\"\n            for feature in input_features_definitions.keys():\n                prompt += f\"{feature}: {example['input'][feature]}\\n\"\n            prompt += \"Output Ratings:\\n\"\n            for rating in output_ratings_definitions.keys():\n                prompt += f\"{rating}: {example['output'][rating]}\\n\"\n            prompt += \"\\n\"\n\n    return prompt\n</code></pre> <p>Integration with ML Pipeline</p> <p>These extracted ratings are combined with structured features (funding stage, headcount, investor quality) and fed into the LightGBM ordinal classifier (see \u00a75.1 Classification Pipeline).</p> <p>Error Handling</p> <ul> <li>Parsing failures: Return default ratings of 0.0 for all features</li> <li>Missing features: Handled gracefully; the model infers ratings based on available data</li> <li>Inconsistent data: The prompt instructs the model to handle missing or conflicting information</li> </ul>"},{"location":"external-integrations/external_integrations/#summary","title":"Summary","text":"<p>OMVision's external integrations form a cohesive data acquisition and enrichment pipeline:</p> <ol> <li>Accern provides structured signals with entity/event separation</li> <li>Gmail delivers unstructured newsletter content requiring full NER processing</li> <li>OpenAI extracts entities, filters noise, and enriches context from both sources</li> <li>Google Custom Search discovers URLs when entities lack web addresses</li> <li>Harmonic enriches entities with comprehensive structured metadata</li> </ol> <p>Each integration is implemented as a Dagster resource with authentication, error handling, and rate limiting tailored to the specific API's requirements. All integrations flow into the unified data pipeline (\u00a73), where signals are deduplicated, entities are enriched, and companies are classified for investment evaluation.</p> <p>Key Architectural Patterns:</p> <ul> <li>Resource-based dependency injection: All API clients are instantiated once per job and injected into operations</li> <li>Structured outputs: OpenAI and all Pydantic schemas ensure type-safe data exchange</li> <li>Rate limiting: Token bucket pattern prevents API quota exhaustion</li> <li>Error propagation: Most errors fail the job and trigger Dagster retries; graceful degradation only for non-critical operations</li> <li>Idempotent operations: All database writes use upsert patterns, allowing safe job re-runs</li> </ul> <p>Configuration Summary:</p> Integration Authentication Rate Limits Retry Strategy Accern JWT (query param) None Dagster job retry Harmonic API key (header) Not enforced Dagster job retry Gmail Service account OAuth 250 quota units/user/second Dagster job retry Google Custom Search API key (param) 100/minute (enforced by RateLimiter) Exponential backoff via RateLimiter OpenAI API key (header) Org-level RPM/TPM Dagster job retry <p>Environment Variables Reference:</p> <pre><code># OpenAI\nOPENAI_API_KEY=sk-...\n\n# Google Services\nGOOGLE_SEARCH_API_KEY=AIza...\nGOOGLE_SEARCH_ENGINE_ID=c0f...\nGMAIL_SERVICE_ACCOUNT_KEY=eyJhbG...  # Base64-encoded JSON\n\n# Harmonic\nHARMONIC_API_KEY=bvudc...\n</code></pre> <p>All credentials are stored in environment variables (locally in <code>.env.prod</code>, in production via AWS Secrets Manager) and never committed to version control.</p>"},{"location":"infrastructure-deployment/infrastructure_deployment/","title":"2. Infrastructure &amp; Deployment","text":"<p>OMVision runs as a containerized application deployed on AWS ECS (Elastic Container Service). The infrastructure is designed around Dagster's multi-service architecture, where job orchestration, execution, and business logic are separated into distinct containers that communicate via gRPC. This section describes how OMVision is packaged, deployed, and run across local development and production environments.</p> <p>The deployment strategy balances operational simplicity with production reliability: Docker Compose manages service definitions for both local and cloud environments, Poetry handles Python dependency management, and Alembic tracks database schema evolution. Understanding this infrastructure is essential for deploying updates, troubleshooting runtime issues, and extending the system's capacity.</p>"},{"location":"infrastructure-deployment/infrastructure_deployment/#21-docker-architecture","title":"2.1 Docker Architecture","text":"<p>OMVision uses a three-service Docker architecture based on Dagster's recommended deployment pattern for production systems. This separation of concerns allows the Dagster UI, job execution engine, and user code to scale and fail independently.</p> <p>[Diagram Placeholder: Docker Service Architecture]</p> <p>Suggested diagram: Three containers (dagster_webserver, dagster_daemon, deal_flow_code) connected via gRPC and shared PostgreSQL, with arrows showing gRPC communication and job queue flow</p> <pre><code>graph TB\n    subgraph Docker[\"Docker Compose Environment\"]\n        DW[\"dagster_webserver&lt;br/&gt;Port: 3000&lt;br/&gt;0.5 CPU | 2GB RAM\"]\n        DD[\"dagster_daemon&lt;br/&gt;Job Orchestrator&lt;br/&gt;0.5 CPU | 2GB RAM\"]\n        DC[\"deal_flow_code&lt;br/&gt;Code Server&lt;br/&gt;0.5 CPU | 2GB RAM\"]\n\n        DB[(\"PostgreSQL&lt;br/&gt;Port: 5432&lt;br/&gt;Metadata Store\")]\n    end\n\n    %% gRPC connections\n    DW --&gt;|gRPC| DC\n    DD --&gt;|gRPC| DC\n\n    %% Database connections\n    DW --&gt; DB\n    DD --&gt; DB\n    DC --&gt; DB\n\n    %% Styling\n    classDef webStyle fill:#e3f2fd,stroke:#1976D2,stroke-width:2px\n    classDef daemonStyle fill:#f3e5f5,stroke:#7B1FA2,stroke-width:2px\n    classDef codeStyle fill:#fff3e0,stroke:#F57C00,stroke-width:2px\n    classDef dbStyle fill:#e8f5e9,stroke:#388E3C,stroke-width:3px\n\n    class DW webStyle\n    class DD daemonStyle\n    class DC codeStyle\n    class DB dbStyle</code></pre>"},{"location":"infrastructure-deployment/infrastructure_deployment/#211-service-composition","title":"2.1.1 Service Composition","text":"<p>The system comprises three containerized services defined in <code>docker-compose.yaml</code>, each with a specific role in the orchestration workflow:</p>"},{"location":"infrastructure-deployment/infrastructure_deployment/#dagster_webserver","title":"dagster_webserver","text":"<p>The Dagster webserver provides the Dagit UI, a web-based interface for monitoring jobs, viewing run history, and inspecting pipeline execution. The webserver is stateless\u2014it does not contain any user-defined job code or execute jobs directly.</p> <p>Key Characteristics:</p> <ul> <li>Purpose: Serves the Dagit UI on port 3000 for job visualization and manual triggering</li> <li>Image: Built from <code>DockerfileDagster</code> and pushed to ECR as <code>dealflow/webserver</code></li> <li>Entrypoint: <code>dagster-webserver -h 0.0.0.0 -p 3000 -w workspace.yaml</code></li> <li>Workspace Configuration: Loads job definitions from the gRPC server specified in <code>workspace.yaml</code> (points to <code>deal_flow_code</code> service on port 4000)</li> <li>Job Submission: When a user manually triggers a job via Dagit, the run is enqueued to the <code>QueuedRunCoordinator</code> and later executed by the daemon</li> <li>Dependencies: Depends on <code>deal_flow_code</code> service being available for gRPC communication</li> </ul> <p>Resource Limits:</p> <ul> <li>CPU: 0.5 cores</li> <li>Memory: 2GB</li> </ul> <p>IAM Permissions (via <code>x-aws-role</code>):</p> <ul> <li><code>ecs:DescribeTasks</code> and <code>ecs:StopTask</code>: Monitor and stop ECS tasks</li> <li><code>iam:PassRole</code>: Pass IAM roles to ECS tasks during job execution</li> </ul>"},{"location":"infrastructure-deployment/infrastructure_deployment/#dagster_daemon","title":"dagster_daemon","text":"<p>The Dagster daemon is a long-running background service responsible for executing scheduled jobs, processing sensors, and dequeuing runs from the coordinator. It is the core execution engine of the system.</p> <p>Key Characteristics:</p> <ul> <li>Purpose: Dequeues runs from the <code>QueuedRunCoordinator</code> and launches them as ECS tasks using the <code>EcsRunLauncher</code></li> <li>Image: Built from <code>DockerfileDagster</code> and pushed to ECR as <code>dealflow/daemon</code></li> <li>Entrypoint: <code>dagster-daemon run</code></li> <li>Restart Policy: <code>on-failure</code> ensures the daemon restarts if it crashes</li> <li>Job Execution: When a scheduled job or sensor fires, the daemon creates a new ECS task running the <code>deal_flow_code</code> image with the specific job configuration</li> <li>Dependencies: Depends on <code>deal_flow_code</code> service for gRPC communication to load job definitions</li> </ul> <p>Resource Limits:</p> <ul> <li>CPU: 0.5 cores</li> <li>Memory: 2GB</li> </ul> <p>IAM Permissions (via <code>x-aws-role</code>):</p> <ul> <li><code>ecs:*</code> actions: Describe, register, run, and tag ECS tasks</li> <li><code>ec2:DescribeNetworkInterfaces</code>: Query VPC networking for task placement</li> <li><code>secretsmanager:*</code>: Retrieve secrets for injecting credentials into job runs</li> <li><code>iam:PassRole</code>: Pass IAM roles to newly launched ECS tasks</li> </ul> <p>Design Note: The daemon does not execute job logic itself\u2014it orchestrates ECS task creation. Each job runs in its own isolated container using the <code>deal_flow_code</code> image.</p>"},{"location":"infrastructure-deployment/infrastructure_deployment/#deal_flow_code","title":"deal_flow_code","text":"<p>The deal_flow_code service is a gRPC server that exposes OMVision's job definitions, resources, and business logic to the webserver and daemon. It contains all user-defined code (jobs, ops, assets, schedules, sensors) and serves as the authoritative source for pipeline definitions.</p> <p>Key Characteristics:</p> <ul> <li>Purpose: Runs a gRPC server on port 4000 that serves job metadata and code locations to other Dagster services</li> <li>Image: Built from <code>DockerfileAppCode</code> and pushed to ECR as <code>dealflow/code</code></li> <li>Code Location: Defined in <code>workspace.yaml</code> as <code>DealFlow</code> location at <code>deal_flow_code:4000</code></li> <li>Restart Policy: <code>always</code> ensures high availability\u2014if the gRPC server crashes, the container restarts immediately</li> <li>Job Execution: When the daemon launches a job, it spins up a new ECS task using this same <code>deal_flow_code</code> image, but with a different entrypoint that executes the specific job rather than running the gRPC server</li> </ul> <p>Resource Limits:</p> <ul> <li>CPU: 0.5 cores</li> <li>Memory: 2GB</li> </ul> <p>Environment Variable: The <code>DAGSTER_CURRENT_IMAGE</code> environment variable is set to the <code>deal_flow_code</code> image URI, instructing the <code>EcsRunLauncher</code> to use this image for job execution tasks.</p> <p>Design Rationale: Separating the gRPC server from job execution allows:</p> <ul> <li>The code location to remain available even during long-running jobs</li> <li>Jobs to run in isolated containers with independent resource limits</li> <li>Multiple code locations to be added in the future without redeploying the daemon or webserver</li> </ul>"},{"location":"infrastructure-deployment/infrastructure_deployment/#212-container-configurations","title":"2.1.2 Container Configurations","text":"<p>All three services share common configuration patterns defined in <code>docker-compose.yaml</code>:</p>"},{"location":"infrastructure-deployment/infrastructure_deployment/#platform-image-registry","title":"Platform &amp; Image Registry","text":"<ul> <li>Platform: All services specify <code>platform: linux/amd64</code> to ensure compatibility with AWS ECS (which uses x86_64 EC2 instances)</li> <li>Image Registry: Images are stored in AWS ECR (Elastic Container Registry) under the <code>010526247397.dkr.ecr.us-east-1.amazonaws.com/dealflow/</code> namespace</li> <li>Image Tags: Images use the <code>latest</code> tag in production; version tagging is not currently implemented</li> </ul>"},{"location":"infrastructure-deployment/infrastructure_deployment/#network-configuration","title":"Network Configuration","text":"<ul> <li>Docker Network: All services connect to a shared bridge network (<code>docker_network</code>) to enable inter-container communication</li> <li>Service Discovery: Containers reference each other by service name (e.g., <code>deal_flow_code</code>) which Docker resolves to internal IP addresses</li> <li>Port Exposure: Only the webserver exposes port 3000 to the host for UI access; the daemon and code server communicate internally via the Docker network</li> </ul>"},{"location":"infrastructure-deployment/infrastructure_deployment/#resource-limits","title":"Resource Limits","text":"<p>Resource limits are defined in the <code>deploy</code> section to prevent any single service from exhausting host resources:</p> Service CPU Limit Memory Limit dagster_webserver 0.5 cores 2GB dagster_daemon 0.5 cores 2GB deal_flow_code 0.5 cores 2GB <p>These limits apply to both local development (Docker Desktop enforces them loosely) and production ECS tasks (where they are strictly enforced).</p> <p>Design Note: The 2GB memory limit is sufficient for the gRPC server and daemon. Individual job runs launched by the daemon inherit these limits but can be overridden via ECS task definitions if specific jobs require more resources.</p>"},{"location":"infrastructure-deployment/infrastructure_deployment/#inter-service-communication","title":"Inter-Service Communication","text":"<p>The three services communicate as follows:</p> <ol> <li>Webserver \u2192 Code Server (gRPC): The webserver queries the code server to load job definitions, asset metadata, and pipeline structures for display in Dagit</li> <li>Daemon \u2192 Code Server (gRPC): The daemon queries the code server to load schedules, sensors, and job definitions for execution</li> <li>Daemon \u2192 ECS API: When executing a job, the daemon calls the AWS ECS API to launch a new task running the <code>deal_flow_code</code> image</li> <li>All Services \u2192 PostgreSQL: All services connect to a shared PostgreSQL instance for storing run history, event logs, schedules, and system state</li> </ol> <p>[Diagram Placeholder: Service Communication Flow]</p> <p>Suggested diagram: Webserver and Daemon both connecting to Code Server via gRPC, Daemon connecting to AWS ECS API, all three connecting to PostgreSQL</p>"},{"location":"infrastructure-deployment/infrastructure_deployment/#213-image-registry-ecr","title":"2.1.3 Image Registry (ECR)","text":"<p>OMVision's Docker images are stored in AWS Elastic Container Registry (ECR), a private container registry that integrates with ECS for secure image deployment.</p>"},{"location":"infrastructure-deployment/infrastructure_deployment/#ecr-repository-structure","title":"ECR Repository Structure","text":"<p>Three ECR repositories are configured under the AWS account <code>010526247397</code>:</p> Repository Purpose Dockerfile Update Frequency <code>dealflow/webserver</code> Dagster UI service <code>DockerfileDagster</code> Rarely (only on Dagster upgrades) <code>dealflow/daemon</code> Job execution coordinator <code>DockerfileDagster</code> Rarely (only on Dagster upgrades) <code>dealflow/code</code> User-defined jobs and business logic <code>DockerfileAppCode</code> Frequently (on every code change)"},{"location":"infrastructure-deployment/infrastructure_deployment/#image-build-process","title":"Image Build Process","text":"<p>Images are built locally using Docker Compose and pushed to ECR manually. The typical workflow is:</p> <ol> <li>Build images locally: <code>docker-compose build --no-cache</code> compiles all three images using their respective Dockerfiles</li> <li>Authenticate with ECR: <code>aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 010526247397.dkr.ecr.us-east-1.amazonaws.com</code></li> <li>Push images to ECR: Push the updated images (typically only <code>dealflow/code</code> changes frequently)</li> </ol> <p>Dockerfile Details (inferred from docker-compose.yaml):</p> <ul> <li>DockerfileDagster: Installs Dagster webserver and daemon packages, copies <code>dagster.yaml</code> and <code>dagster-prod.yaml</code> configuration files. Used for both webserver and daemon images.</li> <li>DockerfileAppCode: Installs application dependencies via Poetry, copies the entire <code>app/</code> directory containing jobs and resources. Used for the code server and job execution containers.</li> </ul>"},{"location":"infrastructure-deployment/infrastructure_deployment/#image-versioning-deployment","title":"Image Versioning &amp; Deployment","text":"<p>Currently, all images use the <code>latest</code> tag, meaning each push overwrites the previous version. This simplifies deployment but prevents rollbacks to previous versions.</p> <p>Operational Note: When deploying code changes, only the <code>dealflow/code</code> image needs to be rebuilt and pushed, since job logic lives exclusively in this image. The webserver and daemon images rarely change unless Dagster itself is upgraded.</p>"},{"location":"infrastructure-deployment/infrastructure_deployment/#22-aws-ecs-deployment","title":"2.2 AWS ECS Deployment","text":"<p>OMVision runs in production on AWS ECS (Elastic Container Service) with Fargate, a serverless container orchestration platform. ECS manages task scheduling, health monitoring, and automatic restarts, eliminating the need to provision or manage EC2 instances.</p> <p>[Diagram Placeholder: ECS Deployment Workflow]</p> <p>Suggested diagram: Developer pushes code \u2192 Build &amp; push to ECR \u2192 Docker context update \u2192 ECS pulls images \u2192 Tasks running in Fargate</p> <pre><code>sequenceDiagram\n    participant Dev as Developer&lt;br/&gt;(Local Machine)\n    participant Docker as Docker Build\n    participant ECR as AWS ECR&lt;br/&gt;(Image Registry)\n    participant CF as CloudFormation&lt;br/&gt;(IaC)\n    participant ECS as AWS ECS&lt;br/&gt;(Fargate)\n    participant Tasks as Running Tasks&lt;br/&gt;(Containers)\n\n    Dev-&gt;&gt;Docker: 1. docker-compose build --no-cache\n    Docker--&gt;&gt;Dev: Images built locally\n\n    Dev-&gt;&gt;Dev: 2. Export AWS credentials\n    Dev-&gt;&gt;ECR: 3. aws ecr get-login-password\n    ECR--&gt;&gt;Dev: Authentication token\n\n    Dev-&gt;&gt;ECR: 4. docker push dealflow/webserver:latest\n    Dev-&gt;&gt;ECR: 5. docker push dealflow/daemon:latest\n    Dev-&gt;&gt;ECR: 6. docker push dealflow/code:latest\n    ECR--&gt;&gt;ECR: Images stored in registry\n\n    Dev-&gt;&gt;CF: 7. docker --context dealflow compose up\n    CF-&gt;&gt;CF: Convert docker-compose.yaml&lt;br/&gt;to CloudFormation templates\n\n    CF-&gt;&gt;ECS: Create/Update Task Definitions\n    CF-&gt;&gt;ECS: Create/Update ECS Services\n\n    ECS-&gt;&gt;ECR: Pull latest images\n    ECR--&gt;&gt;ECS: dealflow/webserver:latest\n    ECR--&gt;&gt;ECS: dealflow/daemon:latest\n    ECR--&gt;&gt;ECS: dealflow/code:latest\n\n    ECS-&gt;&gt;Tasks: Launch Fargate Tasks\n    Tasks--&gt;&gt;Tasks: dagster_webserver running\n    Tasks--&gt;&gt;Tasks: dagster_daemon running\n    Tasks--&gt;&gt;Tasks: deal_flow_code running\n\n    Tasks--&gt;&gt;Dev: Deployment complete&lt;br/&gt;Services available at port 3000\n\n    Note over Dev,Tasks: Deployment Time: 3-5 minutes&lt;br/&gt;Rolling update strategy (zero downtime)</code></pre>"},{"location":"infrastructure-deployment/infrastructure_deployment/#221-ecs-task-definitions","title":"2.2.1 ECS Task Definitions","text":"<p>ECS task definitions are generated automatically by Docker Compose when deploying to the ECS context. Each service in <code>docker-compose.yaml</code> maps to an ECS task definition with the following properties:</p>"},{"location":"infrastructure-deployment/infrastructure_deployment/#task-definition-configuration","title":"Task Definition Configuration","text":"<ul> <li>Launch Type: Fargate (serverless\u2014no EC2 instance management required)</li> <li>Network Mode: <code>awsvpc</code> (each task gets its own elastic network interface and private IP)</li> <li>CPU &amp; Memory: Inherited from <code>docker-compose.yaml</code> deploy limits (0.5 vCPU, 2GB RAM per task)</li> <li>Execution Role: IAM role with permissions to pull images from ECR and retrieve secrets from Secrets Manager</li> <li>Task Role: IAM role with permissions defined in <code>x-aws-role</code> sections of <code>docker-compose.yaml</code> (ECS task management, secret retrieval)</li> </ul>"},{"location":"infrastructure-deployment/infrastructure_deployment/#iam-roles-permissions","title":"IAM Roles &amp; Permissions","text":"<p>ECS tasks require two types of IAM roles:</p> <p>Execution Role (used by ECS agent):</p> <ul> <li><code>ecr:GetAuthorizationToken</code>, <code>ecr:BatchCheckLayerAvailability</code>, <code>ecr:GetDownloadUrlForLayer</code>, <code>ecr:BatchGetImage</code>: Pull Docker images from ECR</li> <li><code>logs:CreateLogStream</code>, <code>logs:PutLogEvents</code>: Write container logs to CloudWatch</li> <li><code>secretsmanager:GetSecretValue</code>: Retrieve environment variables stored in AWS Secrets Manager</li> </ul> <p>Task Role (used by containerized application):</p> <ul> <li>Permissions specified in <code>x-aws-role</code> sections of <code>docker-compose.yaml</code></li> <li><code>dagster_webserver</code>: Permissions to describe and stop ECS tasks (for run management via UI)</li> <li><code>dagster_daemon</code>: Permissions to register, run, and tag ECS tasks (for launching job execution containers)</li> <li>Both roles include <code>iam:PassRole</code> to allow passing roles to newly created tasks</li> </ul> <p>Security Note: Task roles follow the principle of least privilege\u2014the webserver cannot launch new tasks, and the daemon cannot access secrets beyond what's needed for job execution.</p>"},{"location":"infrastructure-deployment/infrastructure_deployment/#networking-security-groups","title":"Networking &amp; Security Groups","text":"<p>ECS tasks run in a VPC with the following networking configuration:</p> <ul> <li>Subnets: Tasks are placed in private subnets with egress-only internet access via a NAT Gateway</li> <li>Security Groups: Inbound traffic is restricted to:<ul> <li>Port 3000 (Dagit UI) accessible from VPN or bastion host</li> <li>Port 4000 (gRPC) accessible only within the VPC for inter-service communication</li> </ul> </li> <li>Database Access: Tasks connect to an RDS PostgreSQL instance in the same VPC via security group rules</li> </ul>"},{"location":"infrastructure-deployment/infrastructure_deployment/#222-manual-deployment-process","title":"2.2.2 Manual Deployment Process","text":"<p>OMVision uses a manual deployment workflow based on Docker Compose's ECS integration. Deployment is triggered by engineers pushing updated images to ECR and updating the ECS stack.</p>"},{"location":"infrastructure-deployment/infrastructure_deployment/#deployment-steps","title":"Deployment Steps","text":"<p>The deployment process (documented in <code>README.md</code>) consists of the following steps:</p> <p>1. Create Docker ECS Context (one-time setup):</p> <pre><code>docker context create ecs dealflow\n</code></pre> <p>This creates a Docker context named <code>dealflow</code> that maps <code>docker compose</code> commands to ECS API calls.</p> <p>2. Build Images Locally:</p> <pre><code>docker-compose build --no-cache\n</code></pre> <p>Compiles all three images (<code>webserver</code>, <code>daemon</code>, <code>code</code>) from their respective Dockerfiles. The <code>--no-cache</code> flag ensures clean builds without stale layers.</p> <p>3. Authenticate with AWS:</p> <pre><code>export AWS_ACCESS_KEY_ID=\"&lt;access-key&gt;\"\nexport AWS_SECRET_ACCESS_KEY=\"&lt;secret-key&gt;\"\nexport AWS_SESSION_TOKEN=\"&lt;session-token&gt;\"\n</code></pre> <p>Temporary credentials are retrieved from the AWS console (assuming MFA-enabled IAM users). These credentials are valid for the duration of the session.</p> <p>4. Login to ECR:</p> <pre><code>aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 010526247397.dkr.ecr.us-east-1.amazonaws.com\n</code></pre> <p>Authenticates Docker CLI with ECR using a temporary password generated by the AWS CLI.</p> <p>5. Push Images to ECR:</p> <pre><code>docker push 010526247397.dkr.ecr.us-east-1.amazonaws.com/dealflow/daemon:latest\ndocker push 010526247397.dkr.ecr.us-east-1.amazonaws.com/dealflow/code:latest\ndocker push 010526247397.dkr.ecr.us-east-1.amazonaws.com/dealflow/webserver:latest\n</code></pre> <p>Pushes all three images to ECR. In practice, only <code>dealflow/code</code> is pushed regularly, as the other images rarely change.</p> <p>6. Update ECS Stack:</p> <pre><code>docker --context dealflow compose --project-name dealflow up\n</code></pre> <p>This command:</p> <ul> <li>Converts <code>docker-compose.yaml</code> to CloudFormation templates</li> <li>Submits the templates to AWS CloudFormation</li> <li>CloudFormation creates or updates ECS task definitions, services, load balancers, and networking resources</li> <li>ECS pulls the <code>latest</code> images from ECR and restarts tasks with the new code</li> </ul> <p>Deployment Time: The stack update typically takes 3-5 minutes. CloudFormation performs a rolling update, starting new tasks before stopping old ones to minimize downtime.</p>"},{"location":"infrastructure-deployment/infrastructure_deployment/#operational-notes","title":"Operational Notes","text":"<ul> <li>No CI/CD Pipeline: Deployment is currently manual. Engineers trigger deployments from their local machines after verifying changes in local development.</li> <li>Rollback Procedure: Since images use the <code>latest</code> tag, rollback requires re-pushing a previous image version to ECR and re-running the stack update.</li> <li>Deployment Verification: After deployment, engineers verify the update by:<ol> <li>Checking CloudFormation stack status in the AWS Console</li> <li>Accessing Dagit UI at <code>http://&lt;load-balancer-dns&gt;:3000</code> to confirm the webserver is running</li> <li>Monitoring CloudWatch Logs for any startup errors in the daemon or code server</li> <li>Verifying that scheduled jobs execute successfully</li> </ol> </li> </ul>"},{"location":"infrastructure-deployment/infrastructure_deployment/#223-environment-variables","title":"2.2.3 Environment Variables","text":"<p>OMVision requires numerous environment variables for database connections, API keys, and AWS resource identifiers. These variables are defined in a <code>.env.prod</code> file that is referenced by <code>docker-compose.yaml</code> via <code>env_file: \".env.prod\"</code>.</p> <p>Security Note: The <code>.env.prod</code> file is never committed to version control. In production, sensitive values are stored in AWS Secrets Manager and injected into ECS tasks via the <code>secrets</code> field in task definitions.</p>"},{"location":"infrastructure-deployment/infrastructure_deployment/#required-environment-variables","title":"Required Environment Variables","text":"<p>The following categories of environment variables are required for OMVision to function:</p> <p>Dagster Storage (PostgreSQL for run history, event logs, schedules):</p> <ul> <li><code>DAGSTER_LOGS_PG_USERNAME</code>: PostgreSQL username</li> <li><code>DAGSTER_LOGS_PG_PASSWORD</code>: PostgreSQL password</li> <li><code>DAGSTER_LOGS_PG_HOST</code>: PostgreSQL hostname (RDS endpoint)</li> <li><code>DAGSTER_LOGS_PG_DB</code>: Database name for Dagster metadata (separate from application data)</li> </ul> <p>Application Database:</p> <ul> <li><code>SYSTEM_DB_CONN_STRING</code>: SQLAlchemy connection string for the OMVision application database (e.g., <code>postgresql://user:pass@host:5432/omvision</code>)</li> </ul> <p>External API Keys:</p> <ul> <li><code>OPENAI_API_KEY</code>: OpenAI API key for NER and context extraction</li> <li><code>GOOGLE_SEARCH_API_KEY</code>: Google Custom Search API key</li> <li><code>GOOGLE_SEARCH_ENGINE_ID</code>: Custom Search Engine ID</li> <li><code>HARMONIC_API_KEY</code>: Harmonic API key for company enrichment</li> <li><code>GMAIL_SERVICE_ACCOUNT_KEY</code>: Base64-encoded Google service account JSON for Gmail API access</li> </ul> <p>AWS Resources (for S3 IO Manager):</p> <ul> <li><code>S3_BUCKET_NAME</code>: S3 bucket for intermediate data storage</li> <li><code>S3_BUCKET_REGION</code>: AWS region for the S3 bucket</li> <li><code>S3_ACCESS_KEY_ID</code>: IAM access key with S3 permissions</li> <li><code>S3_SECRET_ACCESS_KEY</code>: IAM secret key</li> </ul> <p>Dagster Runtime:</p> <ul> <li><code>DAGSTER_CURRENT_IMAGE</code>: Full ECR image URI for <code>deal_flow_code</code> (e.g., <code>010526247397.dkr.ecr.us-east-1.amazonaws.com/dealflow/code:latest</code>)</li> </ul>"},{"location":"infrastructure-deployment/infrastructure_deployment/#configuration-files","title":"Configuration Files","text":"<p>In addition to environment variables, Dagster's behavior is controlled by YAML configuration files:</p> <ul> <li>dagster.yaml: Defines storage backends (PostgreSQL for run storage, event logs, and schedules) used in both local and production environments</li> <li>dagster-prod.yaml: Production-specific configuration including:<ul> <li><code>DagsterDaemonScheduler</code>: Enables schedule execution via the daemon</li> <li><code>QueuedRunCoordinator</code>: Queues runs for asynchronous execution</li> <li><code>EcsRunLauncher</code>: Launches jobs as ECS Fargate tasks</li> </ul> </li> <li>workspace.yaml: Maps code locations to gRPC servers (points to <code>deal_flow_code:4000</code>)</li> </ul> <p>Configuration Hierarchy: Dagster merges <code>dagster.yaml</code> and <code>dagster-prod.yaml</code> at runtime, with production-specific settings overriding defaults.</p>"},{"location":"infrastructure-deployment/infrastructure_deployment/#23-local-development-setup","title":"2.3 Local Development Setup","text":"<p>Engineers developing OMVision run the system locally using Poetry for dependency management, Docker for PostgreSQL, and Dagster's CLI for job execution. The local environment mirrors production architecture but uses local containers instead of ECS tasks.</p>"},{"location":"infrastructure-deployment/infrastructure_deployment/#231-poetry-environment","title":"2.3.1 Poetry Environment","text":"<p>OMVision uses Poetry (a Python dependency and packaging manager) to manage project dependencies and virtual environments. Poetry simplifies dependency resolution and ensures reproducible builds across developer machines.</p>"},{"location":"infrastructure-deployment/infrastructure_deployment/#installation-setup","title":"Installation &amp; Setup","text":"<p>Prerequisites:</p> <ul> <li>Python 3.9\u20133.12 (specified in <code>pyproject.toml</code>)</li> <li>Poetry installed globally (<code>pip install poetry</code> or via official installer)</li> </ul> <p>Setup Steps:</p> <ol> <li>Activate Poetry Shell:</li> </ol> <pre><code>poetry shell\n</code></pre> <p>Creates and activates a virtual environment isolated from system Python packages.</p> <ol> <li>Install Dependencies:</li> </ol> <pre><code>poetry install\n</code></pre> <p>Reads <code>pyproject.toml</code> and installs all dependencies (Dagster, SQLAlchemy, OpenAI SDK, etc.) into the virtual environment. The <code>poetry.lock</code> file ensures all developers use identical dependency versions.</p>"},{"location":"infrastructure-deployment/infrastructure_deployment/#key-dependencies","title":"Key Dependencies","text":"<p>From <code>pyproject.toml</code>:</p> <ul> <li>Orchestration: <code>dagster</code>, <code>dagster-webserver</code>, <code>dagster-postgres</code> (core orchestration framework and storage backend)</li> <li>Database: <code>sqlalchemy</code>, <code>alembic</code> (ORM and migrations)</li> <li>Data Processing: <code>pandas</code>, <code>dagster-pandas</code> (dataframe operations and Dagster integration)</li> <li>ML &amp; NLP: <code>lightgbm</code>, <code>mord</code>, <code>openai</code>, <code>tiktoken</code> (classification model, ordinal regression, OpenAI API)</li> <li>APIs: <code>google-api-python-client</code>, <code>accern-data</code> (external integrations)</li> <li>Utilities: <code>pydantic</code>, <code>fuzzywuzzy</code>, <code>ratelimit</code>, <code>tenacity</code> (validation, string matching, rate limiting, retries)</li> </ul> <p>Development Tools: <code>black</code> (code formatting), <code>ipykernel</code> (Jupyter notebook support for exploration)</p>"},{"location":"infrastructure-deployment/infrastructure_deployment/#232-database-setup","title":"2.3.2 Database Setup","text":"<p>Local development requires a PostgreSQL instance for both Dagster metadata storage and OMVision application data. The simplest setup uses Docker to run a local PostgreSQL container.</p>"},{"location":"infrastructure-deployment/infrastructure_deployment/#local-postgresql-configuration","title":"Local PostgreSQL Configuration","text":"<p>Option 1: Docker Compose (recommended): Add a <code>postgres</code> service to <code>docker-compose.yaml</code> (or use a separate <code>docker-compose.local.yaml</code>):</p> <pre><code>postgres:\n  image: postgres:14\n  container_name: omvision_postgres\n  environment:\n    POSTGRES_USER: omvision\n    POSTGRES_PASSWORD: devpassword\n    POSTGRES_DB: omvision\n  ports:\n    - \"5432:5432\"\n  volumes:\n    - postgres_data:/var/lib/postgresql/data\n</code></pre> <p>Option 2: Managed PostgreSQL (e.g., local Postgres.app or Homebrew installation).</p>"},{"location":"infrastructure-deployment/infrastructure_deployment/#alembic-migrations","title":"Alembic Migrations","text":"<p>OMVision uses Alembic to version control database schema changes. Migrations are stored in the <code>alembic/versions/</code> directory and applied via the Alembic CLI.</p> <p>Applying Migrations (after installing dependencies and starting PostgreSQL):</p> <pre><code>alembic upgrade head\n</code></pre> <p>This command:</p> <ol> <li>Reads <code>alembic.ini</code> to locate migration scripts</li> <li>Connects to the database specified in <code>SYSTEM_DB_CONN_STRING</code> (from <code>.env</code> file)</li> <li>Applies all unapplied migrations in chronological order</li> <li>Updates the <code>alembic_version</code> table to track the current schema version</li> </ol> <p>Migration Files: Each migration is a Python script in <code>alembic/versions/</code> (e.g., <code>5615fc35a13a_phase_one_schema.py</code>, <code>ee99f2c24b09_add_indexes_for_company_table.py</code>). These files are generated via <code>alembic revision --autogenerate</code> and reviewed manually before committing.</p> <p>Environment Configuration: The <code>alembic/env.py</code> file:</p> <ul> <li>Loads the <code>SYSTEM_DB_CONN_STRING</code> from environment variables</li> <li>Imports SQLAlchemy models from <code>app.db.base</code> to enable autogeneration</li> <li>Configures online and offline migration modes</li> </ul>"},{"location":"infrastructure-deployment/infrastructure_deployment/#233-running-locally","title":"2.3.3 Running Locally","text":"<p>After setting up the Poetry environment and database, engineers run OMVision locally using a custom <code>make dev</code> command (defined in a Makefile, though the Makefile itself is not present in the repository snapshot).</p>"},{"location":"infrastructure-deployment/infrastructure_deployment/#local-development-workflow","title":"Local Development Workflow","text":"<p>Start the Development Environment:</p> <pre><code>make dev\n</code></pre> <p>This command (inferred from README.md) likely:</p> <ol> <li>Starts a local PostgreSQL container via Docker Compose</li> <li>Launches Dagster's <code>dagster dev</code> command, which starts:<ul> <li>Dagster webserver (Dagit UI) on port 3000</li> <li>Dagster daemon for executing schedules and sensors</li> <li>gRPC server hosting job definitions from <code>app/main.py</code></li> </ul> </li> </ol> <p>Accessing Dagit:</p> <p>Once running, engineers access the Dagit UI at <code>http://localhost:3000</code> to:</p> <ul> <li>View job definitions and schedules</li> <li>Manually trigger jobs for testing</li> <li>Inspect run logs and debug failures</li> <li>View asset lineage and data dependencies</li> </ul>"},{"location":"infrastructure-deployment/infrastructure_deployment/#local-vs-production-differences","title":"Local vs. Production Differences","text":"Aspect Local Development Production (ECS) Orchestration Single process (<code>dagster dev</code>) Three separate ECS tasks Job Execution Runs in the same process as the daemon Runs in isolated ECS tasks Configuration Uses <code>dagster.yaml</code> only Uses <code>dagster.yaml</code> + <code>dagster-prod.yaml</code> Run Launcher In-process execution <code>EcsRunLauncher</code> (Fargate tasks) Database Local PostgreSQL (Docker or native) AWS RDS PostgreSQL Secrets <code>.env</code> file AWS Secrets Manager <p>Design Note: The local environment executes jobs in-process for faster iteration, while production isolates each job in its own container for fault isolation and resource control.</p>"},{"location":"infrastructure-deployment/infrastructure_deployment/#development-best-practices","title":"Development Best Practices","text":"<ul> <li>Test Migrations Locally: Always run <code>alembic upgrade head</code> after pulling schema changes to ensure local database matches production</li> <li>Use <code>.env</code> for Secrets: Copy <code>.env.example</code> to <code>.env</code> and populate with development API keys (never commit <code>.env</code> to Git)</li> <li>Verify Jobs Before Deploying: Manually trigger jobs in local Dagit and inspect logs before pushing code to production</li> <li>Monitor Resource Usage: Jobs that work locally may OOM (out of memory) in production due to 2GB container limits\u2014test with production-scale data when possible</li> </ul> <p>Next Section: \u00a73 Data Pipeline &amp; Processing Logic (see <code>omvision_doc_structure.txt</code> for full outline)</p>"},{"location":"machine-learning-components/machine_learning_components/","title":"5. Machine Learning Components","text":"<p>This section documents the machine learning subsystem of OMVision, which classifies ingested companies based on their relevance to OMVC's investment thesis. The ML pipeline transforms enriched company data into structured features, applies an ordinal regression model, and produces ranked outputs that enable prioritized deal evaluation.</p> <p>The classification system operates as part of the <code>classify_ingested_companies</code> Dagster job (<code>app/jobs/classify_ingested_companies.py</code>), which runs after companies have been ingested and enriched from various data sources. The model outputs a discrete relevance score (ordinal rank) for each company, stored in the <code>Company.rank</code> field and used by the frontend for sorting and filtering.</p> <pre><code>flowchart TB\n    subgraph Input[\"Data Input\"]\n        DB[(PostgreSQL&lt;br/&gt;Unclassified Companies)]\n        DB --&gt; Split[Split Features]\n        Split --&gt; NL[Natural Language&lt;br/&gt;Features]\n        Split --&gt; Other[Structured&lt;br/&gt;Features]\n    end\n\n    subgraph Feature[\"Feature Engineering\"]\n        NL --&gt; Format[Format NL Text]\n        Format --&gt; OpenAI[OpenAI GPT-4o&lt;br/&gt;Feature Extraction]\n        OpenAI --&gt; Ratings[Numerical Ratings&lt;br/&gt;0.0-1.0 scale]\n        Other --&gt; Merge[Merge Features]\n        Ratings --&gt; Merge\n    end\n\n    subgraph Preprocess[\"Preprocessing\"]\n        Merge --&gt; DF[Combined DataFrame]\n        DF --&gt; Temporal[Temporal Feature&lt;br/&gt;Engineering]\n        Temporal --&gt; Impute[Missing Value&lt;br/&gt;Imputation]\n        Impute --&gt; Encode[Categorical&lt;br/&gt;Encoding]\n        Encode --&gt; Scale[MinMax&lt;br/&gt;Normalization]\n        Scale --&gt; SplitPath{Complete&lt;br/&gt;Data?}\n        SplitPath --&gt;|Yes| Primary[Primary Dataset&lt;br/&gt;All Features]\n        SplitPath --&gt;|No| Secondary[Secondary Dataset&lt;br/&gt;NL Features Only]\n    end\n\n    subgraph Models[\"Model Inference\"]\n        Primary --&gt; Model1[LightGBM Primary&lt;br/&gt;lightgbm_model.pkl]\n        Secondary --&gt; Model2[LightGBM Secondary&lt;br/&gt;lightgbm_nan_model.pkl]\n        Model1 --&gt; Pred1[Rank Predictions&lt;br/&gt;0-4]\n        Model2 --&gt; Pred2[Rank Predictions&lt;br/&gt;0-4]\n    end\n\n    subgraph Output[\"Data Output\"]\n        Pred1 --&gt; Update[Bulk Update&lt;br/&gt;Company.rank]\n        Pred2 --&gt; Update\n        Update --&gt; DB2[(PostgreSQL&lt;br/&gt;Classified Companies)]\n    end\n\n    style Input fill:#e1f5ff\n    style Feature fill:#fff4e1\n    style Preprocess fill:#f0e1ff\n    style Models fill:#e1ffe6\n    style Output fill:#ffe1e1</code></pre> <p>Key Design Principles:</p> <ul> <li>Dual-Model Architecture: A primary model uses all available features for maximum accuracy, while a secondary model handles companies with missing structured data using only NL-derived features</li> <li>LLM-Powered Feature Engineering: OpenAI's GPT-4o extracts numerical ratings from qualitative company descriptions, enabling the model to leverage textual signals that traditional feature engineering cannot capture</li> <li>Ordinal Classification: The model treats relevance as an ordered scale rather than independent classes, improving prediction quality for inherently ranked targets</li> <li>Reproducible Preprocessing: Deterministic feature transformations ensure consistent model behavior across runs and enable offline model training</li> </ul>"},{"location":"machine-learning-components/machine_learning_components/#51-classification-pipeline","title":"5.1 Classification Pipeline","text":"<p>The classification pipeline executes as a Dagster job with nine sequential operations that transform unclassified companies into ranked predictions. The job is scheduled to run daily after ingestion jobs complete, processing all companies where <code>Company.rank IS NULL</code>.</p> <p>Job Definition (<code>app/jobs/classify_ingested_companies.py</code>):</p> <pre><code>@job\ndef classify_ingested_companies():\n    nl_features, other_features = get_all_unclassified_companies()\n    formatted_features = format_company_nl_features(nl_features)\n    extracted_ratings = extract_numerical_features_from_nl(formatted_features)\n    input_df = prepare_input_dataframe(extracted_ratings, other_features)\n    primary_df, secondary_df = preprocess_input_features(input_df)\n\n    primary_classifications = get_primary_company_classes(primary_df)\n    secondary_classifications = get_secondary_company_classes(secondary_df)\n\n    update_company_classes_in_db(primary_classifications)\n    update_company_classes_in_db(secondary_classifications)\n</code></pre>"},{"location":"machine-learning-components/machine_learning_components/#511-feature-engineering","title":"5.1.1 Feature Engineering","text":"<p>Feature engineering transforms raw company data into model-ready inputs through three distinct stages: natural language feature extraction, structured feature preparation, and LLM-based feature transformation.</p>"},{"location":"machine-learning-components/machine_learning_components/#natural-language-features","title":"Natural Language Features","text":"<p>Natural language features capture qualitative information about companies that cannot be represented by metrics alone. These features are extracted from the <code>Company</code> and <code>CompanyMetric</code> tables and include:</p> <p>NL Feature Set (<code>CompanyNLFeatures</code> schema in <code>app/schemas/companies.py</code>):</p> Feature Type Source Description <code>description</code> <code>Text</code> <code>Company.description</code> Company description text from Harmonic <code>tags</code> <code>JSON Array</code> <code>Company.tags</code> Industry/category tags with type labels <code>highlights</code> <code>JSON Array</code> <code>CompanyMetric.highlights</code> Key milestones, partnerships, products <code>employee_highlights</code> <code>JSON Array</code> <code>CompanyMetric.employee_highlights</code> Notable employee backgrounds and skills <p>Feature Extraction (<code>get_all_unclassified_companies</code> op):</p> <pre><code>@op(out={\"nl_features\": Out(), \"other_features\": Out()})\ndef get_all_unclassified_companies(\n    db: DatabaseResource\n) -&gt; tuple[list[CompanyNLFeatures], list[CompanyOtherFeatures]]:\n    companies = db.fetch_unclassified_companies()  # WHERE rank IS NULL\n\n    company_nl_features = [\n        CompanyNLFeatures(\n            id=company.id,\n            tags=company.tags,\n            description=company.description,\n            employee_highlights=company.employee_highlights,\n            highlights=company.highlights\n        )\n        for company in companies\n    ]\n\n    return company_nl_features, company_other_features\n</code></pre> <p>NL Feature Formatting (<code>format_company_nl_features</code> op):</p> <p>Raw JSON structures are converted into concatenated text strings suitable for LLM processing:</p> <p>Tags Formatting: <pre><code>tags_set = set()\nfor tag in tags:\n    display_value = tag.get(\"display_value\", \"\").strip()\n    tag_type = tag.get(\"type\", \"\").strip()\n    if display_value and tag_type:\n        tags_set.add(f\"{display_value} ({tag_type})\")\n\ntags_str = \", \".join(sorted(tags_set))\n# Example: \"Healthcare (industry), B2B (business_model), SaaS (product_type)\"\n</code></pre></p> <p>Highlights Formatting: <pre><code>company_highlights_list = []\nfor item in company_highlights:\n    category = item.get(\"category\", \"\").strip()\n    text = item.get(\"text\", \"\").strip()\n    if category and text:\n        company_highlights_list.append(f\"{category}: {text}\")\n\ncompany_highlights_str = \"\\n\".join(company_highlights_list)\n# Example:\n# Partnership: Collaboration with Mayo Clinic for diagnostic trials\n# Product: Launched AI-powered imaging platform in Q2 2024\n</code></pre></p> <p>Employee Highlights Formatting (with summarization): <pre><code>category_counts = {}\nfor item in employee_highlights:\n    category = item.get(\"category\", \"\")\n    if category:\n        category_counts[category] = category_counts.get(category, 0) + 1\n\nsummary_lines = [f\"{count} employees with '{category}'\" \n                 for category, count in category_counts.items()]\nsummary_str = \"Employee Highlights Summary:\\n\" + \"\\n\".join(summary_lines)\n\nemployee_highlights_str = summary_str + \"\\n\\n\" + \"\\n\".join(individual_highlights)\n# Example:\n# Employee Highlights Summary:\n# 3 employees with 'Former FAANG'\n# 2 employees with 'PhD'\n#\n# Former FAANG: Worked at Google for 5 years as Senior Engineer\n# PhD: Stanford PhD in Computer Vision\n</code></pre></p>"},{"location":"machine-learning-components/machine_learning_components/#structured-features","title":"Structured Features","text":"<p>Structured features include quantitative metrics and categorical attributes extracted from the <code>Company</code> and <code>CompanyMetric</code> tables. These features represent firmographic data and funding information.</p> <p>Structured Feature Set (<code>CompanyOtherFeatures</code> schema):</p> Feature Type Source Description <code>headcount</code> <code>Integer</code> <code>CompanyMetric.headcount</code> Number of employees <code>funding_total</code> <code>Float</code> <code>CompanyMetric.funding.funding_total</code> Total capital raised (USD) <code>last_funding_type</code> <code>String</code> <code>CompanyMetric.funding.funding_stage</code> Most recent funding round type <code>last_funding_date</code> <code>DateTime</code> <code>CompanyMetric.funding.last_funding_at</code> Date of most recent funding <code>stage</code> <code>String</code> <code>CompanyMetric.stage</code> Current funding stage <code>country</code> <code>String</code> <code>Company.location.country</code> Company headquarters country <code>founding_date</code> <code>DateTime</code> <code>Company.founding_date.date</code> Company founding date <code>number_of_funding_rounds</code> <code>Integer</code> <code>CompanyMetric.funding.num_funding_rounds</code> Total funding events <code>web_traffic_change</code> <code>Float</code> <code>CompanyMetric.traction_metrics.web_traffic.90d_ago.percent_change</code> 90-day web traffic % change <p>Feature Extraction:</p> <pre><code>funding = company.funding if company.funding else {}\nlocation = company.location if company.location else {}\ntraction_metrics = company.traction_metrics if company.traction_metrics else {}\nfounding_date = company.founding_date if company.founding_date else {}\n\nweb_traffic = traction_metrics.get(\"web_traffic\", {})\nweb_traffic_90d_ago = web_traffic.get(\"90d_ago\", {})\n\ncompany_other_features.append(\n    CompanyOtherFeatures(\n        id=company.id,\n        last_funding_type=funding.get(\"funding_stage\", \"UNKNOWN\"),\n        country=location.get(\"country\", \"UNKNOWN\"),\n        stage=company.stage,\n        headcount=int(company.headcount or 0),\n        funding_total=funding.get(\"funding_total\", 0) or 0,\n        last_funding_date=funding.get(\"last_funding_at\"),\n        founding_date=founding_date.get(\"date\"),\n        number_of_funding_rounds=funding.get(\"num_funding_rounds\", 0) or 0,\n        web_traffic_change=web_traffic_90d_ago.get(\"percent_change\", 0)\n    )\n)\n</code></pre>"},{"location":"machine-learning-components/machine_learning_components/#llm-based-feature-transformation","title":"LLM-Based Feature Transformation","text":"<p>The <code>extract_numerical_features_from_nl</code> operation uses OpenAI's <code>gpt-4o-2024-08-06</code> model to transform formatted natural language features into numerical ratings. This approach enables the model to quantify qualitative signals that traditional feature engineering cannot capture.</p> <p>Transformation Prompt (defined in <code>app/resources/open_ai.py</code>):</p> <pre><code>You are a venture capital analyst. Given a company's description, highlights, tags, \nand employee highlights, rate the company on the following dimensions using a scale of 0-1:\n\n1. company_relevance: How relevant is this company to early-stage venture investment?\n   (0 = completely irrelevant, 1 = highly relevant startup)\n\n2. founder_strength: How strong is the founding team based on their backgrounds?\n   (0 = weak/unknown, 1 = exceptional pedigree)\n\n3. investor_relevance: How notable are the company's investors?\n   (0 = no notable investors, 1 = top-tier VCs)\n\n4. team_strength: How strong is the overall team composition?\n   (0 = weak/unknown, 1 = exceptional team)\n\nReturn ratings as a JSON object with keys: company_relevance, founder_strength, \ninvestor_relevance, team_strength. Each value must be a float between 0 and 1.\n</code></pre> <p>LLM Feature Extraction (<code>extract_numerical_features_from_nl</code> op):</p> <pre><code>@op\ndef extract_numerical_features_from_nl(\n    formatted_features: list[CompanyNLFeaturesFormatted],\n    openai: OpenAIResource\n) -&gt; list[CompanyExtractedRatingFeatures]:\n\n    extracted_ratings = []\n\n    for company in formatted_features:\n        # Construct user message with formatted features\n        user_message = f\"\"\"\n        Company: {company.description}\n\n        Tags: {company.tags}\n\n        Highlights:\n        {company.highlights}\n\n        Employee Highlights:\n        {company.employee_highlights}\n        \"\"\"\n\n        # Call OpenAI with structured output parsing\n        response = openai.extract_company_ratings(user_message)\n\n        extracted_ratings.append(\n            CompanyExtractedRatingFeatures(\n                id=company.id,\n                company_relevance=response.company_relevance,\n                founder_strength=response.founder_strength,\n                investor_relevance=response.investor_relevance,\n                team_strength=response.team_strength\n            )\n        )\n\n    return extracted_ratings\n</code></pre> <p>Output Schema (<code>CompanyExtractedRatingFeatures</code>):</p> Feature Type Range Description <code>company_relevance</code> <code>Float</code> [0, 1] Investment relevance score <code>founder_strength</code> <code>Float</code> [0, 1] Founding team quality score <code>investor_relevance</code> <code>Float</code> [0, 1] Investor pedigree score <code>team_strength</code> <code>Float</code> [0, 1] Overall team composition score <p>Rationale for LLM-Based Features:</p> <p>Traditional feature engineering struggles to quantify qualitative company descriptions. OpenAI's language models excel at semantic understanding and can reliably score companies based on textual descriptions, providing signals unavailable from structured data alone. The LLM acts as a feature extractor, not a classifier, ensuring reproducible numerical features that the downstream LightGBM model can learn from.</p>"},{"location":"machine-learning-components/machine_learning_components/#feature-merging","title":"Feature Merging","text":"<p>The <code>prepare_input_dataframe</code> operation combines LLM-extracted ratings with structured features into a unified pandas DataFrame suitable for preprocessing.</p> <pre><code>@op\ndef prepare_input_dataframe(\n    extracted_ratings: list[CompanyExtractedRatingFeatures],\n    other_features: list[CompanyOtherFeatures]\n) -&gt; pd.DataFrame:\n\n    # Convert to DataFrames\n    ratings_df = pd.DataFrame([r.dict() for r in extracted_ratings])\n    other_df = pd.DataFrame([f.dict() for f in other_features])\n\n    # Merge on company ID\n    merged_df = pd.merge(ratings_df, other_df, on=\"id\", how=\"inner\")\n\n    return merged_df\n</code></pre> <p>Final Feature Set (before preprocessing):</p> Feature Type Source <code>id</code> <code>Integer</code> Primary key <code>company_relevance</code> <code>Float</code> LLM-extracted <code>founder_strength</code> <code>Float</code> LLM-extracted <code>investor_relevance</code> <code>Float</code> LLM-extracted <code>team_strength</code> <code>Float</code> LLM-extracted <code>headcount</code> <code>Integer</code> Structured <code>funding_total</code> <code>Float</code> Structured <code>last_funding_type</code> <code>String</code> Structured <code>last_funding_date</code> <code>DateTime</code> Structured <code>stage</code> <code>String</code> Structured <code>country</code> <code>String</code> Structured <code>founding_date</code> <code>DateTime</code> Structured <code>number_of_funding_rounds</code> <code>Integer</code> Structured <code>web_traffic_change</code> <code>Float</code> Structured"},{"location":"machine-learning-components/machine_learning_components/#512-model-architecture","title":"5.1.2 Model Architecture","text":"<p>OMVision uses an ordinal classification approach to predict company relevance. Ordinal classification treats the target variable (rank) as an ordered categorical variable rather than arbitrary classes, improving prediction accuracy for inherently ranked outcomes.</p>"},{"location":"machine-learning-components/machine_learning_components/#ordinal-classifier-implementation","title":"Ordinal Classifier Implementation","text":"<p>The ordinal classifier (<code>app/utils/ordinal_classifier.py</code>) wraps a base estimator (LightGBM) and decomposes the ordinal regression problem into multiple binary classification sub-problems.</p> <p>Algorithm Overview:</p> <p>For K ordinal classes, the ordinal classifier trains K-1 binary classifiers. Each binary classifier predicts whether a company belongs to a rank greater than threshold i. </p> <p>Example with 4 ordinal classes (0, 1, 2, 3): - Classifier 1: P(y &gt; 0) - Classifier 2: P(y &gt; 1) - Classifier 3: P(y &gt; 2)</p> <p>The exact number of classes depends on the unique rank values present in the training data labels provided by the investment team.</p> <p>Class Definition (<code>app/utils/ordinal_classifier.py</code>):</p> <pre><code>import numpy as np\nfrom sklearn.base import BaseEstimator, clone\n\nclass OrdinalClassifier(BaseEstimator):\n    def __init__(self, clf):\n        self.clf = clf\n        self.clfs = {}\n\n    def fit(self, X, y):\n        self.unique_class = np.sort(np.unique(y))\n\n        if self.unique_class.shape[0] &gt; 2:\n            for i in range(self.unique_class.shape[0] - 1):\n                # For each k-1 ordinal value, fit a binary classification problem\n                binary_y = (y &gt; self.unique_class[i]).astype(np.uint8)\n                clf = clone(self.clf)\n                clf.fit(X, binary_y)\n                self.clfs[i] = clf\n\n    def predict_proba(self, X):\n        clfs_predict = {k: self.clfs[k].predict_proba(X) for k in self.clfs}\n        predicted = []\n\n        for i, y in enumerate(self.unique_class):\n            if i == 0:\n                # V1 = 1 - Pr(y &gt; V1)\n                predicted.append(1 - clfs_predict[i][:, 1])\n            elif i in clfs_predict:\n                # Vi = Pr(y &gt; Vi-1) - Pr(y &gt; Vi)\n                predicted.append(clfs_predict[i - 1][:, 1] - clfs_predict[i][:, 1])\n            else:\n                # Vk = Pr(y &gt; Vk-1)\n                predicted.append(clfs_predict[i - 1][:, 1])\n\n        return np.vstack(predicted).T\n\n    def predict(self, X):\n        return np.argmax(self.predict_proba(X), axis=1)\n\n    def score(self, X, y, sample_weight=None):\n        from sklearn.metrics import accuracy_score\n        _, indexed_y = np.unique(y, return_inverse=True)\n        return accuracy_score(indexed_y, self.predict(X), sample_weight=sample_weight)\n</code></pre> <p>Key Methods:</p> <ul> <li><code>fit(X, y)</code>: Trains K-1 binary classifiers, each predicting whether y exceeds threshold i</li> <li><code>predict_proba(X)</code>: Computes probability distribution across all K classes using the cumulative probability differences from binary classifiers</li> <li><code>predict(X)</code>: Returns the class with maximum probability (argmax of probability distribution)</li> </ul>"},{"location":"machine-learning-components/machine_learning_components/#base-estimator-lightgbm","title":"Base Estimator: LightGBM","text":"<p>The base estimator wrapped by the ordinal classifier is LightGBM (Light Gradient Boosting Machine), a gradient boosting framework optimized for efficiency and accuracy.</p> <p>LightGBM Configuration:</p> <p>The model is trained offline (outside the OMVision codebase) with the following characteristics:</p> <ul> <li>Algorithm: Gradient Boosting Decision Trees (GBDT)</li> <li>Objective: Binary classification (for each sub-problem in ordinal regression)</li> <li>Training Data: Historical companies with manual rank assignments (0-4) provided by the OMVC investment team</li> <li>Evaluation Metric: Accuracy (correct rank prediction)</li> <li>Hyperparameters: Tuned via cross-validation (specific values in trained model artifacts)</li> </ul> <p>Model Artifacts:</p> <p>Two trained models are serialized using <code>joblib</code> and stored in <code>app/constants/</code>:</p> Model File Description Features Used <code>lightgbm_model.pkl</code> Primary model All features (LLM ratings + structured features) <code>lightgbm_nan_model.pkl</code> Secondary model LLM ratings only (4 features) <p>Both models use the <code>OrdinalClassifier</code> wrapper to handle ordinal regression.</p>"},{"location":"machine-learning-components/machine_learning_components/#rank-meanings","title":"Rank Meanings","text":"<p>The model outputs a discrete rank representing investment relevance. Based on the system design, the typical rank scale is:</p> Rank Interpretation Frontend Behavior 0 Irrelevant Likely filtered out or deprioritized 1 Somewhat relevant Shown in lower priority tier 2 Relevant Standard evaluation queue 3 Highly relevant Priority review <p>These ranks enable the frontend to sort companies by predicted quality, focusing the investment team's attention on the most promising opportunities. The exact rank values and interpretations were defined during model training based on historical labels provided by the OMVC investment team.</p>"},{"location":"machine-learning-components/machine_learning_components/#513-prediction-process","title":"5.1.3 Prediction Process","text":"<p>The prediction process applies trained models to preprocessed features and persists rank predictions to the database. Two parallel classification operations handle companies with complete versus incomplete feature sets.</p>"},{"location":"machine-learning-components/machine_learning_components/#primary-classification","title":"Primary Classification","text":"<p>The primary classification path uses the full feature set (LLM ratings + structured features) for companies with complete data.</p> <p>Primary Classification Op (<code>get_primary_company_classes</code>):</p> <pre><code>@op\ndef get_primary_company_classes(\n    context,\n    df_input: pd.DataFrame,\n    ml: MLResource\n) -&gt; list[CompanyClassification]:\n    # Extract company IDs before dropping\n    company_ids = df_input[\"id\"].tolist()\n    df_input = df_input.drop(\"id\", axis=1)\n\n    # Predict using primary model\n    predictions = ml.primary_classify_companies(df_input)\n\n    # Map predictions back to company IDs\n    classifications = [\n        CompanyClassification(id=cid, rank=pred)\n        for cid, pred in zip(company_ids, predictions)\n    ]\n\n    context.log.info(\n        f\"Predicted classes for {len(classifications)} companies using all features.\"\n    )\n    return classifications\n</code></pre> <p>MLResource Primary Classification (<code>app/resources/ml_model.py</code>):</p> <pre><code>def primary_classify_companies(self, companies: pd.DataFrame) -&gt; list[float]:\n    model = joblib.load(\"app/constants/lightgbm_model.pkl\")\n    y_pred_prob = model.predict(companies, num_iteration=model.best_iteration)\n    y_pred = np.argmax(y_pred_prob, axis=1)  # Ordinal classes (typically 0, 1, 2, 3)\n    return y_pred.tolist()\n</code></pre> <p>Process:</p> <ol> <li>Load serialized model from disk using <code>joblib.load()</code></li> <li>Call <code>model.predict()</code> to generate probability distributions for each company</li> <li>Returns shape <code>(n_samples, K)</code> array with probabilities for each rank class</li> <li>Apply <code>argmax</code> to select the rank with highest probability</li> <li>Return predictions as a list of integers</li> </ol>"},{"location":"machine-learning-components/machine_learning_components/#secondary-classification","title":"Secondary Classification","text":"<p>The secondary classification path handles companies missing critical structured features (e.g., founding_date, last_funding_date). These companies are classified using only LLM-derived features.</p> <p>Secondary Classification Op (<code>get_secondary_company_classes</code>):</p> <pre><code>@op\ndef get_secondary_company_classes(\n    context,\n    df_input: pd.DataFrame,\n    ml: MLResource\n) -&gt; list[CompanyClassification]:\n    company_ids = df_input[\"id\"].tolist()\n    df_input = df_input.drop(\"id\", axis=1)\n\n    # Predict using secondary model (NL features only)\n    predictions = ml.secondary_classify_companies(df_input)\n\n    classifications = [\n        CompanyClassification(id=cid, rank=pred)\n        for cid, pred in zip(company_ids, predictions)\n    ]\n\n    context.log.info(\n        f\"Predicted classes for {len(classifications)} companies using NLP features.\"\n    )\n    return classifications\n</code></pre> <p>MLResource Secondary Classification:</p> <pre><code>def secondary_classify_companies(self, companies: pd.DataFrame) -&gt; list[float]:\n    model = joblib.load(\"app/constants/lightgbm_nan_model.pkl\")\n    y_pred_prob = model.predict(companies, num_iteration=model.best_iteration)\n    y_pred = np.argmax(y_pred_prob, axis=1)\n    return y_pred.tolist()\n</code></pre> <p>Secondary Model Features:</p> <p>The secondary model uses only the four LLM-extracted features:</p> <ul> <li><code>company_relevance</code></li> <li><code>founder_strength</code></li> <li><code>investor_relevance</code></li> <li><code>team_strength</code></li> </ul> <p>This ensures no company is left unclassified due to missing structured data, though predictions may be less accurate than the primary model.</p>"},{"location":"machine-learning-components/machine_learning_components/#database-persistence","title":"Database Persistence","text":"<p>Predicted ranks are bulk-updated in the <code>Company</code> table using the <code>update_company_classes_in_db</code> operation.</p> <p>Database Update Op:</p> <pre><code>@op\ndef update_company_classes_in_db(\n    context,\n    classifications: list[CompanyClassification],\n    db: DatabaseResource\n):\n    for classification in classifications:\n        db.update_company(classification.id, {\"rank\": classification.rank})\n\n    context.log.info(f\"Updated {len(classifications)} company ranks in database.\")\n</code></pre> <p>Database Implementation (<code>app/db/db_manager.py</code>):</p> <pre><code>def update_company(self, company_id: int, update_data: dict):\n    with self.get_session() as session:\n        session.query(Company).filter(Company.id == company_id).update(update_data)\n        session.commit()\n</code></pre> <p>After classification completes, all companies have a <code>rank</code> value (0-4), enabling the frontend to sort by predicted relevance.</p>"},{"location":"machine-learning-components/machine_learning_components/#52-data-preprocessing","title":"5.2 Data Preprocessing","text":"<p>Data preprocessing transforms raw features into normalized, encoded representations suitable for machine learning. The preprocessing pipeline handles missing values, temporal feature engineering, categorical encoding, and numerical scaling to ensure consistent model inputs.</p>"},{"location":"machine-learning-components/machine_learning_components/#521-feature-formatting","title":"5.2.1 Feature Formatting","text":"<p>The <code>preprocess_input_features</code> operation (<code>app/jobs/classify_ingested_companies.py</code>) applies a deterministic sequence of transformations to the merged feature DataFrame.</p>"},{"location":"machine-learning-components/machine_learning_components/#temporal-feature-engineering","title":"Temporal Feature Engineering","text":"<p>Date columns are converted to derived temporal features that capture recency and company age:</p> <p>Date Parsing:</p> <pre><code>df[\"last_funding_date\"] = pd.to_datetime(df[\"last_funding_date\"]).dt.tz_localize(None)\ndf[\"founding_date\"] = pd.to_datetime(df[\"founding_date\"]).dt.tz_localize(None)\n</code></pre> <p>Derived Features:</p> <pre><code># Days since last funding (recency signal)\ndf[\"days_since_funding\"] = (pd.Timestamp(\"today\") - df[\"last_funding_date\"]).dt.days\n\n# Company age in days\ndf[\"company_age\"] = (pd.Timestamp(\"today\") - df[\"founding_date\"]).dt.days.astype(float)\n\n# Drop original date columns\ndf.drop([\"last_funding_date\", \"founding_date\"], axis=1, inplace=True)\n</code></pre> <p>Rationale:</p> <ul> <li>Models cannot directly process datetime objects; temporal features must be numerical</li> <li><code>days_since_funding</code> captures funding recency (more recent funding may indicate traction)</li> <li><code>company_age</code> captures maturity (early-stage companies align with OMVC's thesis)</li> <li>Using \"days\" rather than \"years\" provides finer granularity for recent companies</li> </ul>"},{"location":"machine-learning-components/machine_learning_components/#missing-value-imputation","title":"Missing Value Imputation","text":"<p>Missing values are imputed using domain-appropriate defaults:</p> <p>Numerical Imputation (zero-fill):</p> <pre><code>df[\"headcount\"].fillna(0, inplace=True)\ndf[\"funding_total\"].fillna(0, inplace=True)\ndf[\"web_traffic_change\"].fillna(0, inplace=True)\ndf[\"number_of_funding_rounds\"].fillna(0, inplace=True)\n</code></pre> <p>Categorical Imputation (unknown category):</p> <pre><code>df[\"last_funding_type\"].fillna(\"UNKNOWN\", inplace=True)\ndf[\"country\"].fillna(\"UNKNOWN\", inplace=True)\ndf[\"stage\"].fillna(\"UNKNOWN\", inplace=True)\n</code></pre> <p>Rationale:</p> <ul> <li>Zero-filling for numerical features (headcount, funding) assumes missing data indicates no funding or very small team</li> <li>\"UNKNOWN\" category for categorical features preserves information about missingness without dropping rows</li> <li>LLM-extracted features (<code>company_relevance</code>, etc.) are never missing because they are always generated</li> </ul>"},{"location":"machine-learning-components/machine_learning_components/#categorical-encoding","title":"Categorical Encoding","text":"<p>Categorical variables are encoded into numerical representations using predefined mappings and label encoding.</p> <p>Funding Type Encoding:</p> <p>Funding types are mapped to ordinal categories based on investment stage:</p> <pre><code>df[\"last_funding_type\"] = df[\"last_funding_type\"].map(FUNDING_TYPE_MAPPING)\n</code></pre> <p>See \u00a75.2.2 for the complete <code>FUNDING_TYPE_MAPPING</code> definition.</p> <p>Stage Encoding:</p> <p>Company stages are mapped to risk-based ordinal categories:</p> <pre><code>df[\"stage\"] = df[\"stage\"].map(STAGE_MAPPING)\n</code></pre> <p>See \u00a75.2.2 for the complete <code>STAGE_MAPPING</code> definition.</p> <p>Country Label Encoding:</p> <p>Country names are label-encoded into integers using scikit-learn's <code>LabelEncoder</code>:</p> <pre><code>from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ndf[\"country\"] = le.fit_transform(df[\"country\"])\n</code></pre> <p>Rationale:</p> <ul> <li>Label encoding assigns arbitrary integers to countries (e.g., \"USA\" \u2192 0, \"UK\" \u2192 1)</li> <li>LightGBM treats these as categorical features, learning splits based on country groupings</li> <li>No ordinality is implied (unlike <code>FUNDING_TYPE_MAPPING</code> and <code>STAGE_MAPPING</code>)</li> </ul>"},{"location":"machine-learning-components/machine_learning_components/#numerical-scaling","title":"Numerical Scaling","text":"<p>All numerical features are normalized to the [0, 1] range using MinMax scaling:</p> <pre><code>from sklearn.preprocessing import MinMaxScaler\n\nnumerical_columns = df.select_dtypes(include=[np.number]).columns\nnumerical_columns = numerical_columns.difference([\"country\", \"id\"])\n\nscaler = MinMaxScaler()\ndf[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n</code></pre> <p>Scaled Features:</p> <ul> <li><code>company_relevance</code> (already 0-1 from LLM)</li> <li><code>founder_strength</code> (already 0-1 from LLM)</li> <li><code>investor_relevance</code> (already 0-1 from LLM)</li> <li><code>team_strength</code> (already 0-1 from LLM)</li> <li><code>headcount</code> (scaled from 0 to max observed headcount)</li> <li><code>funding_total</code> (scaled from 0 to max observed funding)</li> <li><code>days_since_funding</code> (scaled from 0 to max observed days)</li> <li><code>company_age</code> (scaled from 0 to max observed age)</li> <li><code>number_of_funding_rounds</code> (scaled from 0 to max observed rounds)</li> <li><code>web_traffic_change</code> (scaled from min to max observed % change)</li> </ul> <p>Rationale:</p> <ul> <li>MinMax scaling prevents features with large ranges (e.g., <code>funding_total</code>) from dominating gradient-based learning</li> <li>Scaling to [0, 1] aligns with LLM-extracted features, which are already in this range</li> <li>LightGBM is relatively robust to feature scaling due to its tree-based nature, but normalization improves convergence and model stability</li> </ul>"},{"location":"machine-learning-components/machine_learning_components/#dataset-splitting","title":"Dataset Splitting","text":"<p>After preprocessing, companies are split into two datasets based on data completeness:</p> <p>Primary Dataset (Complete Data):</p> <pre><code>df_cleaned = df.dropna()  # All features available\n</code></pre> <p>Companies in <code>df_cleaned</code> have no missing values after imputation and are classified using the primary model.</p> <p>Secondary Dataset (Incomplete Data):</p> <pre><code>df_dropped = df[df.isna().any(axis=1)][\n    [\"id\", \"company_relevance\", \"founder_strength\", \"investor_relevance\", \"team_strength\"]\n]\n</code></pre> <p>Companies in <code>df_dropped</code> have missing temporal features (founding_date or last_funding_date resulted in NaN values during temporal feature engineering) and are classified using only LLM-extracted features.</p> <p>Rationale:</p> <ul> <li>Companies founded very recently may not have <code>founding_date</code> recorded yet</li> <li>Companies without funding history have NULL <code>last_funding_date</code>, causing <code>days_since_funding</code> to be NaN</li> <li>Rather than dropping these companies, the secondary model ensures all ingested companies receive a rank</li> </ul>"},{"location":"machine-learning-components/machine_learning_components/#522-data-mappings","title":"5.2.2 Data Mappings","text":"<p>Categorical feature mappings encode domain knowledge about funding types and company stages into ordinal categories. These mappings are defined in <code>app/constants/company_mappings.py</code> and applied during preprocessing.</p>"},{"location":"machine-learning-components/machine_learning_components/#funding_type_mapping","title":"FUNDING_TYPE_MAPPING","text":"<p>Maps funding round types to ordinal categories representing investment stage progression. Lower values indicate earlier stages; higher values indicate non-traditional or unsuitable funding.</p> <p>Mapping Definition:</p> <pre><code>FUNDING_TYPE_MAPPING = {\n    # Non-Equity Funding (0)\n    \"GRANT\": 0,\n    \"NON_EQUITY_ASSISTANCE\": 0,\n    \"M_AND_A\": 0,\n    \"CORPORATE_ROUND\": 0,\n\n    # Early Stage Funding (1)\n    \"ANGEL_INDIVIDUAL\": 1,\n    \"ANGEL\": 1,\n    \"ACCELERATOR_INCUBATOR\": 1,\n    \"PRE_SEED\": 1,\n    \"PRE__SEED\": 1,\n    \"SEED\": 1,\n\n    # Venture Capital Funding (2)\n    \"SERIES_A\": 2,\n    \"SERIES_B\": 2,\n    \"SERIES_A1\": 2,\n    \"EARLY_STAGE_VC\": 2,\n    \"LATER_STAGE_VC\": 2,\n    \"EARLY_STAGE_SERIES_A\": 2,\n    \"LATER_STAGE_SERIES_A\": 2,\n    \"EARLY_STAGE_SERIES_A1\": 2,\n    \"SERIES_1\": 2,\n    \"SERIES_UNKNOWN\": 2,\n\n    # Debt Financing (3)\n    \"DEBT_GENERAL\": 3,\n    \"DEBT_FINANCING\": 3,\n    \"DEBT\": 3,\n    \"CONVERTIBLE_NOTE\": 3,\n\n    # Uncertain or Unknown (4)\n    \"CROWDFUNDING\": 4,\n    \"EQUITY_CROWDFUNDING\": 4,\n    \"INITIAL_COIN_OFFERING\": 4,\n    \"UNDISCLOSED\": 4,\n    \"UNKNOWN\": 4,\n    \"STRATEGIC\": 4,\n\n    # Out of Business (5)\n    \"OUT_OF_BUSINESS\": 5,\n}\n</code></pre> <p>Category Interpretations:</p> Category Funding Types Investment Thesis Alignment 0 Non-equity (grants, M&amp;A) Low relevance (non-traditional funding) 1 Angel, Pre-Seed, Seed High relevance (target stage for OMVC) 2 Series A, Series B, VC Moderate relevance (potentially too late) 3 Debt, Convertible Notes Low relevance (non-equity or distressed) 4 Crowdfunding, ICO, Unknown Low relevance (high risk or unclear) 5 Out of Business No relevance <p>Usage:</p> <p>Applied during preprocessing to convert string funding types to ordinal integers:</p> <pre><code>df[\"last_funding_type\"] = df[\"last_funding_type\"].map(FUNDING_TYPE_MAPPING)\n</code></pre>"},{"location":"machine-learning-components/machine_learning_components/#stage_mapping","title":"STAGE_MAPPING","text":"<p>Maps company stages to ordinal categories representing risk levels. Lower values indicate lower risk (successful exits); higher values indicate higher risk (early stage or failed companies).</p> <p>Mapping Definition:</p> <pre><code>STAGE_MAPPING = {\n    \"EXITED\": 0,            # Lowest risk, successful exit\n    \"SERIES_C\": 1,          # Slight risk, later stage with growth\n    \"SERIES_B\": 1,          # Slight risk, established product-market fit\n    \"SERIES_A\": 1,          # Slight risk, initial institutional funding\n    \"PRE_SEED\": 2,          # Higher risk, very early stage\n    \"SEED\": 2,              # Higher risk, gaining traction but still risky\n    \"STEALTH\": 3,           # Too high risk, early stage in stealth mode\n    \"VENTURE_UNKNOWN\": 3,   # Too high risk, unclear venture stage\n    \"UNKNOWN\": 3,           # Too high risk, uncertain about stage\n    \"OUT_OF_BUSINESS\": 3,   # Too high risk, worst-case scenario\n}\n</code></pre> <p>Category Interpretations:</p> Category Stages Investment Thesis Alignment 0 Exited No relevance (already acquired/IPO'd) 1 Series A-C Moderate relevance (established but possibly late) 2 Pre-Seed, Seed High relevance (target stage for OMVC) 3 Stealth, Unknown, Out of Business Low relevance (too risky or no information) <p>Usage:</p> <p>Applied during preprocessing to convert string stages to ordinal integers:</p> <pre><code>df[\"stage\"] = df[\"stage\"].map(STAGE_MAPPING)\n</code></pre>"},{"location":"machine-learning-components/machine_learning_components/#rationale-for-ordinal-mappings","title":"Rationale for Ordinal Mappings","text":"<p>Both <code>FUNDING_TYPE_MAPPING</code> and <code>STAGE_MAPPING</code> encode domain knowledge about which funding types and stages align with OMVC's investment thesis:</p> <ul> <li>Target Stage: Pre-Seed and Seed (early traction, institutional funding rounds)</li> <li>Too Early: Grants, non-equity assistance (pre-commercial)</li> <li>Too Late: Series B+ (already scaled beyond target stage)</li> <li>Unsuitable: Debt financing, crowdfunding, ICOs (non-traditional equity)</li> </ul> <p>Ordinal mappings enable the model to learn monotonic relationships (e.g., companies at Seed stage may be more relevant than those at Series C), improving prediction quality compared to arbitrary integer encoding.</p>"},{"location":"machine-learning-components/machine_learning_components/#53-model-resource","title":"5.3 Model Resource","text":"<p>The <code>MLResource</code> class (<code>app/resources/ml_model.py</code>) encapsulates model loading and inference logic, exposing a simple API for Dagster operations to consume predictions.</p>"},{"location":"machine-learning-components/machine_learning_components/#mlresource-class-definition","title":"MLResource Class Definition","text":"<p>Implementation (<code>app/resources/ml_model.py</code>):</p> <pre><code>from dagster import ConfigurableResource\nimport pandas as pd\nimport joblib\nimport numpy as np\n\n\nclass MLResource(ConfigurableResource):\n    \"\"\"\n    Resource for loading and executing LightGBM classification models.\n\n    Provides methods for primary classification (all features) and secondary \n    classification (NL features only).\n    \"\"\"\n\n    def primary_classify_companies(self, companies: pd.DataFrame) -&gt; list[float]:\n        \"\"\"\n        Classify companies using the primary model with all features.\n\n        Args:\n            companies: DataFrame with all preprocessed features (no 'id' column)\n\n        Returns:\n            List of predicted ranks (0-4) as floats\n        \"\"\"\n        model = joblib.load(\"app/constants/lightgbm_model.pkl\")\n        y_pred_prob = model.predict(companies, num_iteration=model.best_iteration)\n        y_pred = np.argmax(y_pred_prob, axis=1)\n        return y_pred.tolist()\n\n    def secondary_classify_companies(self, companies: pd.DataFrame) -&gt; list[float]:\n        \"\"\"\n        Classify companies using the secondary model with NL features only.\n\n        Args:\n            companies: DataFrame with NL-derived features only (no 'id' column)\n\n        Returns:\n            List of predicted ranks (0-4) as floats\n        \"\"\"\n        model = joblib.load(\"app/constants/lightgbm_nan_model.pkl\")\n        y_pred_prob = model.predict(companies, num_iteration=model.best_iteration)\n        y_pred = np.argmax(y_pred_prob, axis=1)\n        return y_pred.tolist()\n</code></pre>"},{"location":"machine-learning-components/machine_learning_components/#model-loading-pattern","title":"Model Loading Pattern","text":"<p>On-Demand Loading:</p> <p>Models are loaded from disk on each method call using <code>joblib.load()</code>.</p> <p>File Paths:</p> <p>Model artifacts are stored in <code>app/constants/</code> and loaded using relative paths:</p> <ul> <li><code>app/constants/lightgbm_model.pkl</code>: Primary model</li> <li><code>app/constants/lightgbm_nan_model.pkl</code>: Secondary model</li> </ul> <p>Joblib Serialization:</p> <ul> <li>Models are serialized using <code>joblib.dump()</code> during offline training</li> <li><code>joblib</code> is preferred over <code>pickle</code> for large numpy arrays (used internally by LightGBM)</li> <li>Deserialization is fast (~100ms for typical model sizes)</li> </ul>"},{"location":"machine-learning-components/machine_learning_components/#resource-configuration","title":"Resource Configuration","text":"<p>The <code>MLResource</code> is defined as a Dagster <code>ConfigurableResource</code>, enabling dependency injection into ops:</p> <p>Dagster Definitions (<code>app/__init__.py</code> or similar):</p> <pre><code>from dagster import Definitions\nfrom app.resources import MLResource\n\ndefs = Definitions(\n    jobs=[classify_ingested_companies],\n    resources={\n        \"ml\": MLResource(),\n        # ... other resources\n    }\n)\n</code></pre> <p>Op Usage:</p> <pre><code>@op\ndef get_primary_company_classes(\n    df_input: pd.DataFrame,\n    ml: MLResource  # Injected by Dagster\n) -&gt; list[CompanyClassification]:\n    predictions = ml.primary_classify_companies(df_input)\n    # ...\n</code></pre>"},{"location":"machine-learning-components/machine_learning_components/#best-iteration-usage","title":"Best Iteration Usage","text":"<p>The model loading pattern uses <code>model.best_iteration</code> when calling <code>predict()</code>:</p> <pre><code>y_pred_prob = model.predict(companies, num_iteration=model.best_iteration)\n</code></pre> <p>Rationale:</p> <ul> <li>LightGBM supports early stopping during training to prevent overfitting</li> <li><code>best_iteration</code> stores the iteration number where validation performance was optimal</li> <li>Using <code>num_iteration=model.best_iteration</code> ensures predictions use the same number of trees as validation, preventing overfitting at inference time</li> </ul>"},{"location":"system-overview/system_overview/","title":"1. System Overview","text":"<p>OMVision is OMVC's internal deal sourcing engine that automates the discovery and qualification of early-stage investment opportunities. By continuously monitoring multiple data sources and applying machine learning to filter and rank companies, OMVision enables the investment team to identify promising startups before they become widely known\u2014a critical advantage in competitive venture capital markets.</p> <p>This documentation provides technical context for engineers maintaining and extending the system. The following sections introduce the system's purpose, architecture, components, and technology stack at a conceptual level. Implementation details are covered in subsequent sections (\u00a72-\u00a78).</p>"},{"location":"system-overview/system_overview/#11-purpose-business-context","title":"1.1 Purpose &amp; Business Context","text":"<p>OMVC differentiates its deal sourcing strategy through proactive outbound research rather than relying solely on network referrals and inbound applications. However, manually reviewing thousands of signals from newsletters, news feeds, and databases is time-prohibitive for a four-person investment team. OMVision solves this bottleneck by automating signal ingestion, entity extraction, and relevance classification.</p> <p>The Pre-OMVision Workflow</p> <p>Before automation, OMVC's deal sourcing process required 1-4 hours daily per team member and covered only a fraction of available data sources:</p> <ol> <li>Manually review signals from Accern dashboards, newsletters, and LinkedIn Sales Navigator</li> <li>Identify company names mentioned in each signal and visit their websites</li> <li>Search CBI/Harmonic to check for prior relationships</li> <li>Add promising companies to deal flow collections with appropriate labels</li> </ol> <p>This manual process left most data sources unused and caused the team to miss high-quality opportunities.</p> <p>OMVision's Solution</p> <p>OMVision automates the entire workflow, reducing daily deal review time to approximately 30 minutes while processing all available data sources. The system:</p> <ul> <li>Ingests signals automatically from Accern (news/event feeds), Gmail (VC newsletters), and Harmonic (saved company searches)</li> <li>Extracts and enriches entities using NER, web search for URLs, and the Harmonic API for company/founder data</li> <li>Filters irrelevant companies based on geography, funding stage, team size, and other investment thesis criteria</li> <li>Classifies relevance using a machine learning model trained on OMVC's historical deal flow decisions</li> <li>Surfaces actionable opportunities through a frontend application with custom tracking columns and deal flow management features</li> </ul> <p>Key Business Objectives</p> <ul> <li>Comprehensive Coverage: Process 100% of available deal flow sources daily (currently ~100-200 relevant companies per day) rather than cherry-picking high-yield sources</li> <li>Earlier Discovery: Identify companies at founding, product launch, or initial fundraising stages before they appear in mainstream VC channels</li> <li>Scalable Filtering: Use ML classification to surface the top 10-20 companies daily, enabling the team to evaluate more opportunities without increasing time investment</li> <li>Historical Context: Maintain a searchable database of all signals and entities to understand why companies appeared and track them over time</li> <li>Reduced Manual Work: Eliminate repetitive research tasks (finding URLs, checking for duplicates, enriching company data) so the team focuses on evaluation and outreach</li> </ul>"},{"location":"system-overview/system_overview/#12-high-level-architecture","title":"1.2 High-Level Architecture","text":"<p>OMVision follows a multi-stage pipeline architecture orchestrated by Dagster. Data flows through distinct stages\u2014ingestion, extraction, enrichment, classification, and persistence\u2014with each stage designed to be modular and independently testable.</p> <p>[Diagram Placeholder: End-to-End Data Flow]</p> <p>Suggested diagram: Data Sources (Accern, Gmail, Harmonic) \u2192 Signal Ingestion \u2192 Entity Extraction (NER + URL Enrichment) \u2192 Data Enrichment (Harmonic API) \u2192 Classification (ML Model) \u2192 Database Storage \u2192 Frontend Application</p> <pre><code>flowchart TD\n    %% Data Sources\n    subgraph DS[Data Sources]\n        DS1[Accern&lt;br/&gt;&lt;small&gt;News &amp; event feeds&lt;/small&gt;]\n        DS2[Gmail&lt;br/&gt;&lt;small&gt;VC newsletters&lt;/small&gt;]\n        DS3[Harmonic&lt;br/&gt;&lt;small&gt;Saved searches&lt;/small&gt;]\n    end\n\n    %% Signal Ingestion\n    subgraph SI[Signal Ingestion]\n        SI1[Dagster Jobs&lt;br/&gt;&lt;small&gt;Scheduled hourly/daily&lt;/small&gt;]\n    end\n\n    %% Entity Extraction\n    subgraph EE[Entity Extraction]\n        EE1[NER OpenAI GPT-4o&lt;br/&gt;&lt;small&gt;Extract companies &amp; people&lt;/small&gt;]\n        EE2[LLM Filtering&lt;br/&gt;&lt;small&gt;Remove Fortune 500, etc.&lt;/small&gt;]\n        EE3[Context Extraction&lt;br/&gt;&lt;small&gt;Entity descriptors&lt;/small&gt;]\n    end\n\n    %% URL Enrichment\n    subgraph UE[URL Enrichment]\n        UE1[Google Search API&lt;br/&gt;&lt;small&gt;Find company websites&lt;/small&gt;]\n        UE2[Fuzzy Matching&lt;br/&gt;&lt;small&gt;Score &amp; select best match&lt;/small&gt;]\n        UE3[LinkedIn Profiles&lt;br/&gt;&lt;small&gt;Match people to profiles&lt;/small&gt;]\n    end\n\n    %% Data Enrichment\n    subgraph DE[Data Enrichment]\n        DE1[Harmonic API&lt;br/&gt;&lt;small&gt;Company metadata, funding, team, investors&lt;/small&gt;]\n    end\n\n    %% Filtering &amp; Validation\n    subgraph FV[Filtering &amp; Validation]\n        FV1[Investment Criteria&lt;br/&gt;&lt;small&gt;Geography, stage, size, exclusion lists&lt;/small&gt;]\n    end\n\n    %% ML Classification\n    subgraph MC[ML Classification]\n        MC1[Feature Engineering&lt;br/&gt;&lt;small&gt;NL + structured features&lt;/small&gt;]\n        MC2[LightGBM Model&lt;br/&gt;&lt;small&gt;Ordinal relevance scoring&lt;/small&gt;]\n    end\n\n    %% Persistence\n    subgraph P[Persistence]\n        P1[PostgreSQL Database&lt;br/&gt;&lt;small&gt;Signals, companies, people, classifications&lt;/small&gt;]\n    end\n\n    %% Frontend Application\n    subgraph FA[Frontend Application]\n        FA1[Web Interface&lt;br/&gt;&lt;small&gt;Investment team reviews &amp; tracks deals&lt;/small&gt;]\n    end\n\n    %% Connections\n    DS --&gt; SI\n    SI --&gt; EE\n    EE --&gt; UE\n    UE --&gt; DE\n    DE --&gt; FV\n    FV --&gt; MC\n    MC --&gt; P\n    P --&gt; FA\n\n    %% Styling\n    classDef sourceStyle fill:#e3f2fd,stroke:#2196F3,stroke-width:2px\n    classDef ingestionStyle fill:#f3e5f5,stroke:#9C27B0,stroke-width:2px\n    classDef extractionStyle fill:#fce4ec,stroke:#E91E63,stroke-width:2px\n    classDef enrichmentStyle fill:#fff3e0,stroke:#FF9800,stroke-width:2px\n    classDef filterStyle fill:#e0f2f1,stroke:#009688,stroke-width:2px\n    classDef mlStyle fill:#e8f5e9,stroke:#4CAF50,stroke-width:2px\n    classDef storageStyle fill:#ffebee,stroke:#F44336,stroke-width:2px\n    classDef frontendStyle fill:#fffde7,stroke:#FBC02D,stroke-width:2px\n\n    class DS sourceStyle\n    class SI ingestionStyle\n    class EE extractionStyle\n    class UE,DE enrichmentStyle\n    class FV filterStyle\n    class MC mlStyle\n    class P storageStyle\n    class FA frontendStyle</code></pre>"},{"location":"system-overview/system_overview/#data-flow-overview","title":"Data Flow Overview","text":"<ol> <li>Signal Ingestion: Scheduled Dagster jobs fetch raw data from external sources on daily or hourly schedules:<ul> <li>Accern: API calls retrieve news articles and event-based signals matching pre-configured use cases (fundraising announcements, product launches, executive changes, etc.)</li> <li>Gmail: IMAP client reads emails sent to a dedicated newsletters@omvc.co inbox over the past 24 hours</li> <li>Harmonic Searches: API queries return net-new companies from saved searches (e.g., \"Seed-stage AI companies in North America founded in 2024\")</li> </ul> </li> <li>Entity Extraction: For signal-based sources (Accern and Gmail), the system identifies companies and people mentioned in unstructured text:<ul> <li>Named Entity Recognition (NER): OpenAI GPT-4o extracts organization and person entities from signal text using structured output formatting</li> <li>LLM Filtering: A second OpenAI call removes obviously irrelevant entities (Fortune 500 companies, celebrities, government agencies, etc.) to reduce noise early in the pipeline</li> <li>Context Extraction: OpenAI provides descriptive context for each entity (e.g., \"AI-powered accounting software\" for a company, \"co-founder and CEO\" for a person) to improve downstream URL matching accuracy</li> </ul> </li> <li>URL Enrichment: Since Harmonic's enrichment API requires URLs rather than company names, the system must find web addresses for extracted entities:<ul> <li>Web Search: Google Custom Search API queries are constructed using entity names and descriptive context</li> <li>Fuzzy Matching: A custom algorithm scores search results based on name similarity and context relevance, selecting the best match</li> <li>People Profiles: LinkedIn profile URLs are matched similarly, limiting search scope to <code>linkedin.com/in</code> domain</li> </ul> </li> <li>Data Enrichment: Once URLs are obtained, the Harmonic API enriches entities with structured metadata:<ul> <li>Company Data: Description, founding date, location, funding history, investors, headcount, traction metrics, team members, and highlights</li> <li>People Data: LinkedIn profiles, work history, education, current positions, and network connections to OMVC team members</li> <li>For Harmonic-sourced searches, entities come pre-enriched and skip the URL matching step</li> </ul> </li> <li>Filtering &amp; Validation: Enriched entities are filtered against OMVC's investment criteria before database insertion:<ul> <li>Geography: Exclude companies outside target markets (primarily North America, Western Europe)</li> <li>Stage: Filter out companies beyond target funding stages (typically pre-Seed through Series A)</li> <li>Team Size: Exclude companies above headcount thresholds (e.g., &gt;75 employees indicates post-PMF scaling stage)</li> <li>Funding: Remove companies that have raised beyond target amounts (e.g., &gt;$15M total funding)</li> <li>Manual Exclusion Lists: Check against user-maintained blacklists of irrelevant companies</li> </ul> </li> <li>ML Classification: A machine learning model scores remaining companies on relevance to OMVC's investment thesis:<ul> <li>Feature Engineering: Extract natural language features (company description, highlights, employee bios) and structured features (funding stage, investor quality, team strength)</li> <li>Ordinal Regression: LightGBM model outputs probability distribution across discrete relevance tiers</li> <li>Score Storage: Classification results are persisted to enable ranking and filtering in the frontend</li> </ul> </li> <li>Persistence: All entities, signals, and metadata are stored in PostgreSQL with full relational integrity:<ul> <li>Signals linked to their originating data sources</li> <li>Companies and People linked to the signals where they were discovered</li> <li>Metrics and Classifications stored separately to support historical tracking and model retraining</li> <li>Custom Columns: User-defined fields (watchlists, deal flow stage, comments) persisted to support workflow tracking</li> </ul> </li> <li>Frontend Consumption: A separate web application (outside the scope of this documentation) queries the database to present companies, people, and signals to the investment team with filtering, sorting, and custom field management capabilities.</li> </ol>"},{"location":"system-overview/system_overview/#key-architectural-characteristics","title":"Key Architectural Characteristics","text":"<ul> <li>Event-Driven Scheduling: Each data source runs on its own Dagster schedule (e.g., Accern hourly, Gmail daily, Harmonic searches daily), triggering downstream jobs via sensors</li> <li>Idempotent Operations: Ingestion jobs use upsert patterns and unique constraints to safely re-run without creating duplicate records</li> <li>Decoupled Stages: Extraction, enrichment, and classification operate independently, allowing failures in one stage to be retried without reprocessing earlier stages</li> <li>Stateful Processing: The PostgreSQL database serves as the system's persistent state, enabling incremental updates, historical queries, and audit trails</li> <li>Rate-Limited External Calls: All API integrations implement rate limiting to respect third-party quotas and avoid throttling</li> </ul>"},{"location":"system-overview/system_overview/#13-key-components-summary","title":"1.3 Key Components Summary","text":"<p>OMVision's codebase is organized into logical modules corresponding to pipeline stages. Below is a brief overview of each major component. Detailed explanations appear in later sections (see \u00a72-\u00a77).</p>"},{"location":"system-overview/system_overview/#core-orchestration","title":"Core Orchestration","text":"<ul> <li>Dagster Jobs &amp; Ops (<code>main.py</code>, <code>workspace.yaml</code>, <code>dagster.yaml</code>): Defines ETL workflows, schedules, and sensors. Each data source has dedicated jobs (e.g., <code>ingest_signals_from_accern</code>, <code>ingest_companies_from_searches</code>) that chain together via run status sensors.</li> <li>Operation Configuration (<code>op_config.py</code>): Provides reusable configuration patterns for common operations like source lookups and watchlist management.</li> </ul>"},{"location":"system-overview/system_overview/#data-ingestion-modules","title":"Data Ingestion Modules","text":"<ul> <li>Accern Ingestion (<code>ingest_signals_from_accern.py</code>, <code>accern_api.py</code>, <code>accern.py</code>): Fetches news and event signals from Accern's NLP platform, filters by relevance, and stores raw signals with extracted entity tags.</li> <li>Email Ingestion (<code>ingest_signals_from_emails.py</code>, <code>mail_client.py</code>, <code>mail.py</code>): Connects to Gmail via IMAP, parses newsletter emails, and extracts signals from message bodies.</li> <li>Harmonic Search Ingestion (<code>ingest_companies_from_searches.py</code>, <code>ingest_people_from_searches.py</code>): Retrieves companies and people from Harmonic's saved search API, which returns entities matching pre-defined criteria (e.g., \"recently founded AI companies\").</li> </ul>"},{"location":"system-overview/system_overview/#entity-extraction-enrichment","title":"Entity Extraction &amp; Enrichment","text":"<ul> <li>Entity Extraction from Signals (<code>ingest_companies_from_signals.py</code>, <code>ingest_people_from_signals.py</code>): Processes stored signals to extract company and person entities, using Harmonic's search API to match entities and enrich them with structured data.</li> <li>URL Enrichment (<code>web_search.py</code>): Custom resource that uses Google Custom Search API with fuzzy matching logic to find company websites and LinkedIn profiles for entities extracted from unstructured text.</li> <li>Harmonic API Client (<code>harmonic.py</code>, <code>harmonic_api.py</code>): Wrapper for Harmonic's company and people data endpoints, including search, enrichment, and watchlist management operations.</li> <li>OpenAI Integration (<code>open_ai.py</code>, <code>prompt_definitions.py</code>): Structured prompts for NER, entity filtering, context extraction, and feature rating (used in ML classification).</li> </ul>"},{"location":"system-overview/system_overview/#machine-learning-classification","title":"Machine Learning &amp; Classification","text":"<ul> <li>Ordinal Classifier (<code>ordinal_classifier.py</code>, <code>ml_model.py</code>): Multi-class ordinal regression model that scores companies on a discrete relevance scale. The model is trained offline and loaded at runtime.</li> <li>Classification Job (<code>classify_ingested_companies.py</code>): Dagster job that applies the classifier to newly ingested companies, extracts NL and structured features, and persists predictions.</li> <li>Feature Engineering (<code>dataframes.py</code>, <code>company_mappings.py</code>): Helper functions for transforming company data into model-ready features, including label encoding and normalization.</li> </ul>"},{"location":"system-overview/system_overview/#data-layer-persistence","title":"Data Layer &amp; Persistence","text":"<ul> <li>Database Models (<code>models.py</code>, <code>base.py</code>): SQLAlchemy ORM definitions for all entities (Company, Person, Signal, DataSource, List, CompanyMetric, etc.). Defines relationships, constraints, and indexes.</li> <li>Database Manager (<code>db_manager.py</code>): Provides session management, connection pooling, and utility functions (bulk inserts, upserts, queries) for database access.</li> <li>Alembic Migrations (<code>alembic.ini</code>, <code>env.py</code>, migration scripts): Version-controlled schema changes ensuring consistent database structure across development, staging, and production environments.</li> </ul>"},{"location":"system-overview/system_overview/#supporting-utilities","title":"Supporting Utilities","text":"<ul> <li>Rate Limiting (<code>rate_limiter.py</code>): Token bucket implementation to enforce API rate limits and prevent quota exhaustion.</li> <li>Company Filtering (<code>company_filters.py</code>, <code>company_filter_list.py</code>): Logic for excluding irrelevant companies based on blacklists, hardcoded rules, and user-maintained exclusion lists.</li> <li>Data Sources Management (<code>data_sources.py</code>, <code>upsert_data_sources.py</code>): Configuration and persistence of data source metadata (API endpoints, credentials, channels).</li> <li>Custom Columns (<code>persist_custom_columns_data.py</code>): Manages user-defined fields that track deal flow stage, watchlists, comments, and other workflow-specific data.</li> </ul>"},{"location":"system-overview/system_overview/#14-technology-stack","title":"1.4 Technology Stack","text":"<p>OMVision is built on a modern Python-based data engineering stack optimized for flexibility, developer productivity, and integration with OMVC's infrastructure.</p>"},{"location":"system-overview/system_overview/#core-technologies","title":"Core Technologies","text":"Component Technology Rationale Orchestration Dagster Pipeline orchestration with built-in scheduling, monitoring, logging, and retry logic. Dagit UI provides observability into job runs and data lineage. Language Python 3.11+ Standard for data engineering and ML; rich ecosystem for API integrations, NLP, and data processing. Database PostgreSQL 14+ Reliable relational database with strong JSONB support for semi-structured data, full-text search capabilities, and transactional integrity. ORM SQLAlchemy 2.x Declarative ORM for type-safe database interactions with relationship management and migration support. Migrations Alembic Version control for database schema changes, integrated with SQLAlchemy for autogeneration of migration scripts. Containerization Docker &amp; Docker Compose Local development environment matches production; ensures reproducibility across team members' machines. Deployment AWS ECS (Fargate) Managed container orchestration for running Dagster daemon and scheduled jobs in production. Configuration YAML (<code>dagster.yaml</code>, <code>dagster-prod.yaml</code>, <code>workspace.yaml</code>) Environment-specific settings for Dagster jobs, database connections, and resource configurations."},{"location":"system-overview/system_overview/#key-libraries-dependencies","title":"Key Libraries &amp; Dependencies","text":"<p>See <code>requirements.txt</code> and <code>pyproject.toml</code> for the complete dependency list. Notable includes:</p> <ul> <li>Data Processing: <code>pandas</code>, <code>numpy</code> for tabular data manipulation and feature engineering</li> <li>HTTP Clients: <code>requests</code> for API communication with Accern and Harmonic</li> <li>ML &amp; NLP: <code>lightgbm</code> for ordinal classification, <code>openai</code> SDK for GPT API access, <code>fuzzywuzzy</code> for string matching in URL enrichment</li> <li>Email Parsing: <code>imaplib</code> (stdlib), <code>email</code> (stdlib) for IMAP integration and MIME parsing</li> <li>API Integrations: <code>googleapiclient</code> for Google Custom Search API</li> <li>Validation: <code>pydantic</code> for data schema validation and type checking</li> <li>Utilities: <code>python-dotenv</code> for environment variable management</li> </ul>"},{"location":"system-overview/system_overview/#infrastructure-deployment","title":"Infrastructure &amp; Deployment","text":"<ul> <li>Local Development: <code>docker-compose.yaml</code> defines PostgreSQL container and Dagster daemon for testing pipelines locally. Developers can run full workflows on their machines.</li> <li>Production Environment:<ul> <li>Dagster: Runs as a long-lived ECS service with the Dagster daemon executing scheduled jobs and processing sensor ticks</li> <li>Database: PostgreSQL instance hosted on AWS RDS with automated backups and read replicas for frontend queries</li> <li>Networking: Internal services communicate via VPC; frontend application accesses database read replicas</li> </ul> </li> <li>Secrets Management: Sensitive credentials (API keys, database passwords, OAuth tokens) stored in environment variables or AWS Secrets Manager, never committed to version control.</li> <li>Monitoring: Dagster's built-in run logging and Dagit UI provide visibility into job execution. Additional alerting via AWS CloudWatch for infrastructure failures.</li> </ul>"},{"location":"system-overview/system_overview/#external-integrations","title":"External Integrations","text":"Service Purpose Authentication Accern News intelligence and event-based signals API key per channel endpoint Harmonic Company/people search and enrichment API Key Gmail API Newsletter Ingestion Service account with domain-wide delegation Google Custom Search URL discovery for entity enrichment API key + Custom Search Engine ID OpenAI API NER, entity filtering, context extraction, feature rating API key (Organization scoped) <p>Next Section: \u00a72 Data Models &amp; Database Schema (see <code>omvision_doc_structure.txt</code> for full outline)</p>"},{"location":"utility-modules/utility_modules/","title":"7. Utility Modules","text":"<p>OMVision's utility modules provide essential reusable logic that supports the core data pipeline, ML components, and external integrations. These modules encapsulate cross-cutting concerns including rate limiting, entity filtering, prompt engineering, data validation, and operation configuration.</p> <p>This section documents each utility module, explaining its purpose, implementation, and integration points across the system.</p>"},{"location":"utility-modules/utility_modules/#71-rate-limiting","title":"7.1 Rate Limiting","text":""},{"location":"utility-modules/utility_modules/#overview","title":"Overview","text":"<p>The <code>RateLimiter</code> class (<code>app/utils/rate_limiter.py</code>) implements a token bucket algorithm to enforce API rate limits and prevent quota exhaustion when interacting with external services. This utility is critical for maintaining compliance with third-party API rate restrictions, particularly for Google Custom Search, which has strict per-minute request limits.</p>"},{"location":"utility-modules/utility_modules/#implementation","title":"Implementation","text":"<p>Class Definition</p> <pre><code>class RateLimiter:\n    def __init__(self, max_calls, period, threshold=0.90):\n        \"\"\"\n        Initialize rate limiter with configurable parameters.\n\n        Args:\n            max_calls (int): Maximum number of calls allowed within the period.\n            period (int): Time window in seconds for max_calls.\n            threshold (float): Percentage of max_calls to enforce (default 90%).\n        \"\"\"\n        self.max_calls = max_calls\n        self.period = period\n        self.threshold = threshold\n        self.threshold_limit = int(max_calls * threshold)\n        self._lock = Lock()\n        self._request_counter = 0\n        self._first_request_time = None\n</code></pre> <p>Core Algorithm</p> <p>The rate limiter uses a sliding window approach with the following logic:</p> <ol> <li>Initialization: On first request, record timestamp</li> <li>Counter increment: Each request increments internal counter</li> <li>Threshold check: Block if counter reaches threshold limit</li> <li>Window reset: Reset counter after time period expires</li> <li>Safety margin: Default 90% threshold provides buffer against edge cases</li> </ol> <p>Key Method: <code>acquire()</code></p> <pre><code>def acquire(self):\n    \"\"\"\n    Acquire permission to make a request. Blocks if rate limit exceeded.\n    \"\"\"\n    with self._lock:\n        current_time = time.time()\n\n        # Initialize on first request\n        if self._first_request_time is None:\n            self._first_request_time = current_time\n\n        elapsed_time = current_time - self._first_request_time\n\n        # Reset counter if period elapsed\n        if elapsed_time &gt; self.period:\n            self._request_counter = 0\n            self._first_request_time = current_time\n\n        # Block if threshold reached\n        if self._request_counter &gt;= self.threshold_limit:\n            time_to_wait = ceil(self.period - elapsed_time)\n            print(f\"Rate limit hit. Sleeping for {time_to_wait} seconds.\")\n            time.sleep(time_to_wait)\n            self._first_request_time = time.time()\n            self._request_counter = 0\n\n        self._request_counter += 1\n</code></pre>"},{"location":"utility-modules/utility_modules/#usage-patterns","title":"Usage Patterns","text":"<p>Google Custom Search Integration</p> <p>The most common usage is in the <code>WebSearchResource</code> for Google Custom Search API:</p> <pre><code>class WebSearchResource(ConfigurableResource):\n    def setup_for_execution(self, context: InitResourceContext):\n        self._service = build(\"customsearch\", \"v1\", developerKey=self.api_key)\n        self._rate_limiter = RateLimiter(100, 60)  # 100 requests per 60 seconds\n\n    def _google_custom_search(self, query, website=None):\n        self._rate_limiter.acquire()  # Blocks if rate limit exceeded\n\n        res = self._service.cse().list(q=query, cx=self.cse_id).execute()\n        return res.get(\"items\", [])\n</code></pre> <p>Configuration Examples</p> Use Case max_calls period threshold Effective Limit Google Search (free tier) 100 60 0.90 90 requests/min Conservative API 1000 3600 0.80 800 requests/hour High-throughput 5000 60 0.95 4750 requests/min"},{"location":"utility-modules/utility_modules/#behavior-characteristics","title":"Behavior Characteristics","text":"<p>Thread Safety</p> <p>The rate limiter uses a <code>threading.Lock</code> to ensure thread-safe counter updates, making it suitable for multi-threaded Dagster operations:</p> <pre><code>sequenceDiagram\n    participant T1 as Thread 1\n    participant RL as RateLimiter\n    participant T2 as Thread 2\n\n    T1-&gt;&gt;RL: acquire()\n    activate RL\n    RL-&gt;&gt;RL: Lock acquired\n    RL-&gt;&gt;RL: Check counter (89/90)\n    RL-&gt;&gt;RL: Increment counter (90/90)\n    RL--&gt;&gt;T1: Request allowed\n    deactivate RL\n\n    T2-&gt;&gt;RL: acquire()\n    activate RL\n    RL-&gt;&gt;RL: Lock acquired\n    RL-&gt;&gt;RL: Check counter (90/90)\n    RL-&gt;&gt;RL: Sleep for remaining window\n    RL-&gt;&gt;RL: Reset counter\n    RL--&gt;&gt;T2: Request allowed\n    deactivate RL</code></pre> <p>Rate Limit Scenarios</p> Scenario Behavior Under threshold Request proceeds immediately At threshold Thread sleeps until rate window resets Multiple threads Lock ensures sequential counter access Period expired Counter resets automatically"},{"location":"utility-modules/utility_modules/#integration-points","title":"Integration Points","text":"<p>The <code>RateLimiter</code> is used throughout OMVision's external integrations:</p> <ul> <li>\u00a76.4 Google Custom Search: Primary use case for URL discovery</li> <li>Future API integrations: Template for additional rate-limited resources</li> </ul>"},{"location":"utility-modules/utility_modules/#design-rationale","title":"Design Rationale","text":"<p>Why 90% Threshold?</p> <p>The default 90% threshold provides a safety buffer to account for:</p> <ul> <li>Clock drift between client and server</li> <li>Network latency causing request bunching</li> <li>Concurrent requests in multi-threaded environments</li> <li>API provider's internal rate calculation variations</li> </ul>"},{"location":"utility-modules/utility_modules/#72-company-filters","title":"7.2 Company Filters","text":""},{"location":"utility-modules/utility_modules/#overview_1","title":"Overview","text":"<p>Company filtering enforces OMVC's investment thesis by excluding entities that fall outside target parameters. OMVision implements two complementary filtering mechanisms:</p> <ol> <li>Programmatic filters: Hard-coded criteria based on company attributes (location, funding stage, headcount)</li> <li>Manual filter list: User-maintained exclusion list for domain-specific noise</li> </ol> <p>Both filtering approaches work together to ensure only relevant companies progress through the pipeline.</p>"},{"location":"utility-modules/utility_modules/#programmatic-filter-criteria","title":"Programmatic Filter Criteria","text":"<p>Filter Constants (<code>app/constants/company_filters.py</code>)</p> <pre><code># Geographic scope\nLOCATION_FILTER_LIST = [\n    \"United States\", \"Singapore\", \"Thailand\", \"Australia\", \"Canada\",\n    \"United Arab Emirates\", \"Egypt\", \"Saudi Arabia\", \"New Zealand\",\n    \"Philippines\", \"Indonesia\", \"Malaysia\", \"Hong Kong\", \"Vietnam\",\n    \"Japan\", \"South Korea\"\n]\n\n# Target funding stages\nFUNDING_ROUND_FILTER_LIST = [\n    \"PRE_SEED\", \"SEED\", \"SERIES_A\", \"SERIES_B\", \n    \"VENTURE_UNKNOWN\", \"STEALTH\"\n]\n\n# Financial and size constraints\nFUNDING_AMOUNT_LIMIT = 15_000_000  # $15M\nCOMPANY_HEADCOUNT_LIMIT = 50       # employees\n</code></pre>"},{"location":"utility-modules/utility_modules/#filter-implementation","title":"Filter Implementation","text":"<p>Location in Pipeline</p> <p>The <code>filter_companies</code> op (<code>app/jobs/ingest_companies_from_signals.py</code>) applies filters after Harmonic enrichment:</p> <pre><code>@op\ndef filter_companies(\n    context,\n    searched_companies: list[SignalWithCompanies],\n    enriched_companies: list[SignalWithCompanies]\n) -&gt; tuple[list[CompanyWithSignalId], list[SignalWithCompanyIds]]:\n    \"\"\"\n    Apply investment thesis filters to enriched companies.\n\n    Filters:\n        1. Investor profiles (exclude companies that ARE investors)\n        2. Geographic location\n        3. Funding stage\n        4. Total funding amount\n        5. Company headcount\n\n    Returns:\n        Filtered companies and updated signal associations.\n    \"\"\"\n    filtered_companies = []\n    updated_signals = []\n\n    for signal in searched_companies + enriched_companies:\n        signal_company_ids = []\n\n        for company in signal.companies:\n            # Filter 1: Exclude investor entities\n            if company.investor_urn:\n                continue\n\n            # Filter 2: Location restriction\n            if company.location:\n                country = company.location.get(\"country\")\n                if country and country not in LOCATION_FILTER_LIST:\n                    continue\n\n            # Filter 3: Funding stage restriction\n            if company.stage and company.stage not in FUNDING_ROUND_FILTER_LIST:\n                continue\n\n            # Filter 4: Total funding limit\n            if company.funding:\n                funding_total = company.funding.get(\"funding_total\")\n                if funding_total and funding_total &gt;= FUNDING_AMOUNT_LIMIT:\n                    continue\n\n            # Filter 5: Headcount limit\n            if company.headcount and company.headcount &gt; COMPANY_HEADCOUNT_LIMIT:\n                continue\n\n            # Company passed all filters\n            filtered_companies.append(\n                CompanyWithSignalId(signal_id=signal.id, **company.model_dump())\n            )\n            signal_company_ids.append(company.id)\n\n        updated_signals.append(\n            SignalWithCompanyIds(id=signal.id, source_company_ids=signal_company_ids)\n        )\n\n    return filtered_companies, updated_signals\n</code></pre>"},{"location":"utility-modules/utility_modules/#filter-rationale","title":"Filter Rationale","text":"<p>Investment Thesis Alignment</p> Filter Rationale Example Exclusions Investor URN OMVision targets portfolio companies, not investors Venture capital firms, accelerators Location Geographic focus on key markets European startups, African companies Funding Stage Early-stage focus (Pre-Seed through Series B) Series C+, growth equity, public companies Funding Amount Companies below $15M remain in growth stage Over-capitalized late-stage companies Headcount Small teams indicate early stage Mature companies with 100+ employees <p>Filter Interaction</p> <p>Filters are applied sequentially using short-circuit logic. If a company fails any filter, remaining filters are skipped for efficiency.</p> <pre><code>graph TD\n    A[Company] --&gt; B{Has investor_urn?}\n    B --&gt;|Yes| Z[Exclude]\n    B --&gt;|No| C{Location allowed?}\n    C --&gt;|No| Z\n    C --&gt;|Yes| D{Stage in target list?}\n    D --&gt;|No| Z\n    D --&gt;|Yes| E{Funding &lt; $15M?}\n    E --&gt;|No| Z\n    E --&gt;|Yes| F{Headcount \u2264 50?}\n    F --&gt;|No| Z\n    F --&gt;|Yes| G[Include]\n\n    style G fill:#90EE90\n    style Z fill:#FFB6C1</code></pre>"},{"location":"utility-modules/utility_modules/#manual-filter-list","title":"Manual Filter List","text":"<p>Purpose</p> <p>The manual filter list (<code>company_filter_list</code> asset in <code>app/assets/company_filters.py</code>) captures domain-specific noise that programmatic filters cannot anticipate:</p> <ul> <li>Repeatedly misidentified entities (e.g., \"Ventures\" as standalone company)</li> <li>Media outlets frequently mentioned in signals (e.g., \"TechCrunch\", \"Bloomberg\")</li> <li>Government agencies and academic institutions</li> <li>Large consulting firms</li> </ul> <p>Implementation</p> <pre><code>@asset\ndef company_filter_list(harmonic: HarmonicResource) -&gt; list[str]:\n    \"\"\"\n    Fetch manual exclusion list from Harmonic saved search.\n\n    Returns:\n        List of company names to exclude from pipeline.\n    \"\"\"\n    filter_search = harmonic.get_filter_search()  # \"DealFlow - Filter list\"\n    company_ids = harmonic.get_companies_by_search(filter_search.entity_urn)\n    return [company.name for company in company_ids]\n</code></pre> <p>Harmonic Configuration</p> <p>The filter list is maintained as a Harmonic saved search named \"DealFlow - Filter list\". Investment team members add companies to this search through Harmonic's UI, and the asset automatically syncs the list during pipeline execution.</p> <p>Usage in Pipeline</p> <p>The <code>filter_entities</code> op (<code>app/ops/__init__.py</code>) applies the manual filter to NER-extracted entities before URL enrichment:</p> <pre><code>@op\ndef filter_entities(\n    context,\n    company_names: list[str],\n    entities: list[NerTags]\n) -&gt; list[NerTags]:\n    \"\"\"\n    Remove entities matching names in the manual filter list.\n\n    Args:\n        company_names: Manual exclusion list from company_filter_list asset.\n        entities: Extracted entities with org/person/gpe tags.\n\n    Returns:\n        Entities with filtered organizations removed.\n    \"\"\"\n    filter_count = 0\n\n    for entity_tags in entities:\n        keys_to_remove = [\n            entity_name\n            for entity_name in entity_tags.org.keys()\n            if entity_name in company_names\n        ]\n\n        for entity_name in keys_to_remove:\n            entity_tags.org.pop(entity_name)\n            filter_count += 1\n\n    context.log.info(f\"Total entities removed: {filter_count}\")\n    return entities\n</code></pre>"},{"location":"utility-modules/utility_modules/#filter-pipeline-position","title":"Filter Pipeline Position","text":"<pre><code>graph LR\n    A[NER Extraction] --&gt; B[LLM Entity Filter]\n    B --&gt; C[Manual Filter List]\n    C --&gt; D[URL Enrichment]\n    D --&gt; E[Harmonic Enrichment]\n    E --&gt; F[Programmatic Filters]\n    F --&gt; G[Database Storage]\n\n    style C fill:#FFE4B5\n    style F fill:#FFE4B5</code></pre> <p>Why Two Filter Stages?</p> <ul> <li>Early filtering (manual list): Prevents wasted URL discovery and enrichment API calls</li> <li>Late filtering (programmatic): Requires structured data only available after Harmonic enrichment</li> </ul>"},{"location":"utility-modules/utility_modules/#maintenance-workflow","title":"Maintenance Workflow","text":"<p>Adding to Filter List</p> <ol> <li>Investment team identifies irrelevant entity in Harmonic UI</li> <li>Add entity to \"DealFlow - Filter list\" saved search</li> <li>Next pipeline run automatically excludes entity</li> </ol>"},{"location":"utility-modules/utility_modules/#73-prompt-definitions","title":"7.3 Prompt Definitions","text":""},{"location":"utility-modules/utility_modules/#overview_2","title":"Overview","text":"<p>OMVision uses structured OpenAI prompts for four critical operations: text preprocessing, entity extraction (NER), entity filtering, and feature rating extraction. Prompts are centralized in <code>app/constants/prompt_definitions.py</code> and consumed by the <code>OpenAIResource</code> (<code>app/resources/open_ai.py</code>).</p> <p>This centralization ensures prompt consistency, facilitates A/B testing, and enables version control of prompt engineering decisions.</p>"},{"location":"utility-modules/utility_modules/#prompt-architecture","title":"Prompt Architecture","text":"<pre><code>graph TB\n    subgraph \"Prompt Definitions (Constants)\"\n        A[INPUT_FEATURE_DEFINITIONS]\n        B[OUTPUT_RATING_DEFINITIONS]\n        C[NER_SYSTEM_PROMPT]\n        D[FILTER_SYSTEM_PROMPT]\n        E[CONTEXT_EXTRACTION_PROMPT]\n        F[PREPROCESS_SYSTEM_PROMPT]\n    end\n\n    subgraph \"OpenAI Resource\"\n        G[preprocess_text]\n        H[extract_ner_tags]\n        I[filter_ner_tags]\n        J[extract_context_from_signal]\n        K[transform_to_numerical_features]\n    end\n\n    F --&gt; G\n    C --&gt; H\n    D --&gt; I\n    E --&gt; J\n    A --&gt; K\n    B --&gt; K\n\n    style A fill:#E6F3FF\n    style B fill:#E6F3FF</code></pre>"},{"location":"utility-modules/utility_modules/#preprocessing-prompts","title":"Preprocessing Prompts","text":"<p>Purpose: Remove noise from raw signal text before NER extraction.</p> <p>System Prompt (in <code>OpenAIResource._preprocess_text_system_prompt()</code>)</p> <pre><code>def _preprocess_text_system_prompt(self) -&gt; str:\n    return f\"\"\"\n    You are an advanced text preprocessing AI. Your task is to filter and retain \n    only relevant content from unstructured text signals.\n\n    Keep ONLY text that mentions or describes:\n    - {\", \".join(self.labels)}  # person, org, gpe\n\n    Remove:\n    - Greetings, signatures, boilerplate\n    - Advertisements and promotional content\n    - Navigation elements and metadata\n    - Irrelevant conversational text\n\n    Return cleaned text preserving entity context and relationships.\n    \"\"\"\n</code></pre> <p>Usage Example</p> <pre><code># Input (from Accern signal)\nraw_text = \"\"\"\nHi team, hope you're well!\n\nTechCorp, a Series A fintech startup, raised $5M from Sequoia Capital. \nThe company was founded by Jane Smith, former VP at Google.\n\nClick here to unsubscribe | Privacy Policy\n\"\"\"\n\n# Output (after preprocessing)\npreprocessed = \"\"\"\nTechCorp, a Series A fintech startup, raised $5M from Sequoia Capital. \nThe company was founded by Jane Smith, former VP at Google.\n\"\"\"\n</code></pre>"},{"location":"utility-modules/utility_modules/#ner-extraction-prompts","title":"NER Extraction Prompts","text":"<p>Purpose: Extract person, organization, and geopolitical entity mentions from preprocessed text.</p> <p>System Prompt (in <code>OpenAIResource._system_message()</code>)</p> <pre><code>def _system_message(self, labels: list[str]) -&gt; str:\n    return f\"\"\"\n    You are an expert in Natural Language Processing. Your task is to identify \n    common Named Entities (NER) in a given natural language signal text.\n\n    The possible common Named Entities (NER) types are exclusively: \n    ({\", \".join(labels)}).\n    \"\"\"\n</code></pre> <p>User Prompt with Metadata (for Accern signals)</p> <pre><code>def _user_message(self, text: str, signal: dict, vanilla_prompt: bool = False) -&gt; str:\n    if vanilla_prompt:\n        return f\"Extract named entities from: {text}\"\n\n    # Accern signals include additional context\n    return f\"\"\"\n    Extract named entities from the following text.\n\n    Context:\n    - Primary Entity: {signal.get('entity_name')}\n    - Entity Type: {signal.get('entity_type')}\n    - Document Title: {signal.get('doc_title')}\n    - Document URL: {signal.get('doc_url')}\n\n    Text:\n    {text}\n    \"\"\"\n</code></pre> <p>Structured Output Schema</p> <pre><code>class OpenAiNerTags(BaseModel):\n    person: list[str]  # [\"Jane Smith\", \"John Doe\"]\n    org: list[str]     # [\"TechCorp\", \"Sequoia Capital\"]\n    gpe: list[str]     # [\"San Francisco\", \"United States\"]\n</code></pre>"},{"location":"utility-modules/utility_modules/#entity-filtering-prompts","title":"Entity Filtering Prompts","text":"<p>Purpose: Remove large corporations, government institutions, and celebrities from extracted entities.</p> <p>System Prompt (in <code>OpenAIResource._filter_text_system_prompt()</code>)</p> <pre><code>def _filter_text_system_prompt(self) -&gt; str:\n    example_1_input = {\n        \"person\": [],\n        \"org\": [\"European Investment Bank\", \"European Investment Bank Group\", \n                \"European Investment Fund\"],\n        \"gpe\": [\"Europe\"]\n    }\n    example_1_output = {\"person\": [], \"org\": [], \"gpe\": []}\n\n    example_2_input = {\n        \"person\": [],\n        \"org\": [\"Deepnote\", \"Index Ventures\", \"Accel\", \"Y Combinator\", \n                \"Hyperquery\", \"Credo Ventures\", \"Ramp\", \"Motive\", \n                \"SoundCloud\", \"Gusto\", \"Webflow\"],\n        \"gpe\": []\n    }\n    example_2_output = {\n        \"person\": [],\n        \"org\": [\"Deepnote\", \"Hyperquery\", \"Ramp\", \"Motive\", \"Gusto\"],\n        \"gpe\": []\n    }\n\n    return f\"\"\"\n    You are an entity filtering AI assistant. There is a source text from which \n    entities have been extracted; your task is to use the filtering criteria given \n    below to remove entities from the original list of entities using the source \n    text as context.\n\n    If you are unsure about the entity, retain it. Return ONLY the filtered entities \n    that PASS the given criteria.\n\n    Each entity can be one of many different types. The description for the different \n    entity types is mentioned below:\n    {\", \".join(self.labels)}\n\n    Follow these filtering criteria to eliminate entities from the original list:\n    1) Remove entities that may refer to big companies or major-tech firms like \n       Meta, Google, OpenAI, Disney, JP Morgan etc.\n    2) Remove entities that refer to public or government-owned institutions \n       (e.g., European Investment Bank)\n    3) Remove entities that refer to celebrities or public figures\n\n    Example 1:\n    Input: {json.dumps(example_1_input)}\n    Output: {json.dumps(example_1_output)}\n\n    Example 2:\n    Input: {json.dumps(example_2_input)}\n    Output: {json.dumps(example_2_output)}\n    \"\"\"\n</code></pre> <p>Filter Logic</p> <ul> <li>Retain startups: Deepnote, Hyperquery, Ramp (early-stage companies)</li> <li>Remove VC firms: Index Ventures, Accel (investors, not portfolio companies)</li> <li>Remove large tech: SoundCloud, Webflow (mature companies)</li> <li>Remove government: European Investment Bank</li> </ul>"},{"location":"utility-modules/utility_modules/#context-extraction-prompts","title":"Context Extraction Prompts","text":"<p>Purpose: Extract entity descriptors and URLs for subsequent enrichment.</p> <p>System Prompt (in <code>OpenAIResource._context_extraction_prompt()</code>)</p> <pre><code>def _context_extraction_prompt(self) -&gt; str:\n    return \"\"\"\n    You are an information extraction AI. Given source text and a list of extracted \n    entities, identify additional context for each entity.\n\n    For each entity, extract:\n    1. Descriptors: Short phrases describing the entity's role, title, or function\n       (e.g., \"CEO\", \"Series A startup\", \"former Google executive\")\n    2. Link: Any URL associated with the entity (website, LinkedIn profile)\n\n    Return structured data matching the OpenAiSignalContext schema.\n    \"\"\"\n</code></pre> <p>Output Schema</p> <pre><code>class OpenAiEntityContext(BaseModel):\n    name: str                # \"Jane Smith\"\n    descriptors: list[str]   # [\"CEO\", \"former VP at Google\"]\n    link: str                # \"https://linkedin.com/in/janesmith\"\n\nclass OpenAiSignalContext(BaseModel):\n    people: list[OpenAiEntityContext]\n    companies: list[OpenAiEntityContext]\n</code></pre> <p>Usage Example</p> <pre><code># Input\ntext = \"TechCorp, a fintech startup, raised $5M. CEO Jane Smith, former Google VP.\"\nentities = {\"org\": [\"TechCorp\"], \"person\": [\"Jane Smith\"]}\n\n# Output\ncontext = OpenAiSignalContext(\n    companies=[\n        OpenAiEntityContext(\n            name=\"TechCorp\",\n            descriptors=[\"fintech startup\", \"raised $5M\"],\n            link=\"\"\n        )\n    ],\n    people=[\n        OpenAiEntityContext(\n            name=\"Jane Smith\",\n            descriptors=[\"CEO\", \"former Google VP\"],\n            link=\"\"\n        )\n    ]\n)\n</code></pre>"},{"location":"utility-modules/utility_modules/#feature-rating-prompts","title":"Feature Rating Prompts","text":"<p>Purpose: Transform natural language company features into numerical ratings for ML classification.</p> <p>Input Feature Definitions (<code>app/constants/prompt_definitions.py</code>)</p> <pre><code>INPUT_FEATURE_DEFINTIIONS = {\n    \"Description\": \"A concise overview of the company that outlines its core business, \"\n                  \"products or services, unique value propositions, and any proprietary \"\n                  \"technologies or methodologies.\",\n\n    \"CompanyHighlights\": \"Notable aspects of the company itself, including significant \"\n                        \"achievements, venture backing, partnerships, awards, and other \"\n                        \"distinguishing factors related to the company as an entity.\",\n\n    \"EmployeeHighlights\": \"Notable aspects related to the company's employees, such as \"\n                         \"experienced leadership, notable backgrounds, prior accomplishments, \"\n                         \"and other distinguishing factors related to team members.\",\n\n    \"Tags\": \"Unique keywords or phrases that categorize the company across various \"\n           \"dimensions such as industry, technology, product type, customer type, \"\n           \"market vertical, and technology type.\",\n}\n</code></pre> <p>Output Rating Definitions (<code>app/constants/prompt_definitions.py</code>)</p> <pre><code>OUTPUT_RATING_DEFINITIONS = {\n    \"Company Relevance\": \"This variable will measure how well a company fits into our \"\n                        \"investment thesis based on the information provided. We invest in \"\n                        \"Pre-Seed, Seed, and Series A B2B and B2B2C fintech opportunities \"\n                        \"that fall into three main buckets: Innovations in capital markets, \"\n                        \"innovations in infrastructure, and deep-tech (AI, ML, Quantum, \"\n                        \"Blockchain, etc). Also included in our fintech definition are \"\n                        \"industries like Property Tech (PropTech), Insurance Tech (InsurTech), \"\n                        \"ClimateTech (Software only).\",\n\n    \"Founder Strength\": \"This variable will measure the overall quality of the founder. \"\n                       \"There are multiple things that can determine the quality of a founder, \"\n                       \"some of the things are: Founder-Market Fit (does the founder have \"\n                       \"previous work experience in the market/industry their startup is in?), \"\n                       \"Multi-time founder (Have they founded a company in the past?), relevant \"\n                       \"educational experience (Did they go to a top university? Do they have \"\n                       \"an advanced degree that is relevant for the product they are selling/\"\n                       \"company they are running?), ability to hire high quality talent (what \"\n                       \"is the overall strength of their team? Have they attracted top talent?).\",\n\n    \"Investor Relevance\": \"This variable will measure the quality and relevance of investors \"\n                         \"that have invested into the company so far. We want to understand \"\n                         \"the reputation of the investor on their cap table and thesis alignment \"\n                         \"for these investors. For example, we would rank a16z seed fund / \"\n                         \"experimental check higher than AVG Partners in HK.\",\n\n    \"Team Strength\": \"This variable is experimental. It would measure the overall strength \"\n                    \"of the management team as a whole (rather than just the founder) and see \"\n                    \"if the skillsets of the people on the management team compliment each other.\",\n}\n</code></pre> <p>System Prompt Construction (in <code>OpenAIResource._system_message_for_feature_extraction()</code>)</p> <pre><code>def _system_message_for_feature_extraction(\n    self,\n    input_features_definitions: dict,\n    output_ratings_definitions: dict,\n    examples: Optional[list] = []\n) -&gt; str:\n    prompt = \"\"\"You are an AI assistant to our investment firm that extracts numerical \n    ratings (granular values between 0.00 and 1.00) from a set of natural language \n    features for companies.\n\n    Input Features:\n    \"\"\"\n\n    for feature, description in input_features_definitions.items():\n        prompt += f\"- {feature}: {description}\\n\"\n\n    prompt += \"\\nOutput Ratings:\\n\"\n    for rating, description in output_ratings_definitions.items():\n        prompt += f\"- {rating}: {description}\\n\"\n\n    if examples:\n        prompt += \"\\nExamples:\\n\"\n        for i, example in enumerate(examples):\n            prompt += f\"Example {i+1}:\\n\"\n            prompt += \"Input Features:\\n\"\n            for feature in input_features_definitions.keys():\n                prompt += f\"{feature}: {example['input'][feature]}\\n\"\n            prompt += \"Output Ratings:\\n\"\n            for rating in output_ratings_definitions.keys():\n                prompt += f\"{rating}: {example['output'][rating]}\\n\"\n            prompt += \"\\n\"\n\n    return prompt\n</code></pre> <p>Output Schema</p> <pre><code>class OpenAiCompanyExtractedRatings(BaseModel):\n    company_relevance: Optional[float]   # 0.0 - 1.0\n    founder_strength: Optional[float]    # 0.0 - 1.0\n    investor_relevance: Optional[float]  # 0.0 - 1.0\n    team_strength: Optional[float]       # 0.0 - 1.0\n</code></pre>"},{"location":"utility-modules/utility_modules/#prompt-usage-flow","title":"Prompt Usage Flow","text":"<pre><code>sequenceDiagram\n    participant Signal as Raw Signal\n    participant OpenAI as OpenAI API\n    participant Pipeline as Data Pipeline\n\n    Note over Signal,Pipeline: Stage 1: Preprocessing\n    Signal-&gt;&gt;OpenAI: preprocess_text(raw_text)\n    OpenAI--&gt;&gt;Pipeline: cleaned_text\n\n    Note over Signal,Pipeline: Stage 2: NER Extraction\n    Pipeline-&gt;&gt;OpenAI: extract_ner_tags(cleaned_text, metadata)\n    OpenAI--&gt;&gt;Pipeline: OpenAiNerTags\n\n    Note over Signal,Pipeline: Stage 3: Entity Filtering\n    Pipeline-&gt;&gt;OpenAI: filter_ner_tags(cleaned_text, entities)\n    OpenAI--&gt;&gt;Pipeline: Filtered OpenAiNerTags\n\n    Note over Signal,Pipeline: Stage 4: Context Extraction\n    Pipeline-&gt;&gt;OpenAI: extract_context_from_signal(original_text, entities)\n    OpenAI--&gt;&gt;Pipeline: OpenAiSignalContext\n\n    Note over Signal,Pipeline: Stage 5: Feature Rating (during classification)\n    Pipeline-&gt;&gt;OpenAI: transform_to_numerical_features(nl_features)\n    OpenAI--&gt;&gt;Pipeline: OpenAiCompanyExtractedRatings</code></pre>"},{"location":"utility-modules/utility_modules/#temperature-settings","title":"Temperature Settings","text":"<p>All prompts use <code>temperature=0</code> to ensure deterministic, reproducible outputs:</p> <pre><code>response = self._client.beta.chat.completions.parse(\n    model=self.extraction_model,  # \"gpt-4o-2024-08-06\"\n    messages=messages,\n    temperature=0,  # Deterministic output\n    response_format=OutputSchema,\n)\n</code></pre>"},{"location":"utility-modules/utility_modules/#74-data-schemas","title":"7.4 Data Schemas","text":""},{"location":"utility-modules/utility_modules/#overview_3","title":"Overview","text":"<p>OMVision uses Pydantic models extensively for data validation, serialization, and API contract enforcement. All schemas are defined in the <code>app/schemas/</code> module and provide type-safe interfaces between pipeline components.</p> <p>Pydantic's runtime validation catches data quality issues early, preventing corrupt data from propagating through the system.</p>"},{"location":"utility-modules/utility_modules/#schema-architecture","title":"Schema Architecture","text":"<pre><code>app/schemas/\n\u251c\u2500\u2500 __init__.py                 # Public exports\n\u251c\u2500\u2500 accern.py                   # Accern API response schemas\n\u251c\u2500\u2500 companies.py                # Company data schemas\n\u251c\u2500\u2500 data_source.py              # Data source configuration schemas\n\u251c\u2500\u2500 harmonic.py                 # Harmonic API response schemas\n\u251c\u2500\u2500 mail.py                     # Gmail message schemas\n\u251c\u2500\u2500 open_ai.py                  # OpenAI request/response schemas\n\u2514\u2500\u2500 signal.py                   # Signal processing schemas\n</code></pre>"},{"location":"utility-modules/utility_modules/#core-schema-categories","title":"Core Schema Categories","text":""},{"location":"utility-modules/utility_modules/#entity-extraction-schemas-open_aipy","title":"Entity Extraction Schemas (<code>open_ai.py</code>)","text":"<p>OpenAI NER Output</p> <pre><code>class OpenAiNerTags(BaseModel):\n    \"\"\"Raw NER extraction output from OpenAI.\"\"\"\n    person: list[str]  # Person names\n    org: list[str]     # Organization names\n    gpe: list[str]     # Geopolitical entities\n\nclass NerTags(BaseModel):\n    \"\"\"NER tags with associated URLs after enrichment.\"\"\"\n    person: Optional[dict[str, str]] = {}  # {\"Jane Smith\": \"linkedin.com/in/...\"}\n    org: Optional[dict[str, str]] = {}     # {\"TechCorp\": \"techcorp.com\"}\n    gpe: Optional[dict[str, str]] = {}     # {\"San Francisco\": \"\"}\n</code></pre> <p>Entity Context</p> <pre><code>class OpenAiEntityContext(BaseModel):\n    \"\"\"Additional context for a single entity.\"\"\"\n    name: str                # Entity name\n    descriptors: list[str]   # Descriptive phrases\n    link: str                # Associated URL\n\nclass OpenAiSignalContext(BaseModel):\n    \"\"\"Full context for all entities in a signal.\"\"\"\n    people: list[OpenAiEntityContext]\n    companies: list[OpenAiEntityContext]\n</code></pre>"},{"location":"utility-modules/utility_modules/#signal-schemas-signalpy","title":"Signal Schemas (<code>signal.py</code>)","text":"<p>Signal Creation</p> <pre><code>class SignalCreate(BaseModel):\n    \"\"\"Schema for creating new signals in database.\"\"\"\n    raw_entity_tags: OpenAiNerTags      # Unfiltered NER output\n    entity_tags: NerTags                 # Filtered tags with URLs\n    source_id: int                       # Foreign key to Source table\n    source_data: dict                    # Original signal payload\n\n    class Config:\n        from_attributes = True  # Enable ORM compatibility\n</code></pre> <p>Signal Processing Schemas</p> <pre><code>class SignalBase(BaseModel):\n    \"\"\"Minimal signal representation.\"\"\"\n    id: int\n\n    class Config:\n        from_attributes = True\n\nclass SignalWithTags(SignalBase):\n    \"\"\"Signal with extracted entity tags.\"\"\"\n    ner_tags: Optional[NerTags]\n\nclass SignalWithCompanies(SignalBase):\n    \"\"\"Signal with enriched company data.\"\"\"\n    companies: list[CompanyBase]\n\nclass SignalWithCompanyIds(SignalBase):\n    \"\"\"Signal with company ID references.\"\"\"\n    source_company_ids: list[int]\n</code></pre> <p>Pattern: Schemas follow composition pattern where specialized schemas extend <code>SignalBase</code> with additional fields relevant to specific pipeline stages.</p>"},{"location":"utility-modules/utility_modules/#company-schemas-companiespy","title":"Company Schemas (<code>companies.py</code>)","text":"<p>Natural Language Features</p> <pre><code>class CompanyNLFeatures(BaseModel):\n    \"\"\"Raw NL features from Harmonic enrichment.\"\"\"\n    id: int\n    tags: Optional[list]                    # Industry/tech tags\n    employee_highlights: Optional[list]     # Team backgrounds\n    highlights: Optional[list]              # Company achievements\n    description: Optional[str]              # Business description\n\nclass CompanyNLFeaturesFormatted(BaseModel):\n    \"\"\"Formatted NL features for LLM consumption.\"\"\"\n    id: int\n    tags: str                    # Comma-separated\n    employee_highlights: str     # Newline-separated\n    highlights: str              # Newline-separated\n    description: str             # Plain text\n</code></pre> <p>Structured Features</p> <pre><code>class CompanyOtherFeatures(BaseModel):\n    \"\"\"Structured company attributes for ML models.\"\"\"\n    id: int\n    last_funding_type: Optional[str] = \"UNKNOWN\"\n    country: Optional[str] = \"UNKNOWN\"\n    stage: Optional[str] = \"UNKNOWN\"\n    headcount: Optional[int] = 0\n    last_funding_date: Optional[str] = None\n    funding_total: Optional[float] = 0\n    founding_date: Optional[str] = None\n    number_of_funding_rounds: Optional[int] = 0\n    web_traffic_change: Optional[float] = 0.0\n</code></pre> <p>Extracted Ratings</p> <pre><code>class CompanyExtractedRatingFeatures(BaseModel):\n    \"\"\"LLM-derived numerical ratings.\"\"\"\n    id: int\n    features: OpenAiCompanyExtractedRatings\n\nclass OpenAiCompanyExtractedRatings(BaseModel):\n    \"\"\"Individual rating dimensions.\"\"\"\n    company_relevance: Optional[float]   # Investment thesis fit\n    founder_strength: Optional[float]    # Founder quality\n    investor_relevance: Optional[float]  # Investor quality\n    team_strength: Optional[float]       # Team composition\n</code></pre> <p>Custom Columns</p> <pre><code>class CompanyCustomColumns(BaseModel):\n    \"\"\"User-generated metadata from frontend.\"\"\"\n    name: Optional[str]\n    source_company_id: int\n    list_ids: Optional[list[int]]       # List associations\n    id: Optional[int]\n    rank: Optional[float]               # ML prediction\n    comments: Optional[str]             # User notes\n    relevence_stage: Optional[str]      # Deal flow stage\n    is_hidden: Optional[bool]           # Visibility flag\n</code></pre>"},{"location":"utility-modules/utility_modules/#harmonic-schemas-harmonicpy","title":"Harmonic Schemas (<code>harmonic.py</code>)","text":"<p>Company Response</p> <pre><code>class CompanyBase(BaseModel):\n    \"\"\"Harmonic company enrichment response.\"\"\"\n    entity_urn: str = Field(default=\"\")\n    id: int = Field(default=0)\n    initialized_date: Optional[str] = None\n    website: Dict[str, Any] = Field(default_factory=dict)\n    customer_type: Optional[str] = None\n    logo_url: Optional[str] = None\n    name: Optional[str] = None\n    legal_name: Optional[str] = None\n    description: Optional[str] = None\n    external_description: Optional[str] = None\n    founding_date: Optional[Dict[str, Any]] = None\n    headcount: Optional[int] = None\n    ownership_status: Optional[str] = None\n    company_type: str = Field(default=\"\")\n    stage: Optional[str] = None\n    location: Optional[Dict[str, Any]] = None\n    contact: Optional[Dict[str, Any]] = None\n    socials: Optional[Dict[str, Any]] = None\n    funding: Optional[Dict[str, Any]] = None\n    people: List[Dict[str, Any]] = Field(default_factory=list)\n    tags: List = Field(default_factory=list)\n    tags_v2: List = Field(default_factory=list)\n    funding_attribute_null_status: Optional[str] = None\n    highlights: Optional[List[Dict[str, Any]]] = Field(default_factory=list)\n    snapshots: List[Dict[str, Any]] = Field(default_factory=list)\n    traction_metrics: Optional[Dict[str, Any]] = None\n    website_domain_aliases: List[str] = Field(default_factory=list)\n    name_aliases: List[str] = Field(default_factory=list)\n    employee_highlights: List[Dict[str, Any]] = Field(default_factory=list)\n    funding_rounds: List[Dict[str, Any]] = Field(default_factory=list)\n    investor_urn: Optional[str] = None\n    related_companies: Optional[Dict[str, Any]] = None\n</code></pre> <p>Watchlist Management</p> <pre><code>class WatchlistBase(BaseModel):\n    \"\"\"Base watchlist attributes.\"\"\"\n    id: str\n    name: str\n    description: Optional[str] = None\n    entity_urn: str\n    shared_with_team: bool\n    creator: Optional[str] = None\n\nclass Watchlist(WatchlistBase):\n    \"\"\"Company watchlist.\"\"\"\n    companies: Optional[List[str]] = []\n\nclass PeopleWatchlist(WatchlistBase):\n    \"\"\"People watchlist.\"\"\"\n    people: Optional[List[str]] = []\n</code></pre> <p>Saved Searches</p> <pre><code>class SearchList(BaseModel):\n    \"\"\"Harmonic saved search configuration.\"\"\"\n    query: Dict[str, Any]\n    type: str              # \"companies\" | \"people\"\n    name: str\n    creator: str\n    is_private: bool\n    entity_urn: str\n</code></pre>"},{"location":"utility-modules/utility_modules/#data-source-schemas-data_sourcepy","title":"Data Source Schemas (<code>data_source.py</code>)","text":"<pre><code>class DataSourceBase(BaseModel):\n    \"\"\"Data source configuration.\"\"\"\n    name: str\n    description: Optional[str] = None\n    base_url: Optional[str] = None\n    channels: Optional[list[str]] = None\n\nclass DataSourceReturn(DataSourceBase):\n    \"\"\"Data source with database ID.\"\"\"\n    id: int\n\n    class Config:\n        from_attributes = True\n\nclass DataSourceFetch(BaseModel):\n    \"\"\"Configuration for fetching from a specific source.\"\"\"\n    source_name: str\n</code></pre>"},{"location":"utility-modules/utility_modules/#schema-validation-features","title":"Schema Validation Features","text":"<p>Field Validation</p> <p>Pydantic validates field types and constraints at runtime:</p> <pre><code># Type checking\ncompany = CompanyBase(\n    entity_urn=\"urn:harmonic:123\",\n    id=456,\n    headcount=\"invalid\"  # \u274c ValidationError: Input should be a valid integer\n)\n\n# Optional fields with defaults\nfeatures = CompanyOtherFeatures(\n    id=789,\n    # All other fields default to UNKNOWN/0/None\n)\n</code></pre> <p>Nested Model Validation</p> <pre><code>context = OpenAiSignalContext(\n    people=[\n        OpenAiEntityContext(\n            name=\"Jane Smith\",\n            descriptors=[\"CEO\", \"Founder\"],\n            link=\"https://linkedin.com/in/janesmith\"\n        )\n    ],\n    companies=[]  # Valid - empty list\n)\n</code></pre> <p>ORM Integration</p> <p>Models with <code>Config.from_attributes = True</code> can be instantiated from SQLAlchemy ORM objects:</p> <pre><code># ORM query\ndb_signal = session.query(Signal).first()\n\n# Pydantic conversion\nsignal_schema = SignalBase.from_orm(db_signal)\n</code></pre>"},{"location":"utility-modules/utility_modules/#schema-usage-patterns","title":"Schema Usage Patterns","text":"<p>Pipeline Data Flow</p> <pre><code>graph LR\n    A[AccernSignal] --&gt; B[OpenAiNerTags]\n    B --&gt; C[NerTags]\n    C --&gt; D[SignalCreate]\n    D --&gt; E[Database]\n    E --&gt; F[SignalWithCompanies]\n    F --&gt; G[CompanyBase]\n    G --&gt; H[CompanyNLFeatures]\n    H --&gt; I[CompanyExtractedRatingFeatures]\n\n    style B fill:#FFE4B5\n    style C fill:#FFE4B5\n    style D fill:#90EE90\n    style G fill:#E6F3FF\n    style H fill:#FFE4B5\n    style I fill:#FFE4B5</code></pre> <p>Type-Safe Op Signatures</p> <pre><code>@op\ndef filter_entities(\n    context,\n    company_names: list[str],\n    entities: list[NerTags]  # Type-checked input\n) -&gt; list[NerTags]:            # Type-checked output\n    # Implementation\n    return filtered_entities\n</code></pre>"},{"location":"utility-modules/utility_modules/#75-operation-configurations","title":"7.5 Operation Configurations","text":""},{"location":"utility-modules/utility_modules/#overview_4","title":"Overview","text":"<p>The <code>op_config.py</code> module (<code>app/sensors/op_config.py</code>) provides dynamic configuration generation for Dagster operations, enabling parameterized job execution based on data source and pipeline type. This utility is critical for sensor-triggered jobs that must process entities from different sources (Accern, Gmail) using the same operation graph.</p>"},{"location":"utility-modules/utility_modules/#module-structure","title":"Module Structure","text":"<pre><code>from enum import Enum\n\nclass PipelineType(str, Enum):\n    \"\"\"Pipeline execution mode.\"\"\"\n    people = \"people\"\n    company = \"company\"\n\ndef get_op_config(\n    source_name: str,\n    pipeline_type: PipelineType = PipelineType.company\n) -&gt; dict:\n    \"\"\"\n    Generate operation configuration for source-specific entity processing.\n\n    Args:\n        source_name: Name of data source (\"Accern\", \"Gmail\", \"Harmonic Search\")\n        pipeline_type: Type of entities to process (company or people)\n\n    Returns:\n        Dictionary of op names to config overrides\n    \"\"\"\n    op_config = {\n        \"fetch_source_from_db\": {\n            \"config\": {\"source_name\": source_name},\n            \"inputs\": {\"source_name\": source_name},\n        }\n    }\n\n    watchlist_config = {\"config\": {\"source_name\": source_name}}\n\n    if pipeline_type == PipelineType.company:\n        op_config[\"get_source_watchlist\"] = watchlist_config\n    else:\n        op_config[\"get_source_people_watchlist\"] = watchlist_config\n\n    return op_config\n</code></pre>"},{"location":"utility-modules/utility_modules/#configuration-mechanism","title":"Configuration Mechanism","text":"<p>Op Config Structure</p> <p>The configuration dictionary maps operation names to their configuration overrides:</p> <pre><code>{\n    \"op_name\": {\n        \"config\": {...},   # Config parameters passed to op's config schema\n        \"inputs\": {...},   # Input values provided directly (bypassing upstream ops)\n    }\n}\n</code></pre> <p>Example Configuration</p> <pre><code># Company pipeline for Accern\nconfig = get_op_config(\"Accern\", PipelineType.company)\n# Output:\n{\n    \"fetch_source_from_db\": {\n        \"config\": {\"source_name\": \"Accern\"},\n        \"inputs\": {\"source_name\": \"Accern\"}\n    },\n    \"get_source_watchlist\": {\n        \"config\": {\"source_name\": \"Accern\"}\n    }\n}\n\n# People pipeline for Gmail\nconfig = get_op_config(\"Gmail\", PipelineType.people)\n# Output:\n{\n    \"fetch_source_from_db\": {\n        \"config\": {\"source_name\": \"Gmail\"},\n        \"inputs\": {\"source_name\": \"Gmail\"}\n    },\n    \"get_source_people_watchlist\": {\n        \"config\": {\"source_name\": \"Gmail\"}\n    }\n}\n</code></pre>"},{"location":"utility-modules/utility_modules/#integration-with-sensors","title":"Integration with Sensors","text":"<p>Sensor Usage Pattern</p> <p>Sensors use <code>get_op_config</code> to inject source-specific configuration when triggering downstream jobs:</p> <pre><code>from dagster import RunRequest, RunConfig, run_status_sensor, DagsterRunStatus\nfrom app.sensors.op_config import get_op_config, PipelineType\n\n@run_status_sensor(\n    run_status=DagsterRunStatus.SUCCESS,\n    monitored_jobs=[ingest_signals_from_accern],\n    request_jobs=[ingest_companies_from_signals, ingest_people_from_signals],\n    minimum_interval_seconds=7200,\n)\ndef signal_ingestion_from_accern(context):\n    \"\"\"\n    Trigger entity extraction jobs after successful signal ingestion.\n    \"\"\"\n    # Generate config for company pipeline\n    company_op = get_op_config(\"Accern\", PipelineType.company)\n\n    # Generate config for people pipeline\n    people_op = get_op_config(\"Accern\", PipelineType.people)\n\n    # Yield run requests with injected configs\n    yield RunRequest(\n        job_name=\"ingest_companies_from_signals\",\n        run_key=None,\n        run_config=RunConfig(company_op),\n    )\n\n    yield RunRequest(\n        job_name=\"ingest_people_from_signals\",\n        run_key=None,\n        run_config=RunConfig(people_op),\n    )\n</code></pre>"},{"location":"utility-modules/utility_modules/#pipeline-type-differentiation","title":"Pipeline Type Differentiation","text":"<p>Company vs. People Pipelines</p> <p>The <code>PipelineType</code> enum controls which watchlist operation receives configuration:</p> <pre><code>if pipeline_type == PipelineType.company:\n    op_config[\"get_source_watchlist\"] = watchlist_config\nelse:\n    op_config[\"get_source_people_watchlist\"] = watchlist_config\n</code></pre> <p>This enables the same job graph to process different entity types by swapping the watchlist retrieval operation.</p> <p>Watchlist Operation Signatures</p> <pre><code>@op\ndef get_source_watchlist(\n    context,\n    config: DataSourceFetch,      # Receives source_name config\n    harmonic: HarmonicResource\n) -&gt; Watchlist:\n    \"\"\"Fetch company watchlist.\"\"\"\n    all_watchlists = harmonic.fetch_watchlists()\n    return next(w for w in all_watchlists if w.name == f\"DealFlow - {config.source_name}\")\n\n@op\ndef get_source_people_watchlist(\n    context,\n    config: DataSourceFetch,      # Receives source_name config\n    harmonic: HarmonicResource\n) -&gt; PeopleWatchlist:\n    \"\"\"Fetch people watchlist.\"\"\"\n    all_watchlists = harmonic.fetch_people_watchlists()\n    return next(w for w in all_watchlists if w.name == f\"DealFlow - {config.source_name}\")\n</code></pre>"},{"location":"utility-modules/utility_modules/#configuration-flow","title":"Configuration Flow","text":"<pre><code>sequenceDiagram\n    participant S as Sensor\n    participant OC as get_op_config\n    participant D as Dagster\n    participant J as Job Ops\n\n    S-&gt;&gt;OC: get_op_config(\"Accern\", PipelineType.company)\n    OC--&gt;&gt;S: config dict\n\n    S-&gt;&gt;D: RunRequest(job_name, run_config=config)\n\n    D-&gt;&gt;J: Execute fetch_source_from_db\n    Note over J: Config: {\"source_name\": \"Accern\"}\n\n    D-&gt;&gt;J: Execute get_source_watchlist\n    Note over J: Config: {\"source_name\": \"Accern\"}\n\n    J-&gt;&gt;J: Fetch \"DealFlow - Accern\" watchlist</code></pre>"},{"location":"utility-modules/utility_modules/#use-cases","title":"Use Cases","text":"<p>1. Multi-Source Pipeline</p> <pre><code># Process signals from different sources using same job\nfor source in [\"Accern\", \"Gmail\"]:\n    config = get_op_config(source)\n    context.instance.submit_run(\n        job_name=\"ingest_companies_from_signals\",\n        run_config=RunConfig(config)\n    )\n</code></pre> <p>2. Parallel Entity Processing</p> <pre><code># Process companies and people in parallel for same source\ncompany_config = get_op_config(\"Harmonic Search\", PipelineType.company)\npeople_config = get_op_config(\"Harmonic Search\", PipelineType.people)\n\nyield RunRequest(job_name=\"ingest_companies_from_searches\", run_config=RunConfig(company_config))\nyield RunRequest(job_name=\"ingest_people_from_searches\", run_config=RunConfig(people_config))\n</code></pre> <p>3. Manual Job Execution</p> <pre><code># Manually trigger entity extraction for specific source\nconfig = get_op_config(\"Gmail\", PipelineType.people)\ndagster_client.submit_pipeline_execution(\n    pipeline_name=\"ingest_people_from_signals\",\n    run_config=config\n)\n</code></pre>"},{"location":"utility-modules/utility_modules/#configuration-validation","title":"Configuration Validation","text":"<p>Type Safety</p> <p>Dagster validates config against op config schemas at runtime:</p> <pre><code>@op(config_schema={\"source_name\": str})\ndef fetch_source_from_db(context, db: DatabaseResource) -&gt; DataSourceReturn:\n    source_name = context.op_config[\"source_name\"]  # Type-safe access\n    return db.fetch_source_by_name(source_name)\n</code></pre> <p>Invalid Config Example</p> <pre><code># \u274c Missing required config\nconfig = {\n    \"fetch_source_from_db\": {\n        \"config\": {}  # source_name is required\n    }\n}\n# Result: DagsterInvalidConfigError\n\n# \u2713 Valid config\nconfig = get_op_config(\"Accern\")\n# Result: Successful execution\n</code></pre>"}]}